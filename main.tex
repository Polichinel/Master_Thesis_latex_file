%\pagestyle{article}
\documentclass[a4paper]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} % for figures
\usepackage[section]{placeins} %This prevents placing floats before a section.
\usepackage{csquotes}

\usepackage{natbib}% better citation
%\usepackage{hyperref} %autoref
\usepackage[hidelinks]{hyperref} %hidelinks to remove ugly blue format
\usepackage{amsmath} % for \tag and \eqref macros in mathematical eq.


%% Sets linestretch, paragraphstrech, indentation and footnote stuff 
\usepackage{parskip} %space between paragraphs
\parskip=12pt %set space between paragraphs
\setlength\parindent{12pt} %paragraf indentation
\usepackage[onehalfspacing]{setspace} %linespacing; does not affect footnotes
\setlength{\footnotesep}{0.7\baselineskip}% space between footnotes
\usepackage[hang,flushmargin]{footmisc} %% removes identation in footnoteshttps://www.overleaf.com/project/5b98e00a21d3bd15ac5a2e86

\usepackage{makecell} % make cells in tabels for longer text

\usepackage[colorinlistoftodos]{todonotes}

%% For header and footer (1)
% Marco
\usepackage{fancyhdr}
\pagestyle{fancy}
\textwidth = 424pt % test width ish
\oddsidemargin = 18pt % margin width ish

\fancyheadoffset{0 in} % Shifty solutions..

\fancyhf{} %% clear defuelt header and footer

%% For header and footer (2)
%Specifics
\lhead{Simon P. von der Maase}
\rhead{\today}

\lfoot{University of Copenhagen}
\rfoot{\thepage}
\renewcommand{\footrulewidth}{0.8pt}

\title{Where Men Rebel\\A Modern Approach to Conflict Forecasting}

\author{Simon Polichinel von der Maase\\\emph{Under Frederik George Hjort}}
\date{July 2019}

\begin{document}

	\begin{titlepage}
		\maketitle
		%Character count: 43.950/44.000\\
		\noindent\rule{\linewidth}{0.4pt}
		\begin{figure}[h]
			\centering
			\includegraphics[scale=0.32]{KU_logo.png}
		\end{figure}
		\thispagestyle{empty} % removes page number on front page
	\end{titlepage}
    \tableofcontents
\pagebreak

\begin{abstract}
\todo[inline]{to come. Max one page}

\end{abstract}
\pagebreak

\section{Introduction}
%\todo[inline]{The World}

\begin{displayquote}
\emph{[...] the estate of Man can never be without some incommodity or other; and [...] the greatest, that in any form of Government can possibly happen to the people in generall, is scarce sensible, in respect of the miseries, and horrible calamities, that accompany a Civill Warre;} \cite[128]{Hobbes_1991}\par
\end{displayquote}

Civil wars, and internal conflicts in general, have plagued mankind throughout the ages. And still, this affliction has not yet been throttled. Since 1960, over half of all nations have experienced some manner of internal conflict leading to fatalities \citep[3-4]{Blattman_Miguel_2010}. Indeed, since the end of the Second World War, intra-state conflicts have been far more common than inter-state wars and over five times as many people have died in intra-state conflicts compared to inter-state wars \citep[563]{Collier_Hoeffler_2004}. Thus the 367 years old quote above is today as relevant as ever.\par

\textbf{This thesis represents a substantial step towards the construction of a reliable computational framework for predicting future conflicts at a sub-national level; a so called \emph{early-warning system}.} In the short run such a system will provide international actors valuable information and time to act; mitigating the fallout of conflicts \citep{Ward_Greenhill_Bakke_2010, perry_2013}. In the long run such a system will generate theoretical insights into the mechanics of conflicts, potentially enabling actors to address the underlying courses \citep{Schrodt_2014, chadefaux2017conflict}. Given these potentials, efforts to create an early-warning system have been called "conflict researchers’ ultimate frontier" \citep[474]{cederman2017predicting}. As such, the contribution of this thesis is highly topical and can provide practical and ongoing guidance in future conflict prevention, intervention, and peace keeping efforts.\par

A complete early-warning-system would be constituted by a legion of sophisticated components. In this thesis I will focus on one of these components: A component capable of using past patterns of conflict to predict future patterns of conflict. The reason why I choose this focus, as I will demonstrate throughout this thesis, is that this approach has a number of very appealing properties: it has a clear theoretical foundation, it holds high prediction power, and it takes advantage of very current data. As such, using past patterns to predict future patterns has the potential of being one of the most important and central components of any complete early-warning system. This makes this approach a relevant and worthwhile subject for the thesis at hand.\par

Specifically [...]
\todo[inline]{The steps and prime conclusions of this thesis will be briefly outlined here.}

The proceeding subsections outline some prime insights, conclusions and challenges regarding conflict forecasting in general. This concurrently qualifies and explains why I focus on the past patterns as opposed to e.g. the structural prerequisites.\par

\subsection{Conflict prediction so far}
% condensat af lit review
%\todo[inline]{The science}

% what
The study of internal conflicts has a long and rich history. The sub-field of computational conflict prediction\footnote{from here just denoted conflict prediction}, however, is a rather novel offspring. Researchers of conflict prediction use modern computational tools in efforts to predict the time and place of future conflicts \citep{cederman2017predicting, chadefaux2017conflict}. Some of the earliest examples in academia of such a focus being \cite{Goldstone_2010}, \cite{Hegre2013} and \cite{perry_2013}.\par

% why not before
There are two main reasons why the field of conflict prediction -- despite its obvious usefulness -- has not flourished yet. First of all; the required technology is relatively new. Indeed, some of the more impressive recent results are due to novel developments in quantitative methods, computation power and data availability \citep{ol2010afghanistan, perry_2013}. Secondly, traditional conflict research has focused on causes, correlates and prerequisites of conflict rather than generating actual predictions \citep[8]{chadefaux2017conflict}. As such, modern predictive efforts are still regarded with high skepticism and papers devoted to prediction have been accused of lacking adequate theoretical grounding \citep[8-9]{chadefaux2017conflict}. 

% why it should be now.
In reality, however, both prediction and explanation are important components of scientific inquiry, and both are needed to generate and test theories \citep{Schrodt_2014, chadefaux2017conflict}. Indeed, in the natural sciences, accurate predictions are central for the validation of theory \citep[289]{Schrodt_2014}. As such, the restraint against predictions in the field of conflict research has been increasingly criticized \citep{King_Zeng_2001, Ward_Greenhill_Bakke_2010, Goldstone_2010, Schrodt_2014, chadefaux2017conflict}. What is more; creating models with actual prediction-power will also provide heuristic tools and powerful policy-guides for real-world application \citep[372]{Ward_Greenhill_Bakke_2010}.\par

% A number of other recent developments
Beyond the shift from estimation to predictions, two other recent developments, in the field of conflict studies and conflict predictions, are central to this thesis and requires introduction at this point.\par

% another recent development: disaggregation.
Firstly, the shift from countries to more disaggregated geographical units of analysis. Countries have traditionally been the main focus, but since the phenomenon of interest is a sub-country phenomenon, the unit of analysis should also be disaggregated at sub-national level \citep[490]{Cederman_Gleditsch_2009}. Employing a disaggregated unit of analysis allows me to create a more detailed analysis of conflict patterns. It also allows me to better analyze incidents where administrative boarders provide little to no ward against conflict diffusion \citep[445-446]{ol2010afghanistan}. In turn, the derived insights allow me to generate forecastings pertaining to specific sub-national areas rather than entire countries.\par

% the last recent development: Structures to patterns.
The last recent development, which I will touch upon here, constitutes the starting point of this thesis. This development concerns the turn from structural data to event data. Structural data being data pertaining to poverty, deprivation, resources, political regimes etc. Event data being data pertaining to the patterns of past conflicts.\par 

% why event data is better 1
Traditional efforts have tended to use structural features as foundation. This has been true for both estimations and predictions \cite[10]{chadefaux2017conflict}. However, in a recent contribution of my own I show that patterns of conflict events in themselves appear to hold much more prediction power than the traditional structural variables \citep{Maase}. These findings align perfectly well with a growing strain of the literature concerning conflict diffusion. Little doubt remains that conflicts cluster in time and space \citep[15]{crost2015conflict}. Furthermore, recent efforts have shown that the clustering and diffusion of conflict is often a direct product of contagion \citep{buhaug2008contagion,schutte2011diffusion,crost2015conflict,bara_2017}. As such, when it comes to sheer prediction power, event data appears to have the advantage over structural data.\par

% why evetn data is better 2
Importantly, event data is also, at present, much more current and more often maintained than the data pertaining to the structural features. In practice this means that the data I use for actual forecasting is much closer in time to the forecastings I wish to generate, thus creating more reliable predictions and mitigating uncertainty. This constitutes a further substantial advantage of event data over structural data.\par

% sub konk
Given these insights and conditions -- and the scope of the thesis at hand -- I will only utilize data relating directly to past conflict events in my prediction effort. That is, estimating the probability of future conflicts given past patterns of conflict.\par

% bridge
The next section will introduce the research question I answer, the approach I utilize and the framework I construct throughout this thesis. To guide the reader I also present an overview of the steps taken to this end.\par 

%the concrete contribution of this thesis which is a framework for constructing reliable conflict forecastings using the temporal and spatial patterns of past conflicts. As such the section will also outline the research question and the steps taken to answer this quesition.\par

\subsection{This framework}
\todo[inline]{this paper}

% what you gonna do there champ?
The prerequisite for using past patterns of conflicts to predict future patterns of conflict is the ability to identify and extract salient patterns and further extrapolate these patterns into future years. In this thesis, I show how this can be done using the machine learning technique of \emph{Gaussian processes}. Furthermore, I demonstrate how the technical properties of Gaussian processes align remarkable well with the theoretical foundation of conflict diffusion in general. The presentation, qualification, and exemplification of how Gaussian processes can turn past conflict patterns into future conflict predictions is the prime objective of this thesis.\par

% RQ
The research question motivating this thesis can be summed up accordingly:\par

\begin{displayquote}

\emph{\textbf{Research Question:} How can we efficiently use the temporal and geo-spatial patterns of past conflicts to forecast and predict the time and place of future conflicts?}\par

\end{displayquote}

%For the construction of my framework I use two layers of estimation. First, I use Gaussian processes to estimate the pattern of conflict magnitude and conflict exposure. Secondly, having extrapolated these patterns into future years and derived the corresponding slope, acceleration and mass, I use these patterns as features in my final predictive framework which is based on the xgboost algorithm and various undersampling methods. (Matias kan godt lide den her.)

% Steps - over all...
To answer this question, I use event data pertaining to sub-country geographic grid cells. The data I use covers the years form 1989 through 2017. I split the data into a trainingset (1989-2012) and a testset (2013-2017). Using the training data I identify and extract the spatial and temporal conflict patterns via Gaussian processes. Also using Gaussian processes, I extrapolate these patterns into future years corresponding to those of the test data. From these estimated and extrapolated patterns I extract eight different, but closely related, features pertaining to the temporal and spatial patterns of conflict. I use the feature values corresponding to the training years to train a predictive framework based on Extreme Gradient Boosting. Having trained this framework I introduce the extrapolated feature values corresponding to the test years. Using these extrapolations I estimate the probability of intra-state conflict in a specific grid cell given a specific future year contain in the testset. To asses the usefulness of my approach, these prediction are evaluated through out-of-sample predictions against the actual observations in the test data. Comparing the predicted values with actually observations will show the predictive potential of my framework and thus serve to evaluate my approach; that is using Gaussian processes to turn temporal and geo-spatial patterns of conflict into predictions of future conflicts.\par

% Data and unit of analysis
To be more specific; the data I use is obtained from the Uppsala Conflict Data Program \citep{UCDP_2017}. This data denotes, among other things, conflict fatalities at specific coordinates and dates \citep{UCDP_2017}. I use the logarithm of this measure to create a measure of \emph{conflict magnitude} (cm). The temporal dimension spans from 1989 to 2017 and I aggregate it at a yearly level. The spatial dimension, I aggregate using a global grid constituted by $0.5 \times 0.5$ decimal degree cells; that is squares roughly measuring $50km\times50km$ at the equator \citep[367]{Tollefsen_2012}. Thus, the unit of analysis is one specific grid cell at one specific year.\par

% Time lines as functions
I will refer to the combined observed years of a given cell as the \emph{time-line} of that cell. Each time-line tells the story of conflict in the corresponding cell throughout the included years. Each time-line can also be seen as a continuous function $y = f(x) + \epsilon$ where $\epsilon$ is a noise term, $y$ is conflict magnitude and $x$ is years. If we can estimate this function, we can also extrapolate it into the future by introducing new years; $x_{new}$. This is exactly what we can use Gaussian processes for.\par

% introducing space
Now, this will give an estimate of the future magnitude of conflict in each individual cell. This is in itself a prediction. But we can do much better. Using only the magnitude of the individual cell, we would fail to account for the spatial diffusion of conflicts between cells. We need a measure accounting for \emph{spatial exposure} as well. Encouragingly, I can use Gaussian processes for this purpose as well.\par

% how you solve space
For each individual year in my sample, I estimate a 2D function of the spatial pattern of conflict over all included grid cells. This effectively gives me an estimation of the level of \emph{static conflict exposure} (sce) each cell experiences in any given year. To bind this information together across all years, and allow for extrapolation into the future, I once more view the individual time lines as functions $y = f(x) + \epsilon$. $\epsilon$ is still a noise term and $x$ is still years, but now $y$ is conflict exposure. This captures the spatial patterns of \emph{dynamic conflicts exposure} (dce) across time\footnote{Effectively this constitutes a pseudo 3D space. It could also have been estimated directly in 3D if I had access to vastly more computational power.}.\par

% the six other featues
Where conflict magnitude denotes the level of conflict in a specific cell, conflict exposure denotes the aggregated level of adjacent conflicts. Intriguingly, since I am effectively working with continuous functions, I can readily extract other relevant information. Specifically how much the conflict magnitude or exposure is increasing or decreasing (slope), whether the conflict magnitude or exposure of a given cell is accelerating or decelerating (acceleration), and the total mass of conflicts in the time-line of each cell (mass). Using these options on both conflict magnitude and conflict exposure, I construct six additional features. All in all, I produce eight features representing the spatial and temporal patterns of conflict. All eight feature are extrapolated into future years.\par

% how do you combined these features
Each extrapolation of these measures does in itself constitute a forecasting. However, to harvest the full potential of these measures, I will use them as features in a combined predictive framework\footnote{Note, that I am using extraplated values, I eliminate the need for \emph{lagging} or \emph{leading} any measure.}. A framework capable of predicting probability of conflict in a given cell at some future point in time. For this I will use the forecasting-framework presented in \cite{Maase}. This framework is based on an Extreme Gradient Boosting algorithm \citep{Chen_2016}, which is a powerful \emph{tree-based} machine learning algorithm which uses boosting to better handle hard cases and rare events \citep[X]{Chen_2016}. This structure also allows for automatic generation of relevant interactions \citep[305-310]{Friedman_2001}. The framework is further pruned for rare events by employing a combination of case-cohort under-sampling \citep[142]{King_Zeng_2001} and informed under-sampling \cite[1267]{He_2008}. I specifically designed this framework with internal conflicts in mind, thus making it an obvious choice for the evaluation effort.\par 

%
% Importantly, however, the nuts and bolts of this particular predictive framework will not occupy a central role in this thesis; it will only serve to evaluate the potential of using past temporal and spatial conflict patterns captures with Gaussian processes as future predictors.\par

% Two layers; first x and y second x and y


% test and train
Having combined my extrapolated patterns into aggregated prediction, I need to evaluate how good these predictions are. If I were to forecast into actual future years, I would not be able to conclude how reliable my approach is - at least not before a number of years have passed. To avoid this impractical latency I divide my data into a \emph{train set} and a \emph{test set}. My train set will encompass all years from 1998 to 2012 while the test set will encompass all years from 2013 to 2017. Importantly, my model will not be based on the test set, which will be kept isolated until the evaluation effort. As such, the test set effectively represents "the future" \cite[199-200]{Goldstone_2010}. Using this evaluation-scheme insures that I obtain an accurate assessment regarding my approach potential for actual forecasting.\par 

%my results shows that....
Using this approach I am able to ....\par % here only in substantial terms... no ap or jazz

%future potentials
Future efforts should ...\par
%A natural limitation is completely novel onsets far removed from any other conflicts in time and/or space.
%Other methods, but also perhaps just other event data.

To show how my contribution fit into the large fields of conflict studies, the next section presents two recent and very relevant developments. Firstly, how the focus is shifting from estimation to prediction. And secondly, how the unit of analysis has shifted from countries to more disaggregated geographical units. Understanding these two developments will help qualify my approach.\par

\section{Recent and Relevant Developments}\label{challenges}

%\todo[inline]{Political Science Literature Review}
%Introducer alle de begreber du bruger. 

% Why you need to introduce these developments.
The field of conflict studies has flourished during the last two decades. Yet, during this period the field has also been challenged and critiqued from numerous angles. This thesis is naturally a product of these past debates and developments. Since my starting point is the latest research in the field, I here introduce the reader to the most recent and relevant developments.\par

% what is gonna happen below
As such, the following section serves to introduce two novel developments in the field of conflict studies. The first subsection introduces the development from estimating the effects of various features on the probability of conflict, towards forecasting the actual probability of conflict. The second subsection presents the development from cross-country studies towards more disaggregated geographical units. Together, these two developments serve as context for the main challenge presented hereafter: Using past patterns as future predictors.\par


\subsection{From estimation to forecasting}\label{est_to_pred} % ---------------------------------------------------------------------

% What you gonna say now:
% In this thesis, my focus is reliable prediction rather than substantial explanation. This subsection serves to presents and qualify the background and motivation for this focus.\par

%What use to be
Traditionally, conflict studies have focused on explaining conflict; understanding which features facilitate conflicts. The features under investigation have mostly been structural such as poverty, natural resources or a specific political regime. To this end researchers have used statistical tools such as linear and logistic regressions to estimate the effects of various features on the probability of conflict \citep[8]{chadefaux2017conflict}, and further whether this estimated effect could be considered \emph{statistically significant} \citep[363-364]{Ward_Greenhill_Bakke_2010}. If a given feature was found significantly related to conflict - and the study could be considered valid and unbiased - researchers would use theory to argue why the correlation could be considered causal. This is \emph{causal inference} \citep[8]{chadefaux2017conflict}. Knowing which features "cause" conflicts could then be used for policy recommendation.\par

% But why that way?
The focus on causal inference was (and still is) prevalent, and very few conflict experts have ever attempted to undertake actual conflict prediction and forecasting \citep[474]{cederman2017predicting}. This reluctance to focus on prediction is primarily due to two assertions. Firstly, efforts devoted to prediction have been accused of lacking strong theory and as a consequence been rejected by traditional political science journals \citep[8-9]{chadefaux2017conflict}. Secondly, predictions have been considered fruitless due to "the perceived impossibility of forecasting political events" \citep[8]{chadefaux2017conflict}.

% The problem with these assertions.
Such assertions, however, are both misleading and unproductive. First of all, prediction is not "unscientific". On the contrary, both prediction and explanation are key components of scientific inquiry, and both are needed to generate and test theories \citep[8]{chadefaux2017conflict}. In the natural sciences, accurate predictions are seen as the "epitome of validation of a theory" \citep[289]{Schrodt_2014}. Secondly, while we still do not know the full potential of conflict prediction \citep{cederman2017predicting, chadefaux2017conflict}, we know it is not impossible. The reason is that we already have a few tentative, but encouraging, results available \citep{Goldstone_2010, perry_2013, mueller_2016, Maase}. Indeed, developments in statistical methods, computational power and data availability make such endeavours increasingly feasible \citep{ol2010afghanistan, perry_2013}. 

% But is there i problem with the old approach
Given these insights and developments, the sentiment is shifting and criticism is increasingly aimed at the traditional explanatory approach. This approach is justified by assuming that high explanatory power equals high predictive power. This is not the case however. Using statistical significance as the basis of policy recommendation is considered highly imprudent, since many prominent studies using this approach have shown very poor predictive capabilities \citep{Ward_Greenhill_Bakke_2010, Schrodt_2014, chadefaux2017conflict}. Indeed, the traditional approach of significance testing in conflict studies has been consistently criticized for almost two decades \citep{king_zeng_2001b, Ward_Greenhill_Bakke_2010, Goldstone_2010, Schrodt_2014, chadefaux2017conflict}. Notably, even when explanation is the sole purpose of a study, significance testing has been deemed a misleading way to evaluate the included features of interest: critics claim that prediction-power is a better benchmark for the salience of the included features, even when forecasting is not the end-goal \citep{Ward_Greenhill_Bakke_2010, Schrodt_2014}. The point is that creating models with actual prediction-power is both a better way to evaluate feature importance and it will provide heuristic tools and powerful policy-guides for real world applications \citep[372]{Ward_Greenhill_Bakke_2010}. Thus, whether the specific goal of a study is explanation or prediction, a focus on prediction-power has been recommended going forward in conflict studies.\par

% so what do we do?
When employing a predictive approach we do not rely on significance levels for evaluation. Even more, if the goal is purely heuristic, concerns about bias and endogeneity are shelved. Instead, the primary concern is increasing prediction-power by mitigating both \emph{underfitting} and \emph{overfitting}. Underfitting, meaning creating a model which has failed to learn any salient patterns in the data pertaining to the phenomenon under investigation. Overfitting, meaning the accidental identification of patterns present in the data, yet not present in the real world \citep[165-168]{Mcelreath_2018}. One failure of traditional estimation efforts is the tendency for the models to either over- or underfit \citep[364]{Ward_Greenhill_Bakke_2010}.\par 

% and what do we gain from this?
Testing whether a given model can generate reliable predictions can help identify overfitting, underfitting and other ills. There are many different tools available for testing the prediction power of a model. One such tool recommended for conflict studies is \emph{out-of-sample prediction} \citep{king_zeng_2001b, Ward_Greenhill_Bakke_2010, perry_2013, Schrodt_2014}. This approach is quite simple and entails the construction of the predictive model(s) on one set of data, leaving another set of data for testing; a \emph{training set} and a \emph{test set}. In simplified terms, if the model fits the test set as well as the training set, overfitting has been avoided. If the predictions are also accurate and reliable, underfitting has been avoided. While out-of-sample predictions might not cure the ills, it generates honest evaluations and reveal overfitting and other compromising malaise.\par

% What happens now?
Adopting such evaluation frameworks, some scholars have started using prediction to evaluate the salience of given features along with traditional parameter estimation \citep{Goldstone_2010}. Other scholars have abandoned parameter estimation and now combines modern machine learning techniques with the traditional roster of structural features to create predictive tools for policy recommendation \citep{perry_2013}. Lastly, some scholars abandoned both parameter estimation and the traditional roster of features all together, such as \cite{mueller_2016} who rely solely on text data from news outlets to predict future conflicts.\par

% What do you do
Thus, in this thesis I will use modern machine learning tools in cohort with past conflict patterns to predict future conflicts. A "causal" discussion regarding whether conflict can be considered truly contagious is both interesting and worthwhile, but it is not the focus of this thesis. My goal is solely to examine the potential of using past conflict patterns for reliable forecasting. As such, high prediction power is my prime concern going forward into this project. This does not mean that theory does not matter. What it does mean is that the theory I employ serves to improve prediction power by informing how I construct my framework ex ante -- and not to argue about causality ex post.\par 

% Bridge:
This concludes my section on the development from estimation to prediction. Another central development is the shift from cross-country studies to more disaggregated studies. That is, from studies taking countries as their unit of analysis to studies using much smaller geographic entities as unit of analysis. This development will be presented in the following section.\par


\subsection{From cross-country to disaggregated} % ---------------------------------------------------------------------

% What you gonna do there mate?
In this thesis, rather than countries, the unit of analysis is $0.5\times0.5$ decimal degree grid-cells. This subsection presents the theoretical background and motivation for this disaggregated approach.\par

% Traditional
In the literature on internal conflict and civil war, the unit of analysis has traditionally been \emph{country-years}. That is; a specific country in a specific year. This has been true both when the goal was prediction \citep{Goldstone_2010, mueller_2016} and explanation \citep{Collier_Hoeffler_1998, Fearon_Laitin_2003, Collier_Hoeffler_2004, Hegre_Sambanis_2006}. In other words, the aim was to find the probability that some given country would experience internal conflict in some given year.\par

% the problems with this approach
In reality, however, civil war rarely encompasses entire countries, but are often confined to specific regions of a country \cite[487]{Cederman_Gleditsch_2009}. As such, we miss important nuances and patterns when treating internal conflict as a phenomenon which is necessarily country-wide. Some regional conflicts will be presented as country-wide civil wars, while other serious regional conflicts will be treated as non-conflicts. Furthermore, some theoretically relevant features cannot readily be modelled when utilizing observations aggregated at country-level. As an example, \cite{Cederman_Gleditsch_2009} argues that the many non-findings regarding the role of ethnic fractionalization in the quantitative literature\footnote{Among the most seminal of these studies are \cite{Fearon_Laitin_2003}, \cite{Collier_Hoeffler_2004}, and \cite{Hegre_Sambanis_2006}} can be attributed to over-aggregation \citep[493]{Cederman_Gleditsch_2009}. A point which is rather convincingly elaborated in \cite{Cederman_Gleditsch_Buhaug_2013} and supported by the results in \cite{Goldstone_2010}. 

% Why did we not do it before?
Indeed the denomination "internal conflict" itself should compel us to explore the phenomenon at a sub-country level. This is well formulated by \cite{Cederman_Gleditsch_2009}: "If our theories are disaggregated, then our empirical analyses and research designs should reflect this" \citep[490]{Cederman_Gleditsch_2009}. Now, using sub-country units requires more computational power, better models, and not least the right data. Such obstacles have previously impeded sub-national analysis on a wider scale. Encouragingly, recent developments in statistics, technology, and data availability address these issues and make disaggregated studies evermore manageable \citep[446]{ol2010afghanistan}.\par

% What dies this mean for your paper?
By using a disaggregated approach I am able to analyze the local temporal and spatial dynamics of conflicts at a level which both yields more practical insights and is more appropriate given the theoretical foundation \citep[446]{ol2010afghanistan}. If I were to model the spatial patterns of conflict using countries as the unit of analysis, I would be hard pressed to produce insights beyond those most trivial, such as "If country (A) is experiencing conflict, a neighboring country (B) might be at a greater risk of also experiencing conflict". This would tell us nothing about where the conflict is located in country A; whether it is getting closer to country B; whether it engulfs the boarder between A and B; or where in country B it develops. A more disaggregated approach allows me to produce deeper and more fine-grained insights regarding the diffusion of conflict -- a potential powerful policy tool indeed.\par 

%Bridge: what you gonna do next?
This concludes my presentation of two recent and highly relevant developments in the fields of conflict studies and conflict predictions. In the next section I will focus on the challenge at hand; using conflict patterns as conflict predictors. Firstly, I present empirical motivation for using past patterns as opposed to e.g. structural features as the basis of my forecasting framework. Secondly, I will also present some of the insights recently produced by the literature on conflict diffusion and contagion. Lastly, I show how past efforts have tried to incorporate the patterns of conflict in predictions and explanations alike. The point is to juxtapose the theory of conflict patterns with past implementations illustrating \emph{what not to do} while also formulating criteria for \emph{what we should do}. Together, these insights will qualify why I have chosen to use Gaussian processes for the challenge of mapping conflict patterns.\par

\section{The Present Challenge} % To assnit?

% Whats gonna happen here mate?
Whether the goals were explanation or prediction, past efforts have usually focused on structural features such as poverty, deprivation, resources, political regimes etc. \citep[10]{chadefaux2017conflict}. That being said, temporal and spatial patterns of conflict have not gone unnoticed. The proceeding sections will motivate why these patterns are my primary focus, present what we know about conflict patterns, discuss how previous efforts have tried to incorporate conflict patterns, and lastly argue why these efforts leaves plenty room for improvement. The point is to present clear theoretical criteria for how conflict patterns should be modelled. These criteria will then serve to qualify the tools I use in the project; particularly Gaussian processes.\par 

\subsection{Why Conflict patterns}

% How come you choose this approach?
When reliable prediction is the primary goal, we need features with substantial predictive potential. In \cite{Maase} the predictive potential of various features was evaluated in order to map fertile paths for future research regarding the construction of an early-warning-system. The paper showed that, while structural features such as poverty, deprivation, population size, country size etc. did contribute with relevant prediction power, the most important features - by far - where those pertaining directly to the spatial and temporal patterns of conflict. Specifically three features: Distance from the geographic unit to the nearest conflict, all past fatalities in the geographic unit, and number of past conflict years in the geographic unit\footnote{all lagged one year} \citep[17-18]{Maase}. As such, the conclusion was that further predictive efforts should focus on extracting even more information from the temporal and spatial dimensions by developing more theoretically and methodically appropriate features pertaining to these dimensions \citep[21-23]{Maase}.\par

A second very important advantage when the goal is actual forecasting is that the data pertaining to the patterns of conflict is more readily available, more up-to-date and more current compared to structural data. To capture the spatial and temporal patterns of conflict I only need event data. That is, data pertaining to the past conflicts themselves. Structural data such as wealth measures often take a lot of time to gather and process. The consequence being that the last observations of such data is often quite dated by the time the data is made public. Event data such as that used in this thesis is released much more frequently with the last entry being much more current. As an example, if I used structural data for the effort, it would be hard to get complete data more current than 2015. The event data used for this effort, however, has its last entry at 2017, with 2018 already available\footnote{While the data for 2018 has been available from UCDP since 03-06-2019, it was not included in this project since all the most demanding computations where completed before this release. Since I do not actually here forecast into true future years such as 2020 or 2021 the inclusion of the 2018 data would have delayed the completion of this project, without adding much value to the effort.}. As such, the topicality of event data is another important advantage over structural data when forecasting is the goal.\par

\subsection{What we know about conflict patterns}
%\subsection{Pattern as predictor so far}

% The criteria:

%To reiterate, what we need in regards to the temporal dimension is a tool that allow incorporation of information drawn from all past (included) years. The magnitude and volatility of past conflicts should influence probability of future conflicts with with some decreasing influence the longer we move back in time. Further more this deterioration rate should be estimated through the data itself, rather then guessed at by me, the researcher.\par

%In regards to the spatial dimension, the criteria are rather similar. We need a tool capable of including information from all relevant events, taking into account both the magnitude and distance of all relevant conflicts. Notably I do not want to decide how close a conflict has to be, to be included. Nor do I want to decided the deterioration rate of influence. These elements should be estimated from the data at hand. Furthermore, the tool should be able to distinguishing between different patterns of conflicts. E.g. I want encirclement compared to exhibit higher influence than tangency.\par

%What do we know:
% Thay culster in time and space
% They can be a product of cognetation
% They move seemlessly over boarders
% near boarders - men det tager du ikke højde for så ud med det
% Previous research on conflict diffusion has established that internal conflicts often unfolds near boarders \cite[29-30]{Blattman_Miguel_2010} 
% They expand outwards in space from one place to the surrounding places -> seems like cogniation

It is well known that conflicts exhibit discernible patterns. Here I present four specific insights from the literature on conflict patterns. Firstly, it has been firmly established that conflicts cluster in time and space, with \cite{crost2015conflict} listing no less then 20 published academic papers supporting this assertion \citep[15]{crost2015conflict}. Secondly, the emerging consensus is that the clustering and diffusion of conflict is often a direct product of contagion rather then merely a bi-product generated through clusters of structural features such as poverty or political regimes \citep{buhaug2008contagion,schutte2011diffusion,crost2015conflict,bara_2017}. Thirdly, it has been found that conflicts often diffuse seamlessly across any administrative boundaries they might encounter \cite[442-443]{ol2010afghanistan}. Lastly \cite{schutte2011diffusion} show how patterns of internal conflict are characterized by distinctive patterns comparable across cases. Indeed, when conflict engulfs one location it is likely to expand outwards from the location over time \citep[151]{schutte2011diffusion}. The take-away from these insights is that the pattern of conflict, at its most fundamental level, exhibits bell-curve (or Gaussian) like properties through both time and space. The closer you are to an active conflict in time and/or space, the more likely it is to spread to your location. A simple but powerful guideline which will prove very useful going forward.\par

% - The problems are ...
The challenge is to construct a framework which incorporates such insights into the actual modeling of conflict patterns. Unfortunately, past efforts which have aimed at taking conflict patterns into account often fall short of creating theoretically and methodologically coherent operationalizations. Indeed it would not be unfounded to call many past solutions underdeveloped. Naturally this contention requires elaboration and justification which is best done through the power of examples. This leads me to the next subsection.\par

\subsection{How (not) to use patterns as predictors}

% What's gonna happen now?
Given the widespread consensus that conflicts cluster in time and space, it is no surprise that a number past efforts have aimed to incorporate measures pertaining to temporal and spatial patterns. Unfortunately, modeling these patterns has rarely been the prime objective. The consequence is that the operationalization of these patterns has been ad hoc and underdeveloped. This is true for spatial and temporal patterns alike. In this section I will, in turn, present and criticize some of the past efforts made to capture the temporal and spatial patterns of conflict. In tandem with the insights on conflict patterns just presented, I will use this section to formulate clear theoretical criteria which any framework meant for the identification and extraction of conflict patterns should fulfill. These criteria will in turn qualify the tools presented in the proceeding section.\par

%These examples are juxtaposed with theory regarding how conflict actually moves trough time and space. This juxtaposition will serve as a guideline which will direct us towards the right tools.\par

% ex perry's temporal
I will start by presenting how the temporal dimension of conflict patterns have previously been modelled. A deterioration index recently proposed by \cite{perry_2013} can serve as an example of the general state of affairs. Perry's idea is related to the phenomenon of a conflict trap and the notion of some inertia in conflict which might deteriorate over time. This time deteriorating index could be created by including the number of fatalities in some geographic unit for each of the last ten years as features. The deterioration rate is then incorporated through down-weighing these fatalities by dividing with the number of years passed since the corresponding events. Thus, a feature pertaining to fatalities two years ago will have, as its values, half of the fatalities observed that year \cite[14]{perry_2013}. As such the proposed index tries to fit the insight that the closer in time a geographic region is to past conflicts, the more likely the region is to experience conflict again.\par

% The problem with perry:
As such the heart is at the right place and the sentiment presented in \cite{perry_2013} is also rather symptomatically for the literature at large. The problem is that it is an ad hoc and underdeveloped solution. There is no reason to cap the effort at ten years and there is no theoretical or practical reason to choose the suggested deterioration rate. Instead of dividing with years past it might be more appropriate to divide by half that; or the deterioration rate might have an altogether different functional form, such as an exponential or linear decay function. The point is that if we do not know the relevant functions, efforts should been made to estimate them rather than guess them.\par 

% Better solutions - but we still have a problem
Some scholars have used slightly more involved solutions. \cite{Collier_Hoeffler_2004} use a linear decay function counting years since last conflict and \cite{Hegre_Sambanis_2006} use a linear decay function counting years since last peace. Yet, while such frameworks come closer to actual estimation, the specification of these functions still require ad hoc and arbitrary decisions \cite[501]{Gelman_2013}. Others such as \cite{Cederman_Gleditsch_Buhaug_2013} and \cite{Maase} simply count the number of previous conflicts in the geographical unit of analysis. Surely, we can do better if we employ methods actually capable of estimating these functions on the basis of the data.\par

% The spatial problem
Turning to the spatial patterns of conflicts the challenges are, to a large extent, the same. However, the enduring focus on countries inflates the problem even further. To exemplify, a simple dummy is often used to indicate whether some predefined number of neighboring countries are experiencing conflict or not \citep{Hegre_Sambanis_2006, Goldstone_2010}. The thresholds here often appear ad hoc as \cite{Hegre_Sambanis_2006} has a dummy denoting one or more "bad neighbours" \citep[521-522]{Hegre_Sambanis_2006} while \cite{Goldstone_2010} has a threshold of 4 or more bad neighbours \citep[197]{Goldstone_2010}. Surely the mechanisms determining whether conflicts spread from A to B are more complex then this and surely we can do a better job of emulating them.\par 

% Better solutions 1 - but we still ahve a problem
Encouragingly, a few scholars have started to explore more complex patterns, taking into account the size of shared boarders, the country size of bad neighbours, the presence of trans-boarder ethnic kinship, and the explicit number of bad neighbours \citep{buhaug2008contagion, Cederman_Gleditsch_Buhaug_2013, bara_2017}. This is definitely a progressive development, yet the enduring focus on countries still hampers the development of micro-level insights concerning where precisely a conflict unfolds in a given country and where it will contract, expand and diffuse to its surroundings.\par

% But there is ward 2013....

%One study which touches upon the micro level patterns of conflicts is \cite{schutte2011diffusion}. They show how patterns of internal conflict are characterized by distinctive patterns comparable across cases. Indeed, when conflict engulfs one location it is likely to expand outwards from said location over time \citep[151]{schutte2011diffusion}. While, this is valuable knowledge \cite{schutte2011diffusion} only study the patterns, but never use they derived insight to predict future conflicts. What I take away from their study is the insight that conflcit exposure at its most fundamental level exhibits bell curve like properties. The closer you are to an active conflict to more likely it is to spread to your location. A simple but powerful guideline which will prove very useful going forth.\par

% Better solutions 2 - but we still have a problem
Two studies which do take a disaggregated approach are \cite{ol2010afghanistan} and \cite{weidmann_ward_2010predicting}. \cite{ol2010afghanistan} do a commendable job of showing the diffusion of conflict from Afghanistan to Pakistan over the Duran Line from a disaggregated perspective, while \cite{weidmann_ward_2010predicting} illustrate how spatial and temporal patterns influenced the civil strife in Bosnia between 1992 and 1995. The challenge is that, using a disaggregated approach, we still have to decide how to include the effects of bad neighbours - the neighbours now simply being some sub-country unit. Indeed the uncertainty of how many bad neighbours to include only amplifies as we move from country to the sub-country level. Here 2$^{nd}$, 3$^{th}$, 4$^{th}$ and potential n$^{th}$ order neighbors will have to be considered, preferably with some demising influence as a function of distance, given the insight from \cite{schutte2011diffusion}. Furthermore, given the bell-curve-like properties of conflict diffusion it seems logical that the magnitude of adjacent conflicts also have an important part to play.\par

%  what we should do
Unfortunately, both \cite{ol2010afghanistan} and \cite{weidmann_ward_2010predicting} only choose to include a dummy for conflict in 1$^{st}$ order neighbors. The operationalization presented in \cite{Maase} is hardly any better; here distance to nearest conflict is used without taking into account the magnitude of this conflict, or the number of other adjacent conflicts zones. And even if the study had included the 2. nearest conflict, the 3. nearest conflict etc., and scaled the distance by some factor related to the magnitude of conflict, we would still not know if these conflicts surrounded and engulfed the observation of interest or instead clustered neatly and distinctly beside it. The pattern of conflict might matter; the magnitude of conflict might matter; the magnitude of adjacent conflicts in 1$^{st}$, 2$^{nd}$ and n$^{th}$ order might matter. Again the point is clear: modeling features to capture these phenomena must be an estimation effort in and of itself.\par

%\cite[146]{ol2010afghanistan}

%[DU HAR INTET EXPLICT BELÆG FOR AT MAGNITUDE MATTERS!!! Og du argumentere heller ikke for det] ++++++++++++++++++++++++++++++++++

%[Hvad med volatility or long and short term trends?]
%[Opsummering af criterier....]

To reiterate, what we need with regards to the temporal dimension is a tool that allows incorporation of information drawn from all past (included) years. The magnitude and volatility of past conflicts should influence probability of future conflicts with some decreasing influence the longer we move back in time. Furthermore this deterioration rate should be estimated through the data itself, rather than being guessed by the researcher.\par

In regard to the spatial dimension, the criteria are rather similar. We need a tool capable of including information from all relevant events, taking into account both the magnitude and distance of all relevant conflicts. Notably, I do not want to decide how close a conflict has to be in order to be included. Nor do I want to decided the deterioration rate of influence. These elements should be estimated from the available data. Furthermore, the tool should be able to distinguish between different patterns of conflicts. E.g. I want encirclement to exhibit greater influence than tangency.\par

In the next section I will present a tool capable of fulfilling all these criteria - and more: The machine learning technique of Gaussian processes. The goal is to demonstrate the nuts and bolts of the tool before I move on to the actual implementation. The section below will also briefly introduce a number of other computational tools used to bind the whole effort together.\par

% why slope, acc and mass?

\section{The Appropriate Tools}\label{tools}

% what going down here mate?
The following subsections serve to present the various computational tools used in this thesis going forward. The aim is to introduce the tools and qualify why these tools are particularly suited for the challenges at hand. The main focus here will be on using Gaussian processes to model the temporal and spatial patterns of conflict, but I will also briefly introduce the final predictive framework and the evaluation metrics used in the final evaluations effort. First however, a small subsection will introduce the concept of \emph{feature engineering}.\par

% Du skal også sige noget om hvorfor de features du ender med at construere er bedre ind bare at sige: der hvor der plejer at være konflikt: her can du kommer bla ind på heldning og acceleration hvilket hvilket er forskelligt fra timeliine til time line - og det leder videre differentiering.

% Whether diffusion is do to cognitation is irrelevant; it is the fact that it spreads like cognitation that you are gonna exploit. Yet that is the argument of Milton Friedman, Essays in Positive Economics, 1953 (p. 21) about as if.. Wich you don't like.... You  could say something like "from an eginering point of veiw, one might argue.. however, from a sceincetic point of view I find comfort in knowing that the methodolgy applied indeed tries to micmic that wich we know about the data generating process"


\subsection{Feature engineering - capturing theory with data} % ---------------------------------------------------------------------

% what?
Creating features from raw data is referred to as feature engineering. In conventional machine learning this means modifying the data to maximize its predictive power. In political science this often means modeling the data to more accurately capture the theoretical mechanism connecting $x$ to $y$. This could involve changing a wealth measure from absolute to relative, if one believes relative deprivation to be more important than greed or state capacity. When I talk about extracting patterns from event data, I am talking about feature engineering.\par

% Why?
Theoretically appropriate features are naturally needed if we wish to estimate a proposed theoretical relationship between two phenomena \citep{Blimes_2006, Cederman_Gleditsch_Buhaug_2013}. However, as this thesis focuses on prediction, prediction power is naturally the prime objective. That being said, theoretically viable features will often allow us to create models which come close to emulating the true data generating process, thus increasing the predictive power of the model \citep[209-211]{Mcelreath_2018}. As the criteria formulated above illustrates, theory can go a long way in guiding our feature engineering effort - also when prediction is the prime objective.\par

% So what do you do?
The feature engineering I present in this thesis, will be an estimation effort in itself: Not estimating a limited number of parameters as in traditional linear regressions, but estimating complete functions pertaining to the diffusion of conflict through time and space by the use of Gaussian processes. Specifically I will estimate two functions of each grid cell: One pertaining solely to the temporal diffusion of conflict in the individual cells and one also taking into account the conflict magnitude of proximate cells. From each of these two functions I will extract the values $f(x)$, the slopes $f'(x)$, the acceleration $f''(x)$ and the mass $F(x)$. This gives my eight measures which will serve as features in the final prediction effort.\par

%bridge
While such a "Matryoshka doll" of estimations and predictions are common in other traditions, it will understandably occur a bit exotic to many social scientists. As such, the subsections below will, one after another, clarify and qualify the approach.\par

\subsection{Gaussian Processes - capturing theory with method}\label{GPS}  % ---------------------------------------------------------------------
%Du skal også have introduceret priors for error term og hyper-parameters.
%Og hvad med Xnew? Det skal du også have ind

% what going down here mate?
This subsection presents the technical framework with which I will identify, extract and extrapolate the temporal and spatial patterns of conflict: Gaussian processes. The point is to familiarize the reader with the basics of Gaussian processes and concurrently illustrate how Gaussian processes conform beautifully to the criteria formulated for modelling conflict patterns. I will not get overly technical, but some intuition is needed in order to appreciate the link between theory and method.\par

%Gaussian processes can be used as predictive models in themselves, but more often they are utilized as components in larger models \citep[505]{Gelman_2013}. In this thesis they serve to model the spatial and temporal patterns of conflict. These patterns then serves in a large predictive framework, which could potentially incorporate other features such as structural variables and text data.\par

\subsubsection{From lines to functions}

% A point of reference
To get an appreciation for how Gaussian Processes works, it is helpful to start with a simple linear relationship. In the univariate example presented in equation \ref{eq:lin}, a linear relationship between a dependent target $y$ and the independent feature $x$ is described by a slope parameter $\beta$ and an error term $\epsilon$. The parameter $\beta$ is drawn from a Gaussian distribution ($\mathcal{N}$) with mean $\mu$ and deviation $\sigma$:

\[
\Tilde{y_i} = \beta x_i + \epsilon  \tag{1} \label{eq:lin}
\]
\[
\beta \sim \mathcal{N}(\mu,\sigma)  \tag{2} \label{eq:beta}
\]

% But we can do better
Now, the linear form presented above only allows the relationship between $y$ and $x$ to be described by a straight line with the slope given by $\beta$. We rarely see a linear development in temporal trends, -- at least not in the long -- and regarding spatial diffusion patterns it is hard to imagine any natural or social phenomenon taking this shape. As such, we want a way to model more complex functional forms. As a solution we might include n$^{th}$ order terms, which effectively would allow us to depict a function of arbitrarily large complexity:\par

\[
\Tilde{y_i} = \beta_1 x_{i1} + \beta_2 x_{i2}^2 + \dots + \beta_n x_{in}^n + \epsilon  \tag{3} \label{eq:orders}
\]

% Not enough though
However, unless we have very clear theoretical presumptions, we do not know how many orders to include. This would lead to arbitrary decisions. Furthermore, the approach of using higher order transformations is a well know source of overfitting \citep[2]{williams2006gaussian}. We need a framework which can accommodate complex forms and simultaneously combat overfitting.\par

% The solution
As such, instead of including $^{th}$ order terms let us imagine some relationship where the function $f$ is given by a Gaussian Process ($\mathcal{GP}$). The Gaussian process is closely related to the Gaussian distribution, but instead of being a distribution of numbers, it is a distribution of functions \citep[13-15]{williams2006gaussian}. As such, equation \ref{eq:f} does not denote any specific functional form for $f$. Instead, it denotes that the function $f$ is drawn from a Gaussian process - just as we draw numbers from a Gaussian distributing. Rather than being defined by the parameters $\mu$ and $\sigma$ a Gaussian process is given by a \emph{mean function} $m$ and a \emph{covariance function} $k$.\par

\[
\Tilde{y} = f(x) + \epsilon  \tag{4} \label{eq:y}
\]
\[
f(x) \sim \mathcal{GP}(m(x),k(x,x'))  \tag{5} \label{eq:f}
\]

% what is the mean function?
The mean function $m$ is our assumption in the absence of knowledge. Where knowledge - or data - presents itself, the mean function adapts to the data \citep[3-4]{williams2006gaussian}. In Bayesian terms this mean function can be understood as a weakly informative prior and in frequentist terms as a weak regularization \citep[35]{Mcelreath_2018}. Notably, however, only very little data is needed to overshadow the mean function. Indeed the surrounding observations and the covariance function $k$ is often much more important.\par

% what is you mean function 1?
Usually the mean function is set to the constant zero, but it need not be the case -- it could be any other constant such as the mean of $y$, a slope or any other function which might be appropriate given the specific theoretical underpinnings \citep[28-29]{williams2006gaussian}. In our case, the median and the mode of our dependent variable is 0 and the mean is rather close; most places do not experience conflict most of the time -- and since the target is logged, even large outliers, such as the genocide in Rwanda 1994, do not overly influence the mean. As such, a constant of zero also appears as a appropriate mean function here.\par

% what is you mean function 2?
Furthermore, the only situation in this project where I do not have data dictating the mean function is when I am forecasting. Proximate forecastings will be determined by the data pertaining the preceding years and the covariance function $k$. Forecasting to more distant years will increasingly be influenced by the predetermined mean function. That is, the further we move away from the last observed year, the less the data can tell us about future conflicts and the more influence the mean function will claim. Notably, the mean function will only dominate, when I extrapolate into a future too distant for data to reliably describe -- at which point the projections should not be consulted anyhow. Even more, a long run equilibrium of "zero conflict" in the individual cells is not an unrealistic assumption since, historically, no region on earth have ever experienced uninterrupted conflict in the long run. Thus, a mean functions of zero is to be utilized going forward in both examples and application.\par

\[
m(x) = 0 \tag{6} \label{eq:m}
\]

% what is a covariance function?
The covariance function $k$ is the crux of the machinery, often referred to as the kernel. It describes the similarity between each of the observations $x$ and $x'$. It effectuates the assumption that two observations with similar values on $x$ should also have similar values on $y$ \cite[79]{williams2006gaussian}. In the case of time and space this is a quite reasonable assumption. Given conflict magnitude pertaining to a geographic location $A$ at year 1990, 2012 and 2013 I would expect the conflict magnitude to be most similar between the adjacent years 2012 and 2013. Likewise, given a specific year I expect the conflict-intensity to be more similar the closer two geographic locations are located to each other. These are of cause simplified assumptions but they align with the insights produced by both \cite{weidmann_ward_2010predicting} and \cite{schutte2011diffusion}. All in all, such assumptions do not appear unreasonable given the general theoretical insights already presented.\par 

% what is your covariance function 1?
As such, the covariance function can simply be understood as a similarity measure. A lot of similarity measures are valid covariance functions -- each appropriate for specific tasks given specific theory and assumptions \citep[79]{williams2006gaussian}. In this thesis I use the \emph{squared exponential covariance function}\footnote{Also known as a Gaussian kernel or a Radial basis function kernel}. This covariance function is widely applied and is often a safe choice since the only assumption attached is that we are estimating smooth functions \citep[84]{williams2006gaussian}. As such, it is often used to model trends \cite[119]{williams2006gaussian}.\par 


%Furthermore, the smoothness of these functions also allow me to easily extract information regarding the slope and acceleration of the function at any given point in time through differentiation. Conversely, integration allows easy extraction of information regarding the total amount\footnote{Or mass} of conflict experienced in a given cell over the course of the included years.\par
% men du cruger jo ikke rigtigt defferentiering eller integrering?

% what is your covariance function 2?
Naturally, if we find it unsafe to assume smoothness or, conversely, safe to make more detailed assumptions such as periodic patterns, other covariance functions might be appropriate \citep[502-503]{Gelman_2013}. It is beyond the scope of the present thesis to explore different covariance functions, but future endeavours should naturally test whether more appropriate kernels exist. Here, the squared exponential covariance function will serve as the covariance function of choice in examples and application going forward. It is given in equation \ref{eq:k}.\par

\[
k(x,x') = \eta^2 exp\left(-\frac{|x-x'|^2}{2\ell^2}\right) \tag{7} \label{eq:k}
\]

% What are hyperparemeters?
From equation \ref{eq:k} it is clear that this is simply a similarity measure. What naturally stands out are the \emph{hyperparameters} $\ell$ and $\eta$. Hyperparameters in this context meaning scale parameters, which can be estimated and determine the volatility of the functions drawn from the Gaussian process.\par

% Ell?
Specifically, the $\ell$ is denoted \emph{length scale} \cite[501-502]{Gelman_2013} and can be interpreted as the distance we have to move across our $x$-axis before the functional value can change substantially \citep[14-15]{williams2006gaussian}. As such, in the present endeavour $\ell$ also denotes an appropriate rule-of-thumb-limit regarding how far into the future we should consult the extrapolated forecasting. Beyond the last observed year + $\ell$ our data provides little to no information, uncertainty proliferates, and the predefined mean function will start to dominate.\par

% Eta?
The $\eta$ is denoted \emph{amplitude} or "output variance", and roughly determines the average distance the functions vary from their means \cite[502]{Gelman_2013}. While $\eta$ serves a central part in the covariance function, the substantial interpretation is only of secondary interest given the focus of my project. Thus I will not spend much ink on this hyperparemater going forth.\par

\subsubsection{Exemplifying Gaussian Processes}

% Example
In \autoref{GP_varying_hp} I have drawn 15 samples from three different Gaussian processes given three different, pre-defined, sets of hyperparameters. The functions are randomly drawn from the "prior"; that is before any data have been introduced to the Gaussian processes at hand.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{GP_varying_hp.pdf}
    \caption{\footnotesize{15 functions drawn from three different GPs (priors) with different hyperparameters $\ell$ and $\eta$. All three GPs uses a squared exponential kernel function and a mean function = 0}}\label{GP_varying_hp}
\end{figure}

% Explaining the 1. example
The mean value across all 15 functions is the thick line and is denoted $\mu$. It is routinely used as the most-likelihood estimate of a functional form, and without any data it will default to the mean function \cite[3]{williams2006gaussian}. The volatility seen in \autoref{GP_varying_hp} is only due to the small number of samples drawn. The shaded area denotes two \emph{standard deviations} ($\sigma$) from the $\mu$ given the sample. Again, the volatility is due to the small sample number. Without any data introduced all functions given by the mean and covariance function are valid estimates. However, introducing data makes some functions more likely than others, effectively limiting the forms of the sampled functions. This is illustrated in \autoref{GP_toy_posterior} where the sampled functions now accommodate the data where it is available. Note that this Gaussian process is defined without any error term $\epsilon$, forcing all drawn processes to cut directly through the data points.\par  

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{GP_toy_posterior.pdf}
    \caption{\footnotesize{15 samples from a Gaussian process after the introduction of data. The points represent the data. The thick line is $\mu$ and the shaded area represents $\mu \pm 2\sigma$.}}\label{GP_toy_posterior}
\end{figure}

% Explaining the 2. example
Again, $\mu$ is the thick line and the shaded background represents $\mu \pm 2\sigma$. We see that uncertainty shrinks in regions illuminated by data, and grows the further we move away from data.\par

% concluding on examples
It should be clear from \autoref{GP_varying_hp} and \autoref{GP_toy_posterior} that if I were to determine the hyperparameter myself and omit an error term $\epsilon$, I could fit most smooth patterns with total precision. This would naturally lead to overfitting and furthermore, I would not have handled the issue of researchers guessing at functions rather than estimating them.\par

% Solution
Encouragingly, this can be amended rather elegantly. We included an error term $\epsilon$ to the Gaussian processes, which along with the hyperparameters $\ell$ and $\eta$, will be estimated through a framework which actively discourages overfitting \cite[114-115]{williams2006gaussian}. Using the estimated error term and hyperparameters in tandem with our data will generate Gaussian processes which will capture the general patterns of the data, but not overfit to noise.\par

% How this solution is don?
These estimates are obtained by maximizing the marginal likelihood of the given model \cite[114-115]{williams2006gaussian}. This, however, is a technical and non-trivial mathematical operation which I shall not explore further here\footnote{Curious readers should consult \cite{williams2006gaussian} section 5.4.1 for a complete overview and implementation of the operation.}.\par

% Exemple 3
A toy-example, emulating the subject of conflict magnitude, can be seen in \autoref{GP_toy_eks}. What we see here could be the development in three different conflict-ridden geographic units from 1990 to 2018. Here $\ell$, $\eta$ and $\epsilon$ are estimated from the data. I have only included $\mu$, as the solid lines and the shaded areas represents an interval of two standard deviations given the underlying samples. Since we have observations for each year there is very little uncertainty regarding $\mu$ during the observed years. We also see that the inclusion of $\epsilon$ allows $\mu$ some freedom to vary from the observations, thereby discouraging overfitting to noise.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{GP_toy_eks.pdf}
    \caption{\footnotesize{Three (generated) time-lines of conflict-ridden geographical locations. $\ell$ = 3.64, $\eta$ = 2.54, $\epsilon$ = 0.51}\label{GP_toy_eks}}
\end{figure}% you could make an ex with more noise.

In \autoref{GP_toy_eks} I have extrapolated 10 years ahead to illustrate how the two hyperparameters determine functional form of the function in the absence of data and how the mean function takes over as we venture into the unknown future. Crucially, I do not estimate a separate sets of hyperparameters for each of the three time-lines, but use the information from all three time-lines to estimate shared hyperparameters for all observations - so-called \emph{multi-task learning} \cite[115]{williams2006gaussian}.\par

%

% Patterns and non-zeroes
While I do use the same hyperparameter for all time lines in my implementation, I will not use all of the time lines when I estimate the hyperparameters. The reason is that most time lines do not experience conflicts and as such do not tell us anything about conflict patterns. Including such "flat-lines" would yield a misleading estimate of $\ell$. This is because $\ell$ tells us how far we have to move on $x$ to see changes in $y$ and time lines with no conflicts have a consistent conflict magnitude $y$ of $0$ no matter which year $x$ we look at. The result would be an estimated $\ell$ which would reflect that conflict magnitude is largely constant across time \footnote{Indeed, preliminary tests showed that the models would often not converge at all, if I did not add a minimum of noise to the "flat lines".}. Naturally this is only the case for time lines experiencing no conflcits and not time lines actually experiencing conflicts. To accommodate this issue the hyperparameters are only estimated using time lines with at least two years of conflicts (or conflict exposure). While two might seem an arbitrary number, it stands to reason that you need at least two none-zero observations to constitute any kind of pattern.\par

% Your assumtions
As such, I assume that the broader patterns of conflict across time (and later space) are comparable across the observations\footnote{Using separated hyperparameters for all observations would be going too far and would mean that we do not think conflict patterns share any similarity across cases. Yet, less demanding assumptions could be made if we used a hierarchical structure which allowed the hyperparameters to be similar without being identical. Notably, that would entail a substantial increase in the computational resources needed.}. While the results from \cite{schutte2011diffusion} do support the use of the same covariance functions across all cases, it would be too bold to claim that the results conclusively support the use of the same hyperparameters across cases. The validity of this assumptions should be further scrutinized in future endeavours. For now, however, this will do.\par

% Priors for hyper parameters
It should be briefly noted that just as I have priors for my Gaussian processes, I also set priors for these hyperparameters and the error term. More specifically, in the examples shown in \autoref{GP_toy_eks} I instruct my program to search for these parameters within a pre-specified distribution as presented in equation \ref{eq:dist_ell}, \ref{eq:dist_eta} and \ref{eq:dist_epsilon}.

\[
\ell \sim \text{Gamma}(5,2)  \tag{8}  \label{eq:dist_ell}
\]

\[
\eta \sim \text{HalfCauchy}(2)  \tag{9}  \label{eq:dist_eta}
\]

\[
\epsilon \sim \text{HalfCauchy}(5)  \tag{10}  \label{eq:dist_epsilon}
\]

Both the Gamma distribution and the Half-Cauchy distribution are simply probability distribution just as the Normal distribution. The difference is that they have different forms which makes them more suited for the tasks I assign them \citep[280-285]{Mcelreath_2018}. Understanding the nature and properties of these distributions is not necessary in order to appreciate the role they play: they serve as weakly regularizing priors, which merely discourage highly unrealistic values. These priors are easily overwhelmed by the patterns in the data, should the two not align. As such these priors only serve to increase computational efficiency and insure convergence \citep[35-36]{Mcelreath_2018}.\par 

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[scale=0.47]{GP_toy_eks.pdf}
%     \caption{\footnotesize{Three (generated) time-lines of conflict ridden geographical locations. $\ell$ = 3.64, $\eta$ = 2.54, $\epsilon$ = 0.51}\label{GP_toy_eks}}
% \end{figure}

% Concluding on the example:
In this toy example $\ell$ is estimated to be 3.64 with 95\% probability of being between 2.46 and 4.56. Thus, in this example it would be imprudent to extrapolate beyond year 2022 as indicated by the red line and shade in \autoref{GP_toy_eks}. Importantly, this hard limit is only a rule-of-thumb, here given by the mean estimate of $\ell$. The specific uncertainty should \textbf{always} be consulted in practice. In this example the uncertainty becomes extremely high after 2020. The mean of the three Gaussian processes are still valid estimates, but the prudent analyst should recognize that a "best guess" does not necessarily equal a "good guess". With this call for prudence in mind, \autoref{GP_toy_eks} does illustrate the potential of using Gaussian processes to model functions pertaining to the temporal pattern of conflict and how this framework allows easy extrapolation into future years.\par

% Changing to a spatial focus
To model the spatial pattern, I simply change the first dimension and include a second. That is instead of years, I use latitude and longitude. Here, the point is not to forecast into some unknown geographical space, but rather to let each observed cell incorporate information from all other cells in the data to estimate how exposed the given cell is to conflict. Naturally, the spatial and temporal patterns can also be combined into 3D space including two spatial and one temporal dimension, thus allowing for extrapolation of conflict exposure into future years.\par

% X_new
Having both estimated temporal patterns of conflict magnitude and conflict exposure, forecasting is simply a matter of introducing new future years $x_{new}$ to the time lines. Now we simply generate Gaussian processes over these elongated time lines. The data of each specific time line together with the covariance function and the estimated hyperparameters will guide how the function appears closest to the observed values, and the longer we stray from any observed value the more uncertainty will accumulate and the more influence the mean function will claim.\par 

% integration and differentiation:
Having functions extending into future years also allow for easy extrapolation of conflict \emph{slopes}, \emph{acceleration} and \emph{mass} through. In practice, the estimate I produce is not an actual formula for the function $f$ but merely the values generated by the function $f$. As such equation \ref{eq:slope}, \ref{eq:acc} and \ref{eq:mass} denotes what I derive and extract, but not the actual mathematical of computational operation used. $f'$, $f''$ and $F$ are simply measures derived from the function $mu$ -- which was simply is maximum likelihood estimate obtained over the Gaussian processes. As such, the values of these functions can also be used as individual features in a greater predictive framework.\par 
% should this be included in the criteria? 
%You should mention why it is theoriticly interesting nad potnetially usfulll

\[
\text{slope} = f'(x)   \tag{11}  \label{eq:slope}
\]

\[
\text{acceleration} = f''(x) \tag{12}  \label{eq:acc}
\]

\[
\text{mass} = F(x) \tag{13}  \label{eq:mass}
\]

%Another interesting potential of this approach is that we can also model a function as a combination of more functions; E.g. a short term trend and a long term trend \citep[505-510]{Gelman_2013}. In such a scenario the $\ell$ of a long term trend would be greater than the combined $\ell$ of both the short and the long term trend. It follows that the identifications of a long term trend would allow me to extrapolate further into the future with less uncertainty. Naturally, this is an opportunity which I shall take advantage of further on.\par

% Back to the criteria
Now, revisiting the criteria I presented earlier, we see that Gaussian processes fulfills them all. In regards to the temporal pattern, they allow incorporation of information drawn from all past (included) years with decreasing influence \citep[410-419]{Mcelreath_2018}. Furthermore, the rate with which past years influence the forecastings is estimated through the data itself. These properties are the reason why Gaussian processes are often used to model functions over time \citep[13]{williams2006gaussian} Furthermore, no arbitrary "splines" or "knots" needs defining, which is one reason it has been recommend as a substitute to linear decay functions \cite[501]{Gelman_2013}. In regards to the spatial dimension, utilizing Gaussian Processes on a disaggregated geographical grid allows us to analyze and model spatial patterns at arbitrarily high complexity levels only hampered by the resolution of the data and computational power available. We need not define the number of neighbours, since all observations are considered\footnote{That said, we could choose some appropriate subset to improve computation massively \citep{gelfand2016spatial} - but, this is a project for an other time.}. Furthermore, we do not have to guess the deterioration rate of influence since this is estimated. Lastly, using Gaussian processes to model spatial diffusion, a given geographical cell will be influenced directly by the pattern and magnitudes of conflict around it, in a manner similar to the conflict patterns identified by \cite{schutte2011diffusion}. High magnitude will translate to higher influence, as will encirclement compared to tangency. Indeed, these properties are part of what compelled \cite{gelfand2016spatial} to declare the union of spatial data and Gaussian processes a "beautiful marriage" \citep[86]{gelfand2016spatial}.

%In regards to the spatial pattern this is ..... \cite{schutte2011diffusion} MEN! husk noget med friedman as-if... Du laver ikke noget kausal studio og kikker ikke på nogen mekanisme, men du mener stadig man skal gå efter at emulerer den data generende process i det omfang man har insigt, teori og empiri der muliggøre det. 

% But there are some problems... Below zero and space as degrees is more important then count...
Notably however, while I have illustrated the potential of the approach, it should also be clear from \autoref{GP_toy_posterior} that the framework presented here is somewhat misspecified. Since my base measure for conflict is conflict fatalities logged, one could argue that I should treat the data as count data. Since I will not be using the extrapolations directly as estimations of death tolls, getting fractions of death is not the problem. Instead the issue is that I will incidentially estimate negative conflict magnitude and exposure. This will happen proceeding steep dives in temporal or spatial patterns.\par

% How cloud this be solved - and why it is not a problem
This could simply be handled by formulating the regression presented in equation \ref{eq:y} as a Poisson regression. This is conceptually trivial, but unfortunately much more computationally expensive and it introduces more complexity to an already complex endeavour. Somewhat encouragingly however, I ran initial tests which showed little to no difference when using a Poisson framework. The estimated $\mu$'s rarely dip below zero, and when they do, it is only marginally. As such, I allow this misspecification to persist for the purpose of simplicity and efficiency\footnote{A choice which is not unheard of  \cite[123]{williams2006gaussian}. A similar example can be found in \cite{Gelman_2013} chapter 21. Effectively, it is the same choice made every time a linear regression is used on count data such as death tolls, births, employment and indeed most data revolving around items or people.}.\par %your model is misspecified \cite[123]{williams2006gaussian}

% [Credibility inteval And baysian jazz?]\par++++++++++++++++++++++++

% Next section
The next section will briefly present the theoretical underpinnings of the predictive framework which will transform the patterns estimated to predictions.\par 

%small $\ell$ less noice. Large $\ell$ more noice \cite[115]{williams2006gaussian}
%computational burdensome \citep[503]{Gelman_2013}


\subsection{The predictive framework}
% not the central endeavour!
% Her til er du kommet.

%[GP kunne altså godt bruges some pred i sin egen ret, men...]

% Whats going down here mate?
Naturally Gaussian processes can be used as predictive models in themselves; after all we forecast expected values into future years. However, to combine these forecasted values of conflict magnitude, conflict exposure and the derived measures of slops, accelerations and mass into unified predictions of conflict probability, we need another tool. Indeed, Gaussian processes are often utilized as subcomponents in larger models \citep[505]{Gelman_2013}. A predictive framework suitable for the challenge at hand has been presented in \cite{Maase}. Since the nature of this framework is not a prime concern in this thesis, I will keep this presentation very brief and concise. A more in-depth presentation can be found in the original paper \citep[9-12]{Maase}.\par %While I here implement a number of improvements which I proposed in the conclusion of \cite{Maase} the setup is largely the same.

% The specific elements
The framework consists of a number of individual elements best introduced in turn. First of all we need some algorithm capable of using the patterns extracted to estimate the probability of an event. We know that conflicts are complicated phenomenas ridden with \emph{interactions} \citep[474]{cederman2017predicting}. Thus, the predictive algorithm needs to be able to identify and generate such interactions. Furthermore, we know that conflicts are rare events. As such, the algorithm also needs to be suitable for handling rare events. For the sake of both policy recommendations and theoretical discussion it is also important that the algorithm is not a \emph{black box}; we must be able to asses which "decisions" facilitate the results \cite[476]{cederman2017predicting}. Secondly, even an algorithm tuned for rare events can have difficulty handling the rarity of conflicts. As such I need tools which can mitigate some of the ills of imbalanced data. Finally, we need appropriate metrics for evaluating the potential of the endeavour as a whole. Metrics which again take into account the rarity of the event give us an honest evaluation of the predictive potential of the approach. In the following subsections I show how the \emph{extreme gradient boosting} algorithm, undersampling and the precision-recall curve can fulfill these roles.\par

%Bayesian Prior Correction ?

\subsubsection{Extreme Gradient Boosting}\label{xgboost}

% what is this shit?
The algorithm I use to estimate both the probability and magnitude of conflict is called extreme gradient boosting or simply \emph{xgboost} \citep{Chen_2016}. It is a machine learning algorithm somewhat more advanced than traditional regression analysis. Thus it can be constructed as a regressor to predict a number, similar to a linear regression, or as a classifier to predict probabilities, similar to a logistic regression. In this thesis, I will use it as a classifier to estimate the probability of future conflict in the individual grid cells.\par

% What will you say about it?
This is where the similarity between traditional regression analysis and xgboost cease. The xgboost algorithm is a rather new addition to the machine learning toolbox. Thus it is a more complex construct than most political scientist have traditionally been exposed to. Luckily, one does not need a deep technical understanding of the algorithm to appreciate its properties. As such, I shall refrain from getting into the technicalities of the algorithm. That being said, some base-intuition will serve to qualify why this algorithm works remarkable well in this context. Particularly three characteristics deserve attention; it is a \emph{boosting} algorithm; it consists of \emph{regression trees}; and it is \emph{self-regularizing}.\par

% boosting:
Boosting is used in a variety of machine learning algorithms and entails aggregating a lot of weak classifiers to create a single strong classifier \citep[337]{Friedman_2001}. To this end, we evaluate the results from the weak classifiers and on basis of these results we distribute different weights across our observations. We now run a new batch of classifiers but this time, the observations which were correctly predicted in the first round will carry less weight while observations which were incorrectly predicted will carry more weight. This procedure is iterated until some predefined criteria is met. Lastly, all classifiers are weighted according to their performance and used as a predictive ensemble to estimate the probability of some event \citep[338-339]{Friedman_2001}. This procedure ensures a continuing focus on "hard to classify"-observations, and as such it is a particularly useful approach when working with rare events.\par

% !!!!!!!!!!!!!!
% regression tress - interactions er pointen! så er spørgsmålet om du bruger for meget jazz på class/reg...
Naturally we need to decide which weak classifiers to use as the basis of our boosting. xgboost utilizes regression trees -- which strictly speaking are regressors and not a classifiers but in the xgboost algorithm they are used as classifiers in non-the-less \citep[786]{Chen_2016}. We use these regression tress to partition our data according to the split-points which best sort our data according to a predefined target \citep[786]{Chen_2016}. The reason the xgboost algorithm uses regression trees rather then decision trees, even for classification, is that each tree produces a continues score as oppose to a binary classification at the end of each branch. These score holds more information then a hard classifications and they can be added together across all trees before being normalized to probabilities and used for classification \cite[786]{Chen_2016}. Given my project, this means using my eight features to split grid cells experiencing conflict from cells that do not experience conflict. The features and specific split-points to be used are automatically found by identifying the splits that minimizes a specific \emph{objective function}\footnote{I  will not go into the mathematics of this function, but the curious reader can find it in \cite{Chen_2016} page 786.}\citep[786]{Chen_2016}. We keep splitting partitions until we fail to minimize the objective function further\citep[786]{Chen_2016}. What is crucial about this procedure, is that each split (apart from the very first) effectively constitutes an interaction. Thus the xgboost algorithm is able to automatically identify and generate the most salient interactions.\par
% Regression trees are related to the more traditional decision trees. Yet, unlike decision trees, regression a tree produces a continuous score, which can be converted into probabilities rather then the binary classifications of decision trees \citep[786]{Chen_2016}. 

% self-regularizing
A further features of the specific objective function is that is is self-regularizing for the purpose of mitigating overfitting. Specifically the objective function penalizes complex tree structures. Thus when the algorithm has to decide whether to create a new split nor not, it compares the potential improvement in prediction power to the added complexity. If the added complexity is deemed to great compared to the improvement in prediction power the split is not effectuated \cite[787-791]{Chen_2016}. Thus, the regression trees used in the boosting effort searches for relevant patterns in the data, but automatically stops before overfitting commence.\par

% but also a bit more
There are a large number of other regularization strategies and mechanism which also plays a part in the actual implementation of xgboost \citep[787]{Chen_2016}. However, to review them all is far beyond the scope of this project. Thus I move on to the final characteristics of the algorithm which needs introduction here. Its transparency.\par

% Feature imp.
Since the xgboost algorithm is based on tree structures, we can readily asses which splits generated most prediction power, and thus which features are most \emph{important} in regards to the combined prediction effort. Importance here meaning how much prediction power the specific feature contribute with, compared the the other features \citep[787-788]{Chen_2016}. As such, feature importance should be understood as a relative measure comparing how much information a specific features bring the the effort compared to the other features \cite[367-368]{Friedman_2001}. While this tells us nothing about causation, it is still highly relevant for guiding future prediction frameworks, informing theoretical debates pertaining to explanations and for formulation of concrete policy recommendations.\par

% Bridge - good for undersampling but no good enough
Naturally, this is a very superficial introduction to the xgboost algorithm; nevertheless it serves to illustrate why this algorithm is especially suited for the endeavour at hand. The boosting element makes the algorithm suitable for rare events and the fact that is is based on regressions trees both allows for automatic generation of interactions and for assessment of feature importance. Importantly, the specific trees used in this algorithm are self-regularizing thus discouraging overfitting. A suitable framework indeed. Yet I can still do more the. Particularly in regard to the imbalance of the data. The next section will introduce a number of \emph{undersampling} techniques which I implement to further tackle the rarity of conflict events.\par 

\subsubsection{Undersampling}
% Her til er du nået +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
%\todo[inline]{IN PROGRESS}

% what is Imbalance?
%"Specifically, this form of imbalance is referred to as a between-class imbalance; not uncommon are between class imbalances on the order of 100:1, 1,000:1, and 10,000:1, where in each case, one class severely outrepresents another [4], [5], [6]. [...]Imbalances of this form are commonly referred to as intrinsic , i.e., the imbalance is a direct result of the nature of the dataspace" \citep[1264]{He_2008}

% what is undersampling?
When our data is highly imbalanced, the predictive algorithm used often favors the classification of the majority class. In my case this would mean that the framework would be focused more on predicting the absence of conflict rather than the presence of actual conflict. Using a boosting algorithm such as xgboost does a good job of mitigating this problem -- yet there is still more I can do to ameliorating the issue further. A simple and logical solution is simply to undersample the majority class. As such in our train set we drop a portion of non-events to even the ratio between events and non-events. This is called undersampling \citep[1266-1267]{He_2008}.\par

%It is tempting to apply the same procedure to the testset, but since the test set is suppose to mimic an unknown future 

% What do you do? - 
Specifically I combine the two procedures \emph{case-cohort sampling} and \emph{informed undersampling}. Case-cohort sampling implies, that I train my model using all available events (present in the training set) together with a randomly drawn and equally sized set of non-events (also from the training set)  \citep[142]{King_Zeng_2001}. This procedure is usually justified by arguing that more information is stored in the events than in non-events \cite[139]{King_Zeng_2001}. While this may be true, I still discard a lot of potentially relevant information this way. To amend this "information-waste" I embed this approach in a variant of informed undersampling. Instead of just using one model with one random subset of non-events I use a large \emph{ensemble} of models each using a new random subset of non-events \cite[1267]{He_2008}. Specifically I run the xgboost algorithm 1000 times; each time with the full set of (training) events and a randomly drawn subset of (training) non-events. As such I am effectively estimating a distribution of the conflict probabilities for each cell thus taking advantage of all the information in events and non-events alike. I can then use the mean of these distributions as a maximun likelihood point estimate for the actual probability. Furthermore, given that I can also asses the variance of these distributions, I am also able to infer how certain I am of this point estimate.\par 

% Introducing the Baysian correction
One issue with this undersampling approach is that the specific probabilities produced will be somewhat inflated. After all each of the 1000 models run is train to believe that conflict is much more common than it actually is. This, however, can easily be amended using a \emph{Bayesian prior correction} akin to what is presented in \cite{King_Zeng_2001, king_zeng_2001b} and implemented in \cite{Goldstone_2010}. I use the overall probability of conflict in the last observed year in my training set: 2012. This is simply the ratio between events and non-events. I denote the share of events $Pr(E_{2012})$ and the share of non-events $Pr(NE_{2012})$. Then, denoting the estimated probabilities of an event in a specific cell at a specific year $Pr(E_{estimated})$; the corresponding estimated probabilities of a non-event $Pr(NE_{estimated})$; and the corrected probabilities of events as $Pr(E_{corrected})$ the correction can be expressed as follows:

\[
Pr(E_{corrected}) = \frac{Pr(E_{estimated}) \times Pr(E_{2012})}{Pr(E_{estimated}) \times Pr(E_{2012})+Pr(NE_{estimated} \times Pr(NE_{2012})} \tag{14} \label{eq:bayesC}
\]

% concluding on it:
This correction ensures that the probabilities estimated match the "empirical" probability of conflict given all the data at hand. Notably however, this does not make my framework more or less precise. The reason is that, if we want to turn our estimated probabilities into actually classifications we still need to set some probability threshold splitting our estimates dichotomous into predicted events and predicted non-events. This threshold is normally set at 0.5 (50\%), but this threshold is arbitrary as any other number would be \citep[890-891]{weidmann_ward_2010predicting}. Indeed, any such threshold should always be chosen with the specific subject and purpose in mind \citep[194]{Goldstone_2010}. As such, since the correction does not change the relative difference between the estimated probabilities, I could get the same binary classification both with and without the Bayesian correction if I just used two different thresholds. One high threshold for the uncorrected estimates, and one lower threshold for the corrected estimates. However, the probabilities obtained after the correction are still preferable since they incorporate information regarding actually conflict propensity present in the data. As such they correctly conform to how we usually understand probabilities. This is crucial, since I do not recommend using binary classification for decision-making purposes. The actual probabilities hold much more information and should always be consulted.\par

%bridge
Together, the xgboost algorithm and the undersampling approach do a good job of priming the framework for rare events. However, both efforts do so through the model training; the test data that we feed our model will still be imbalanced. We cannot undersample this data since its role is to emulate an unknown future. Undersampling it would imply that we already know which cells that will experience conflict. Unfortunately conventional evaluation matrices tends to evaluate models used on such imbalanced data too favorable \citep[1264]{He_2008}. The next section introduces the evaluation metrics which I use for this project, and qualify why these are appropriate for evaluating unbalanced data.\par


\subsection{Evaluating Predictions}
%\todo[inline]{TODO: Precision-recall curve}
%Samme som sidst, men må ikke fremstå som plagiat... Og denne gang skal du også have AUC med for at kunne sammenligne med andre efforts.

% The two different estimation efforts.
For the construction of my framework I use two layers of estimation. First, I use Gaussian processes to estimate the pattern of conflict magnitude and conflict exposure. Secondly, having extrapolated these patterns into future years and derived the corresponding slope, acceleration and mass, I use these patterns as features in my final predictive framework which is based on the xgboost algorithm and various undersampling methods. I will then use this final predictive framework to estimate the probability of future conflicts. Naturally to assess whether I truly captured any salient conflict patterns with the Gaussian processes I must evaluate how well the final predictive framework performs; how good my predictions actually are.\par

% Out-of-sample prediction
Given the predictive scope of my project, I employ out-of-sample prediction to evaluate the performance of my approach. Out-of-sample-prediction is implemented by using a subset of my data to train my predictive framework and an other subset to test the framework. Given that my goal is practical forecastings I use the last five years of my data as test set. As such, to construct the final predictive framework I use a target $y_{cmBinary}$ from the training set and the features I have constructed via Gaussian processes $X_{patterns}$ also from the training set. When I want to create prediction, I introduce the $X_{patternsEX}$ which I extrapolated into the test year to my predictive framework to produce out-of-sample predictions $\tilde{y}_{prob}$. These prediction can the be evaluated against the empirical observations $y_{cmBinary}$ contained in the test set.\par

% What are yo gonna do?
Now, having my predictions $\tilde{y}_{prob}$ (test set), and the empirical observations $y_{cmBinary}$ (test set) I need some metric which can capture how well  $\tilde{y}_{prob}$ fits $y_{cmBinary}$. There are a plethora of such metrics available. The metric I will primarily use is the \emph{precision-recall} curve and the three related metrics \emph{recall}, \emph{precision} and \emph{average precision}. However, to put these metrics into perspective I will also introduce the metrics \emph{accuracy} and the \emph{Receiver Operating Characteristic} curve along with the corresponding metric the \emph{Area Under the Curve} (AUC) score. The reason I include more then one metric well become apparent as I introduce each measure.\par

% Criteria for a good measure/why no hard threshold.
Naturally the metrics used must fit the challenge at hand; not least the fact that I am dealing with imbalanced data. Furthermore, many metrics require that I set some hard threshold partitioning my predictions into predicted events and predicted non-events. The framework I use, however, does not produce binary results but probabilities. As such $y_{cmBinary}$ might by binary  -- either $0$ or $1$ -- but $\tilde{y}_{prob}$ can take any value between $0$ and $1$. These probabilities are in themselves far more informative than a simple binary classification. As such the metrics I use should not depend on the formulation of some arbitrary threshold.\par 

% Introducing Acc and error/ the problem the Acc and error
The most commonly used metric for classification is \emph{accuracy}\footnote{or the inverse error-rate}. Accuracy simply denotes the proportion of correctly predicted observations. As such accuracy is easy to interpret and intuitively appealing. However, there are two problems. First of all, the measure requires that we choose a hard threshold. Secondly when the data is imbalanced we can achieve a rather high accuracy just by predicting in favor of the majority class every time. If conflict only happens 5\% of the time we can get an accuracy of 95\% by simply predicting that conflict never happens. As such accuracy is not very suited for imbalanced data \citep[1264]{He_2008}, and even though it is the most commonly known measure, I will not be using this metric going forward.\par

% Introducing AUC (and TO/TN/FN/FP)
The metric most commonly chosen to avoid the problems afflicting accuracy is the ROC-curve and the summarizing measure the AUC scores \citep[1277-1278]{He_2008}. The ROC curve circumvents the issue of a hard threshold by evaluating each possible threshold. Specifically the ROC curve denotes the trade-off between the \emph{true positive rate} ($TP_{rate}$) and the \emph{false positive rate} ($FP_{rate}$) by plotting the $TP_{rate}$ over the $FP_{rate}$. This curve can then be interpreted visually or summarized by the area under it; the AUC score\citep[1277-1278]{He_2008}. Denoting the actual number of negatives $N_C$ and the actual number of positives $P_C$, the rates can be expressed by equation \ref{eq:TPFP}.\par

\[
TP_{rate} = \frac{TP}{P_C};\quad FP_{rate}=\frac{FP}{N_C} \tag{15} \label{eq:TPFP}
\]

% concluding on AUC
As such the ROC curve does not require me to specify a hard threshold and it illustrates clearly the trade-off between true positives and false positives at all possible thresholds. Given these attributes it has been widely used in conflict studies \citep[14]{chadefaux2017conflict}, and even been coined as the "gold-standard" in this field \citep[366]{perry_2013}. 

% The problem with AUC in imbalanced problems - and why it is still here
However, while better suited for imbalanced data than accuracy, the ROC curve and AUC score tends to judge model-performance on highly imbalanced data too favorable \citep[1278]{He_2008}. Looking at equation \ref{eq:TPFP} it is clear that if we can increase $N_C$ without increasing the $FP$ rate we will get a better score. As such, including Antarctica would probably improve my results substantially. Antarctica would constitutes a large number of non-events ($N_C$) and given my focus on past conflict patterns my framework would never produce a false positive ($FP$) here, leading to a lower false positive rate ($FP_{rate}$).\par

% Why is it still here
Despite this weakness I will still report the AUC score. The simple reason is that the metric is widely used and rather commonly known. The ROC curve and AUC score are points of reference for most political scientist working with advanced quantitative methods and including the measure will make it easier to compare my project with past efforts. That being said we should move on to more appropriate metrics better suited for highly imbalanced data. Therefore, my main focus will be on the PR curve.\par

% Intorducing Precision, Recall, PR-curve and average precision.
The PR curve shares many similarities with the ROC curve. It also denotes the trade off between two measures, specifically \emph{recall} and \emph{precision}. Notably recall is just another name for the true positive rate $TP$, while precision denotes the rate of true positive out of all positives. As such, recall and
precision can be expressed as in equation \ref{eq:recall/precision}.\par% and \autoref{eq:precision}.\par 

\[
precision = \frac{TP}{TP+FP}; \quad recall = \frac{TP}{TP+FN} \tag{16} \label{eq:recall/precision}
\]

% \[
% recall = \frac{TP}{TP+FN} \tag{17} \label{eq:precision}
% \]

% int the equations:
It is clear that since $TP+FN = P_C$ recall is indeed simply the true positive rate. In substantial terms, precision denotes how many of my predicted events turn out to be actual events, while recall denotes how many of all actual events my predictions capture. These two measures are in themselves valid metrics and they are both highly relevant when dealing with imbalanced data. However, since these metrics rely on components such as $TP$'s, $FP$'s, $TN$'s and $FN$'s, both metrics require a hard threshold. However, Combining them in a curve for all possible thresholds eliminates the need for any hard threshold and concurrently summarizes both metrics neatly \citep[1287]{He_2008}.\par

% Average precision
The PR curve can be interpreted visually and also be summarized in a single measure called average precision ($AP$). This summarizing metric denotes a weighted mean of precision at each possible threshold. The weighting is the increase in recall from the previous threshold. Denoting recall $R$, precision $P$, and the different thresholds as $n$ the AP score can be expressed as seen in equation \ref{eq:ap}.\par

\[
AP = \sum_n (R_n-R_{n-1})P_n \tag{17} \label{eq:ap}
\]

% compared to AUC?
The AP score has a number of similarities with AUC and can be thought of as the area under the PR curve  \citep[349-350]{su2015relationship}. The key difference is that AP places more emphasis on identifying high probability events than identifying low probability events \citep[350]{su2015relationship}. The interpretation also differs from AUC. An AUC score of 0.5 denotes a classifier which is no better than random. This is not the case with AP where 0.5 can be a decent score depending on the context \citep[350-351]{su2015relationship}. Specifically, an approximation of the "random" baseline of AP is given the share of events \citep[132]{bestgen2015AP}. If the data is precisely balanced the baseline for the AP score is 0.5 just like the AUC score. If the data is imbalanced, say 5\% events versus 95\% non-events, the baseline for the AP score will be 0.05. As such, AP is a good summarizing measure for judging and comparing the predictive performance of models on imbalanced data without setting a hard threshold. I will use both measures to compare my results with the results presented in \cite{Maase} and to show how the predictive power of my framework changes as I move further into the future.\par

% The downside and the solution
The downside of AP is that it is not particularly interpretable on a substantive level. As such, to best present the potential of my framework in substantial terms I will use the AP score in tandem with recall and precision at various thresholds. In the same manner I will also use the components $TP$, $FP$, $FN$ and $TN$ for visualizations. This will naturally demand that I set some hard threshold. I use a threshold which generates a number of predicted events which roughly matches the number of actual events in the last observed year: 2012. This threshold is as arbitrary as any other hard threshold chosen, but it serves well to create interpretable visualizations. Together these measures will ensure both honest evaluation and interpretability of my framework.\par % you could also map with different thresholds....

% Bridge
Having presented the methods which I will use to construct my predictive framework, I will now move on to present the specific data which I use. As such the next section serves as the last primer before I present the implementation and the results.\par

\section{The Chosen Data}\label{data}% you have the essence in the introduction...

% Whats go happen here mate?
In this paper I use two data sources. A spatial grid which divides the world into cells is obtained from the PRIO grid database \citep{Tollefsen_2012} while the Upssala Conflict Data Program (UCDP) \citep{Sundberg_2013, Croicu_Sundberg_2017} provides all substantial data used. I will present each source in turn below.\par

\subsection{The PRIO grid}

%What PRIO DATAbase?
The PRIO grid database holds a large variety of features denoting wealth, mountains, ethnic discrimination and much more, partitioned at sub-national level. In this paper, I do not use any of these features. I only use the geographical base-grid which the database provides. Using a preconstructed base-grid not only save me the hassle of constructing my own grid, it also allows for PRIO grid features or data prime for the PRIO grid to be easily incorporated in future endeavours.\par

% What the PRIO gird
The PRIO grid is a global grid dividing the world -- excluding Greenland and Antarctica -- into grid cells of $0.5 \times 0.5$ decimal degrees, which corresponds to roughly $50km\times50km$ at the equator \citep[367]{Tollefsen_2012}. It is constructed as geo-spatial data and primed for collaboration with the UCDP data. As such merging and handling these two data sources is a trivial task. However, due to computational limitations I have chosen only to use a subset of the full globe. This subset is presented in \autoref{map_2017}.\par

% er tallen serif?
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{log_best_2012_samples.pdf}
    \caption{\footnotesize{Conflict fatalities (logged) from 2017 according to UCDP aggregated at the level of PRIO grid cells.}}\label{map_2017}
\end{figure}

%interpreate the map
In \autoref{map_2017} I have plotted all conflict fatalities (logged) classified by UCDP in 2017 aggregated at PRIO grid cell level in the chosen subset. While the exact boarders of the subset are rather arbitrary\footnote{north: 50*, south: -10*, east: 100*, west -20*}, I have aimed to capture as many conflicts as possible across the surveyed timespan in one continuous geographic area. As such, the subset encompasses more or less conflict-prone regions such as Balkan, Caucasus, Syrian, Iraq, Yemen, Palestine, Rwanda, Kashmir, Afghanistan, Nepal, Aceh, Sri Lanka, Rwanda, Mali, Nigeria and many more. With more computational power available, the rest of the globe could easily be incorporated into my framework.\par

% selecting on the dependable
Naturally, this is selection on the dependable variable, and as such it will lead to bias in any estimation effort \citep[129-130]{king1994designing}. However, I have no traditional parameters to estimate and no claim of effect or causality to make. Thus, since accurate prediction is the goal, selection on the dependable variable is less of a problem than with traditional estimation efforts. Furthermore, any ills could easily be handled through yet another Bayesian correction \citep[627-628]{King_Zeng_2001}. That being said, it would still be imprudent to extrapolate any insights I produce -- such as the estimated hyperparameters -- beyond the geographical scope of this project. Correspondingly, the probabilities I produce should be seen as conditional on the geographical subset under scrutiny.\par


% This precaution, however, is not enough. On one hand selecting a geographic area with relatively many conflicts is a way to battle the imbalance of the data. Indeed " the real information in the data lies much more with the ones than the zeros" \citep[139]{king_zeng_2001b}. One the other hand, however, our model will "believe" that conflict is much more common then it is. This is already a problem given the effort to battle to imbalance of the data as presented in \autoref{imbalanced} and thus the remedy the same already introduced; a baysian correction similar to that presented in \cite{King_Zeng_2001} and implemented in \cite{Goldstone_2010}.\par 
% Er det den ritige henvising?

% Having present, the context, the challenge, the tools and the data which I use, the next section while present the implementation.\par
% Bridge
With this call for prudence I now introduce the substantial data which I will use to capture the patterns of conflict magnitude and exposure.\par

\subsection{The UCDP data}

%\todo[inline]{Her du skal sige hvilket år der er test og hvilke der er train}
% Two layers; many different y and x's -> how to keep up?


% What is the UCDP?
My framework consists of two layers of estimations. First, I estimate the patterns of conflict magnitude and conflict exposure. Then I use these estimated patterns to estimate the probability of conflict in a cell at some future year. The only data I need for these two endeavours is data pertaining directly to the history of conflict patterns. For this I use the \emph{Uppsala Conflict Data Program} (UCDP) \citep{Sundberg_2013, Croicu_Sundberg_2017}. Specifically I utilize the UCDP Georeferenced Event Dataset (GED) Global version 18.1 \citep{UCDP_2017}. The data contains records of conflict fatalities and the corresponding coordinates and dates. I aggregate this data to yearly fatalities and utilize data from 1989 through 2017.\par 

% How is conflict fatalities defined
I define conflict fatalities using the minimal definition from UCDP. They include in their data all fatalities where "armed force was used by an organized actor against another organized actor, or against civilians, resulting in at least 1 direct death at a specific location and a specific date” \cite[9]{Croicu_Sundberg_2017}.\footnote{See definitions regarding "armed force" and "organized actor" page 10 and forth of \cite{Croicu_Sundberg_2017}.}\par 

% onlys intra
Since I limit my project to intra-state conflict, I only include estimates from incidents which do not include two different nations as the organized actors. What is left are all conflict fatalities induced by internal conflicts, civil strife and terror.\par

% what do you uses?
There are a number of interesting features included in the UCDP data. I only use the feature \emph{best}. This feature is defined as: "The best (most likely) estimate of total fatalities resulting from an event" \cite[7]{Croicu_Sundberg_2017}. To get my raw measure of conflict magnitude, used as a target in my pattern estimation efforts, I take the log of this measure.\par

\[
\text{conflict magnitude} = log(\text{conflict fatalities}) \tag{18} \label{eq:cm}
\]

% Why log?
The log-transformation is wanted since the data is highly skewed; across all years the majority of the cells experience no conflict fatalities, while a few cells experiences a lot of conflict fatalities. Furthermore a logged transformation mitigates the challenges of extreme outlets such as Rwanda 1994. For the final predictive effort I construct a binary target simply denoting whether or not a given cell is experiencing any conflict at all.\par

% Different y's and x'x
This measurement, conflict magnitude, aggregated at the yearly level and distributed across the PRIO grid is the basis of my whole framework. In the first layer it will be the target $y_{cm}$ as I estimate the patterns of conflict magnitude and years will constitute the single feature $x_{year}$. As I estimate the static conflict exposure for each year it will also be the target $y_{cm}$, while longitude and latitude will be the features $X_{ll}$. In the second layer, a binary transformation of conflict magnitude will constitute the target $y_{binary}$ when I estimate the probability of conflict using the last predictive frame work, while the features will be the eight features derived from the first estimation layer will constitute the features $X_{patterns}$.\par

% what will be test and what will be train?
Given that I am producing forecasting, I use the last five years of my data, 2013 through 2017 as test set, and all other years -- from 1989 through 2012 -- as my training set. As such, I use a ratio of roughly 20\% for the test set, which is rather conventional \citep{Friedman_2001, Ward_Greenhill_Bakke_2010}.\par

% MEN SKAL DET HER ST HERÅ? +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
% Illustratively, in \cite{Maase} I used the PRIO grid database to obtain the structural features at a disaggregated sub-national level \citep{Tollefsen_2012}. This database holds a plethora of interesting features at disaggregated sub-national level, most with some relevance in regards to conflict prediction.. The database is indeed impressive, yet the challenge of using this data - and indeed most data like it - for forecasting, is that it takes researchers a lot of time to collected, process and make accessible. Both for the researches at PRIO and the researches responsible at each original source. At the time of writing - 2019 - the most up-to-date features have the last entry at 2015, while some have last entry at 2010; a five to ten year lag if I want to predict the conflict zones of 2020. This is less than optimal to say the least. Even if one where to bypass the Prio Grid database and go directly to the different original sources of data, much would still be lagging, and it would be a huge burden to collect, clean and merge these various data sources.\par

% Conversely, for data relating to the spatial/temporal pattern of conflict we only need one data source; on pertaining to when and where conflict has taken place in the past, e.g. the UCDP. At the time of writing the last entry in the UCDP is from 2017, and the given past history the entry for 2018 is due sometime doing the first half of 2019. A clear advantage compared the the PRIO gird database. As such, I might not be able to use data from 2019 to predict events in 2020, but I would be able to use data from 2018 to predict events in 2020 and onwards; a manageable two year lag.\par
% +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%bridge 
Having presented the context of my project, the tools I employ and the data used, I now move on to the actual creation of my framework.\par

%In the next section I will estimate and extraplote the patterns of conflict magnitude and conflcit exposure 

\section{Compiling the framework}% Better name?

% What is gonna happen here?
The following section is divided into two subsections corresponding to the two layers of estimation I employ. Firstly, I estimate the temporal and spatial patterns of conflict using my test set and Gaussian processes. These patterns will then be extrapolated into future years corresponding to those of the test set. From these elongated times lines I will derive the slope and acceleration pertaining to each year, along with the total conflict mass inhabiting each time line. This yields eight features. Secondly, using xgboost and undersampling, these eight features will be combined in my final predictive framework to estimate the probabilities of conflict in each individual grid cell given the test years from 2013 through 2017. An overview of the two layers of estimations is presented in \autoref{overview}.\par

% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{1cm} m{1.8cm} m{6cm} m{0.2cm} m{4cm}}
	%\hline
	\textbf{Estimations}
	\\Overveiw\\
	\hline
    & Target $(y)$                            &  Features $(x/X)$                    && Estimate $(\tilde{y})$  \\
	\hline
	\\
	\thead{\\}                  &$y_{cm}$                                & $x_{year}$                           && $\tilde{y}_{cm} = f_{cm}(x_{year}) + \epsilon_{cm}$        \\
    \thead{First\\layer}        &$y_{cm}$                                & $X_{ll} =$ $x_{long}$, $x_{lat}$       && $\tilde{y}_{sce} = f_{sce}(X_{ll}) + \epsilon_{sce}$           \\
    \thead{\\}                  &$f_{sce}(X_{ll})$                       & $x_{year}$                           && $\tilde{y}_{dce} = f_{dce}(x_{year}) + \epsilon_{dce}$        \\
    \\
    \hline
    \\
    \thead{Second\\layer}       &$y_{cmBinary}$                           & $X_{patterns} =$  $f_{cm}(x_{year})$, $f'_{cm}(x_{year})$, $f''_{cm}(x_{year})$, $F_{cm}(x_{year})$, $f_{dce}(x_{year})$, $f'_{dce}(x_{year})$, $f''_{dce}(x_{year})$, $F_{dce}(x_{year})$     &&$\tilde{y}_{prob}$ \\
    \\
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{Targets, features and estimates pertaining to the various estimation efforts in the two next sections. For brevity I omit the extrapolations in the table}}\label{overview}
\end{table} 

% Math will be in the appendix
% or? 

% Afterwards
% In the proceeding section I will then present the results and evaluate the performance of my approach. That is; assessing whether or not I have actually identified and extracted conflict patterns which can be used to predict the time and place of future conflicts. 

%\todo[inline]{Why the two baseline conflict exposure and conflict magnitude}
%\todo[inline]{Why the there derived measures: slope, accelaration and mass?}

\subsection{First layer: Patterns as features}
%[HERTIL ER DU KOMMET!!!]+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

%First I will estimate the temporal and spatial patterns of conflict in each grid cell at all years in included in the train set using Gaussian processes. These patterns will then be extrapolated into future years corresponding to those of the test set. From these elongated times lines I will then derive the corresponding slope and acceleration pertaining to each year, along with the total conflict mass inhabiting each time line.

% Whats gonna happend here mate
In the final predictive framework I will use eight features. All eight features pertain directly to the temporal and spatial patterns of conflict. The construction of these eight features is my objective in this subsection. I derive all features from two base functions; $f_{cm}$ and $f_{dce}$, both estimated using Gaussian processes. These two functions will respectively be an estimate of the pattern of conflict magnitude $cm$ and the pattern of conflict exposure $dce$. The two base functions are estimated using the training time line of each geografical grid cell. Having estimated the two functions of each grid cell, I extrapolate these into the "future" test years. This gives me two base function for each grid cell covering all included years; both training years and the test years. From each of these base function $f$ three more features are derived; $f'$, $f''$, $F$. The value of each of the two base functions $f$ at any given year constitutes a feature; so does the slope of the function $f'$ that year, the accelaration of the function $f''$ that year and the total mass under the function $F$ given all (training) years. Together, this constitutes the eight features $X_{patterns}$ used in the final predictive framework.\par 

% in wht order
To construct these eight features, I start by estimating and extrapolating the function pertaining to conflict magnitude $f_{cm}$. I then move on to estimating and extrapolating the function pertaining to conflict exposure $f_{dce}$. Finally I derive the slope, accelaration and mass corresponding to each of these two base function.\par

% Esitmateing cm
To estimate the function pertaining to conflict magnitude via Gaussian processes I simply use conflict fatalities logged as my target $y_{cm}$ and the years in my training set as the sole feature $x_{year}$. The mean function $m_{cm}$ is simply a constant $0$ and the covariance function $k_{cm}$ is the squared exponential function. Mathematically this is expessed in the equations \ref{eq:form_cm}, \ref{eq:func_cm}, \ref{eq:m_cm} and \ref{eq:k_cm}. All corresponding priors can be found in the appendix, \autoref{cmPrior}.\par

\[
\tilde{y}_{cm} = f_{cm}(x_{year}) + \epsilon_{cm} \tag{19} \label{eq:form_cm}
\]

\[
f_{cm}(x_{year}) \sim \mathcal{GP}_{cm}(m_{cm}(x_{year}),k_{cm}(x_{year},x_{year}')) \tag{20} \label{eq:func_cm}
\]

\[
m_{cm}(x_{year}) = 0 \tag{21} \label{eq:m_cm}
\]

\[
k_{cm}(x_{year},x_{year}') = \eta_{cm}^2 exp\left(-\frac{|x_{year}-x_{year}'|^2}{2\ell_{cm}^2}\right) \tag{22} \label{eq:k_cm}
\]

% hyper parameters and sample
I first estimate the hyperparameters $\eta_{cm}$ and $\ell_{cm}$ along with the error term $\epsilon_{cm}$ using time lines with two or more years of conflict. I then introduce $x_{yearNew}$ which is simply a vector of all years; training and test alike. Using the estimated hyper parameters and the data contained in the training set I now generate Guassian processes for each time line acorss all years included in $x_{yearNew}$. The estimated hyperparameters can be found in \autoref{cm_hp} and an illustrative sample of 15 estimated functions and corresponding time-lines can be seen in \autoref{cm_sampel_eks}.

% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{3cm} m{3cm} m{3cm} m{3cm}}
	%\hline
	\textbf{Hyperparameters}\\
	\text{Conflict magnitude}\\
	\hline
                            &  \thead{Point estimate\\(mean)}   & \thead{Standard\\deviation}   & \thead{95\% Credibility\\interval} \\
	\hline
	$\ell_{cm}$             & \thead{3.56}        & \thead{0.24} 	& \thead{3.08 - 3.99}                             \\
    $\eta_{cm}$             & \thead{1.36}        & \thead{0.04} 	& \thead{1.26 - 1.39}                             \\
    $\epsilon_{cm}$         & \thead{0.95}        & \thead{0.02} 	& \thead{0.91 - 0.98}                             \\
  
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{The tabel contains the estimated hyperparemeters pertaining to $\tilde{y}_{cm}$. }}\label{cm_hp}
\end{table}

% Int. the estimated hps
The most informative entry in \autoref{cm_hp} is the lenghtscale $\ell_{cm}$. Given the data and my model specifications there is a 95\% probability that $\ell_{cm}$ lies between 3 and 4 with my point estimate being 3.6. As such, the patterns I extract should be somewhat reliable until three years past my last observation. Thus, given that my training set ends at 2012, I expect my prediction power to drop substantially beyond 2015. \par% In \autoref{cm_sampel_eks} I have shade all years beyond the last observation in gray while all observations beyond the last observation $+\ell_{cm}$ are shaded red.\par

% eta and epsilon. Not that big difference. = maybe short and long term?
The error term $\epsilon$ and the amplitude $\eta$ are most informative when assessed in tandem. Given the ratio between $\eta$ and $\epsilon$ it appears that my estimated functions are able to explain well over half of the variations in the data. This is an early indication that conflict patterns can indeed be captured. On the other hand it also shows that there is still a lot of variation not captured by my estimated functions.\par %and? Men du vil jo heller ikke fange alt? Det ville være overfitting

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{cm_15_samples.pdf}
    \caption{\footnotesize{The estimated temporal patterns of conflict magnitude from fifteen randomly drawn time lines. For visualization purposes all fifteen samples has minimum one event over the course of the train years. The solid line is the maximum likelihood point estimate of $\mu_{cm}$ and the corrosponding shading denotes $2\times\sigma_{cm}$. At such, given the model and the data there is a 95\% that $\mu_{cm}$ is within this zone. The scatter points are the actual observed $y_{cm}$ values from the test set. $\ell_{cm}$ = 3.6, $\eta_{cm}$ = 1.1, $\epsilon_{cm}$ = 0.9}\label{cm_sampel_eks}}
\end{figure}

% Int. the samples  -> critaria for good temporal patterns.-> whats the point?
Turning from the hyperparameters to the actual estimated functions; \autoref{cm_sampel_eks} shows a sample of 15 randomly drawn time lines and their corresponding functions $f_{cm}$. These functions have been extrapolated to cover all years; $x_{yearNew}$. As such, the estimated functions continue beyond the training years 1989-2012 into the test years 2013-2017 guided by past (training) data, the covariance function $k_{cm}$, the mean function $m_{cm}$ together with the estimated error term and hyperparameters $\epsilon_{cm}$, $\ell_{cm}$ and $\eta_{cm}$. Thus, what I illustrate with the small sample in \autoref{cm_sampel_eks} is how conflict has waxed and waned in the geographical grid cells over the course of the training years, and how this pattern can be expected to continue into the test years given the data and model specification employed.\par 

%What about the critarias?\par
The samples in \autoref{cm_sampel_eks} illustrates in practice how the criteria for theoretical coherent (temporal) conflict patterns are fulfilled by using Gaussian processes. Information is drawn from all past included years; the volatility of past conflict impact the magnitude of estimated future conflicts; the influence of past observations decline over time; and the deterioration rate of influence is estimated, as opposed to guessed at.\par

% What it does not capture: two steps ot ammend
The functions $f_{cm}$ only captures the temporal patterns. To capture the spatial patterns more explicitly I need $f_{dce}$. But to get this function I must first estimate a 2D Gaussian process for each separate year in the training set using longitude and latitude as features ($x_{lat}$, $x_{long}$: $X_{ll}$) and conflict magnitude ($y_{cm}$) as target. This is the measure static conflict exposure ($sce$). It is "static" since I have yet to take time into account - the measure simply tells us how exposed a given cell is to conflict in a given year, without taking into account any temporal patterns. Secondly, I simply estimate a 1d Gaussian process similar to that already implemented to estimate $\tilde{y}_{cm}$. Once more I use $x_{year}$ as the sole feature, but instead of conflict magnitude ($y_{cm}$) as target, I use the values obtained through $f_{sce}$ as my target $y_{dce}$. The estimate I derive is one of dynamic conflict exposure $\tilde{y}_{dce}$. Instead of only taking into account the past patterns of the individual cell, this measure takes into account the past patterns of all cells in the relevant vicinity.\par 

% SCE
Starting with the first step I estimate the shared hyperparameters and error term $\ell_{sce}$, $\eta_{sce}$ and $\epsilon_{sce}$ for a 2D Gaussian process pertaining to the spatial conflict patterns pertaining to each specific year in the training set. Conflict magnitude is my target $y_{cm}$ and I use longitude $x_{long}$ and latitude $x_{lat}$ as the features $X_{ll}$. This gives me an estimate of static conflict exposure $\tilde{y}_{sce}$. The mathematical notation can be found in equations \ref{eq:form_sce}, \ref{eq:func_sce}, \ref{eq:m_sce} and \ref{eq:k_sce}.  The priors for $\epsilon_{sce}$, $\eta_{sce}$, $\ell_{sce}$ can all be found in the appendix, \autoref{scePrior}.\par

\[
\widetilde{log(CF)} = f_{sce}(X_{ll}) + \epsilon_{sce} \tag{23} \label{eq:form_sce}
\]

\[
f_{sce}(X) \sim \mathcal{GP}_{sce}(m_{sce}(X_{ll}),k_{sce}(X_{ll},X_{ll}')) \tag{24} \label{eq:func_sce}
\]

\[
m_{sce}(X_{ll}) = 0 \tag{25} \label{eq:m_sce}
\]

\[
k_{sce}(X_{ll},X_{ll}') = \eta_{sce}^2 exp\left(-\frac{|X_{ll}-X_{ll}'|^2}{2\ell_{sce}^2}\right) \tag{26} \label{eq:k_sce}
\]

% hyper parameters and sample
As before, I first estimate the hyperparameters and error term $\eta_{sce}$, $\ell_{sce}$, $\epsilon_{sce}$. Since I have only estimated the function over spatial dimensions I cannot extrapolate into future year $x_{yearsNew}$ (yet) and I have no intention of extrapolating the patterns into unknown geografical regions so I do not introduce any $X_{llNew}$. The estimated hyperparameters and error term can be found in \autoref{sce_hp}. To visualize the output, the static conflict patterns pertaining to 2012 are plotted in \autoref{sce_sampel_eks}.\par


% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{3cm} m{3cm} m{3cm} m{3cm}}
	%\hline
	\textbf{Hyperparameters}\\
	\text{Static conflict exposure}\\
	\hline
                            &  \thead{Point estimate\\(mean)}   & \thead{Standard\\deviation}   & \thead{95\% Credibility\\interval} \\
	\hline
	$\ell_{sce}$             & \thead{1.33}        & \thead{0.02} 	    & \thead{1.26 - 1.39}                             \\
    $\eta_{sce}$             & \thead{0.20}        & \thead{$<$0.01} 	& \thead{0.19 - 0.20}                             \\
    $\epsilon_{sce}$         & \thead{0.48}        & \thead{$<$0.01} 	& \thead{0.47 - 0.48}                             \\
  
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{The tabel contains the estimated hyperparemeters pertaining to $\tilde{y}_{sce}$. }}\label{sce_hp}
\end{table}

% Int. the estimated hps
Looking at the hyperparameters, the most informative is once again the lenghtscale $\ell_{sce}$. There is a 95\% probability that $\ell_{sce}$ is between 1.2 and 1.4 with my point estimate being 1.3. In substantial terms this tells us that conflict magnitude is relatively stable within a radius of roughly 130 kilometers. To illustrate the actual spatial patterns estimated I have plotted the obtained $\tilde{y}_{sce}$ values pertaining to 2012 in \autoref{sce_sampel_eks}. Similar, but unconnected, output is estimated for all years in the training set.\par

% Something about eta and epsilon - eta is smaller then epsilon.. That is somthing to comment on. A lot of things cell specific stuf is not captured here.  But we also wants general patterns
The ratio between $\eta$ and $\epsilon$ tells us that there is a lot of variation not explained by our 2D function. Indeed, with $\epsilon$ being twice as large as $\eta$ it appears my function only captures $1/3$ of the total variation in conflict exposure. There are two simple reasons why this is not overly surprising. First of all there are many unknown/unincluded factors separating the different cells from each other. One cell might include a major city, another a great lake. One might be inhabited by a wealthy elite and another by a marginalized and/or poor minority. Secondly, just because a cell did not experience conflict, it does not mean that there was no risk of conflict. What the four features pertaining to the spatial patterns of conflict are meant to capture is not whether or not a given cell experience conflict, but simply whether or not it is exposed to conflict. Thus this ratio poses no apparent problem.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{sce_2012_samples.pdf}
    \caption{\footnotesize{LOREM IPSUM}}\label{sce_sampel_eks}
\end{figure}

%Int the plot. -> critaria for good spatial patterns.-> whats the point?
What I illustrate in \autoref{sce_sampel_eks} is simply an estimated 2D function over the conflict magnitude of all cells in 2012. We see that the spatial patterns estimated conforms neatly to the theoretical expectation regarding spatial conflict patterns. Information is drawn from all relevant events in the specific year, taking into account both the magnitude and the distance of said events, the deterioration rate of influence is estimated from the available data; conflict diffusion appears fundamentally bell-shaped and radiates out from specific centers. Further, looking at examples such as Nigeria, Somalia and especially Afghanistan we also see how patterns such as circulation produces different results compared to tangency.\par  

% Moving on to dce.
To connected this measure across time and facilitate extrapolation into future years the next step is to estimate $\tilde{y}_{dce}$. To this end, I simply repeat the steps taken to estimate $\tilde{y}_{cm}$. Now, instead of using $y_{cm}$ as target I use the estimated values obtained from $f_{sce}(X_{ll})$ as my target. I denote this estimate $\tilde{y}_{dce}$. Beyond that small change, the procedure is identical. The mathematical specifications are presented in equation \ref{eq:form_dce}, \ref{eq:func_dce}, \ref{eq:m_dce} and \ref{eq:k_dce}. The priors for $\epsilon_{dce}$, $\eta_{dce}$, $\ell_{dce}$ can be found in the appendix, \autoref{dcePrior}.\par

\[
\tilde{y}_{dce} = f_{dce}(x_{year}) + \epsilon_{dce} \tag{27} \label{eq:form_dce}
\]

\[
f_{dce}(x_{year}) \sim \mathcal{GP}_{dce}(m_{dce}(x_{year}),k_{dce}(x_{year},x_{year}')) \tag{28} \label{eq:func_dce}
\]

\[
m_{dce}(x_{year}) = 0 \tag{21} \label{eq:m_dce}
\]

\[
k_{dce}(x_{year},x_{year}') = \eta_{dce}^2 exp\left(-\frac{|x_{year}-x_{year}'|^2}{2\ell_{dce}^2}\right) \tag{29} \label{eq:k_dce}
\]

% hyper parameters and sample
I estimate the relevant hyperparameters $\eta_{dce}$ and $\ell_{dce}$ and the error term ($\epsilon_{dce}$). The patterns are then extrapolated into the test years using $x_{yearNew}$. I present the estimated hyperparemeters in \autoref{dce_hp}. To illustrate the estimated patterns I draw 15 adjacent time lines which are plotted in \autoref{dce_sampel_eks}.\par 

% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{3cm} m{3cm} m{3cm} m{3cm}}
	%\hline
	\textbf{Hyperparameters}\\
	\text{Dynamic conflict exposure}\\
	\hline
                            &  \thead{Point estimate\\(mean)}   & \thead{Standard\\deviation}   & \thead{95\% Credibility\\interval} \\
	\hline
	$\ell_{dce}$             & \thead{3.23}        & \thead{0.13} 	& \thead{2.99 - 3.50}                             \\
    $\eta_{dce}$             & \thead{0.59}        & \thead{0.01} 	& \thead{0.55 - 0.62}                             \\
    $\epsilon_{dce}$         & \thead{0.23}        & \thead{0.01} 	& \thead{0.22 - 0.23}                             \\
  
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{The tabel contains the estimated hyperparemeters pertaining to $\tilde{y}_{dce}$. }}\label{dce_hp}
\end{table}


% Int the hyperparameters
We see that $\ell_{dce}$ has a 95\% probability of being between 3 and 3.5 with a point estimate of 3.2. As such this result is very similar to that of $\ell_{cm}$. Again, I only expect my results to be reliable three years into the future. A sample of the estimated patterns is presented in \autoref{dce_sampel_eks}.\par

% eta and epsilon...
% The two oher estimates for $\epsilon$ and $\eta$ are less simple to interpreate here since, a lot of noise have allready been removed estimating $\tilde{y}_{sce}$.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{dce_15_samples.pdf}
    \caption{\footnotesize{The estimated temporal patterns of conflict exposure from fifteen randomly drawn adjacent time lines. The solid line is the maximum likelihood point estimate of $\mu_{dce}$ and the corrosponding shading denotes $2\times\sigma_{dce}$. At such, given the model there is a 95\% that $\mu_{cde}$ is within this zone. The colors of the lines denotes how close the time lines are in space. More similar colors equals more proximate cells. The scatter points are the target values obtained through $f_{sce}$. $\ell_{dce}$ = 3.2, $\eta_{dce}$ = 0.59, $\epsilon_{dce}$ = 0.2}}\label{dce_sampel_eks}
\end{figure}

% Int the figure  -> critaria for good spatial patterns. -> whats the point?
By drawing adjacent samples, the spatial dimension of conflict exposure becomes easily discernible. As such, even though I have not explicitly plotted the spatial dimension in \autoref{dce_sampel_eks}, it is still clearly visible. Each timeline is influenced by all proximate timelines with declining impact as distance grows. Again, the product aligns gracefully with our theoretical criteria regarding conflict patterns.\par

% Two base measures. bridge
I now have my two base measures $f_{cm}$ and $f_{dce}$. Both these measure are estimated using my training set and have then been extrapolated into the "future" test years. As such it is now a trivial task to further extract the corresponding slopes ($f'_{cm}$ and $f'_{dce}$), accelerations ($f''_{cm}$ and $f''_{dce}$) and masses ($F_{cm}$ and $F_{dce}$). With this done I have created all eight features which I will use to capture the patterns of conflict.\par

% The new split 
The last step here is to split the features according to the training and test set. As such all feature values pertaining to the training years from 1998 through 2012 ($X_{patterns}$) are appended to the train set, while the extrapolated feature values from 2013 through 2017 ($X_{patternsEX}$) are appended to the test set. Importantly, the target values in the test set have still not been used for any estimations, computations or model training. As such, the process still emulates a real world forecasting scenario where we are able to extrapolate patterns based on past observations, but not use any information pertaining to future results. With all features constructed and the data-split completed, I now move on to test the combined predictive power of these features using the final predictive framework.\par

\subsection{Second layer: Predicting conflicts}
% \todo[inline]{todo}

% Whats going to happen here mate?
% In this short subsection I will briefly describe how I use the eight constructed features in the final predictive framework to create out-of-sample predictions. I then evaluate these predictions in the proceeding section.\par

% what goes ind nad what does not go ind.
To train the models, I employ the features $X_{patterns}$ and a binary conflict indicator $y_{binary}$ as the target - naturally only the set pertaining to the training years. As such, $X_{patterns}$ contains the values of all eight features from 1989 through 2012 and $y_{binary}$ is a binary indicator denoting whether or not a given cell experienced any conflict in some given year between 1989 and 2012. This constitutes the training data. The test data, which holds the extrapolated $X_{patternsEX}$ and the out-of-sample prediction target $y_{binary}$ values from 2013 through 2017 are kept isolated from the model construction effort and not used before the evaluation effort.\par

% what happens with what goes ind
I train 1000 xgboost models using the training data. Every model uses the complete set of events from the training set along with an equally sized set of randomly drawn non-events, also from the training set. Every time a single model is finished training I use the model to generate out-of-sample predictions $\tilde{y}_{pred}$ by introducing the $X_{patternsEX}$ from the test set. As such, combining all 1000 predictions pertaining to one cell in one given year, I obtain a probability distribution of predictions. \par

%A most likely estimate of the predicted probability can be obtain from this distribution along with the an estimate of the variance of the distributions.\par
%[can be programmed better]


% What comes out
The genereated predictions are expressed as probabilities. Specifically, probabilities that some given grid cell will experience conflict the specific (test) year. As such the full outputs are probability distributions of probabilities. The individual probabilities are adjusted via Bayesian correction to account for the undersampling technique and a maximum likelihood estimate is obtained from each individual distribution of probabilities. Given that the distributions appear Gaussian, the maximum likelihood estimate is simply the mean and represents my best guess of what the probability of conflict is in a given cell, in a specific year.\par 

%[evt. fig eks?]

% Bridge
To evaluate to what extent my framework, and as such the features I have created, have successfully captured the patterns of conflict, I will now compare these probabilities to the actual observations contained in the test set $y_{binaryTest}$. The results will be presented in the next section.\par

\section{The Results}
% [Analysis]
% I virkeligheden mest bare resultaterne; start bare hård med et resultat.

% Whats gonna happen here.
In the preceding sections I have shown how we can estimate and extrapolate the temporal and geo-spatial patterns of past conflicts using modern machine learning techniques. However, I have yet to demonstrate whether these estimated patterns hold any predictive power -- whether they can actually by used to forecast the time and place of future conflicts. In the following section I will evaluate the predictive performance of my approach in order to assess the extent to which the constructed features hold prediction power pertaining to time and place of future conflicts. Further more I will briefly asses which of my eight included features holds the most prediction power.\par 
%RQ: How can we use effectivly the temporal and geo-spatial patterns of past conflicts to forecast and predict the time and place of future conflicts?

\subsection{The predictive potential}

% How
To best convey the potential of my framework, I will evaluate it from a number of angles starting with the PR-curve, the AP score, and the ROC-AUC score. Then, I will set a threshold which will be used to convert my predicted probabilities to binary predictions. From these binary predictions I derive the rates of true positives, false positives, true negatives and false negatives as well as the related measures precision and recall. Finally I evaluate the relative importance of the eight features used in the framework.\par

% AP over time
The AP score is the prime evaluation metric of interest. Since I have a distribution of predictions, I naturally also have distributions of results. In \autoref{ap_scores} I show the distributions of estimated out-of-sample AP scores for each of the test years used with point estimates simply being the mean. As expected the performance of my framework changes as I move into the future. Specifically -- and as foretold by the lenghtscales $\ell_{cm}$ and $\ell_{dce}$ -- the performance drops substantially beyond 3 years. This is easily seen in \autoref{ap_trend} and \autoref{ap_scores} as the AP scores fall subtantially after 2015.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{ap_trend_alt.pdf}
    \caption{\footnotesize{The trend in average precision as it changes over the test years. The orange line denotes the maximum likelihood estimate (mean). The blue shade denotes the actual 1000 estimates per year.}}\label{ap_trend}
\end{figure}

\autoref{ap_trend} shows how the AP score change over the test years from 0.55 in 2013 down to 42 in 2013. The orange line is the maximun likelihood estimate of the AP given all the models and blue shade is the individual estimates. This is further illustrated in \autoref{ap_scores}.\par


\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{ap_scores.pdf}
    \caption{\footnotesize{Average precision distributions across all test years. Each distribution is base on the results from 1000 models}}\label{ap_scores}
\end{figure}

% the trend
As such it is clear that is a substantial difference between my prediction power before 2015 and after. Indeed, \autoref{ap_scores} show practically no overlap between 2013, 2014 and 2015 on one side and 2016 and 2017 on the other. Looking at the actual numbers, out of all the models run, no model from 2013, 2014 and 2015 did as bad or worse then any model from 2016 or 2017. This leaves us a probability of $<0.001\%$ that our framework will performer as well after 3 years as before. For comparison there is a 2.4\% probability that $AP_{2015} \geq AP_{2013}$ and a 89.3\% probability that $AP_{2015} \geq AP_{2014}$. The point is that the lenghtscale indeed does provide powerful guidance regarding how far we can look into the future, and it should be taken quite seriously doing any real world application.\par

% Regarding why 2015 is better then 2014!
Naturally, it might seem a bit odd that my model seem to do better in 2015 then in 2014. Intuitively the predictive power of the framework should always decrease somewhat when going further into the future, or at least stay the same. As I will go future into below this is neither a flaw or a mystery. It is simply do to the fact the the patterns of 2015 coincidentally aligns more with the patterns of 2012 -- the last train year -- the 2014 does. As such, this is not a pattern I would expect to generalize beyond these particular years.\par 

%selected years
Now, given these results and to keep the evaluation effort concise I will not spend more time evaluating the two last test years 2016 and 2017. To mirror the challenges of real world applications I also ignore the first test year 2013. After all, the data used to train the models would not have been available before June 2013, and thus predictions regarding conflicts in 2013 would have been of limited use. Further more, any relevant actor -- political or otherwise -- needs some reaction time to take any forecasting into account. As such I focus on the years 2014 and 2015, respectively 6 and 18 months into the future from when the data would first have been available for analysis.\par

% PR-curve and ap score ( ROC and AUC..) for 
The PR-curve and the AP score for the years 2014 and 2015 are presented in \autoref{pr_curves} while the corresponding ROC-curves and AUC scores are presented in \autoref{roc_curves}.\par 

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{pr_curves_14_15.pdf}%insert baseline
    \caption{\footnotesize{The precision-recall curve for the years 2014 and 2015. The orange line is the maximun likelihood point estimate while the blue shade represents the 0.99 credibility interval.}}\label{pr_curves}
\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{roc_curves_14_15.pdf}
    \caption{\footnotesize{The receiver operating characteristic curve for the years 2014 and 2015. The orange line is the maximun likelihood point estimate while the blue shade represents the 0.99 credibility interval.}}\label{roc_curves}
\end{figure}

% Int the PR-curve and ROC curve
The PR-curve in \autoref{pr_curves} illustrates the trade-off between recall and precision at various probability thresholds between 0 and 1, while the ROC-curve in \autoref{roc_curves} denotes the relationship between the false positive rate and the true positive rate at various thresholds. The share of events in both 2014 and 2015 is respectively 0.050 and 0.053. As such an AP score around 0.05 and AUC score at 0.5 is equivalent to random guesses. As such, with AP scores of 0.51 and 0.52, and AUC scores of 0.91 and 0.91 (point estimates) it is clear that the features I produced exhibit considerable predictive power. The question is how this prediction power holds up compared to other efforts using different approaches.\par

% compare with last assignment 
Intriguingly, the results presented here are better than those produced in \cite{Maase}. Specifically \cite{Maase} achieved an AP-score of 0.47 \cite[14]{Maase}. This is interesting for a number of reasons. First of all, since the results which I have produced for this thesis rely solely on conflict patterns, these results it reaffirms the conclusion from \cite{Maase} stating that patterns are more informative than structural features when it comes to predicting future conflicts. Secondly, the framework presented in \cite{Maase} also included features pertaining to the temporal and spatial patterns of conflicts. These features, however, were vastly less theoretically and methodologically developed compared to the eight features I use here. Point being, using only the past patterns of conflict, in a theoretically and methodologically coherent manner, here generates better predictions, than using a broad roster of more traditional structural variables in cohort with poorly operationalized patterns. Only future research will show if the predictions I present here can be further improved be reintroducing structural patterns.\par

%compared to general stat of the art.
Beyond the results presented in \cite{Maase}, direct comparison is less forward. My framework produces and AUC of 0.91 for both 2014 and 2015. The state of the art prediction efforts in academia achieve an AUC at approximately 0.80 \citep[14]{chadefaux2017conflict}. Importantly however, most of these past studies deal with country-level conflicts and only include novel onsets \citep[14]{chadefaux2017conflict}. This naturally makes any direct comparisons with my framework somewhat misleading. On one hand you could argue that predicting onsets is the most challenging part of conflict prediction. On the other hand, I am both predicting conflict onsets, continuation of conflict and conflict termination; and indeed at a much more disaggregated level than any efforts before this, which should make prediction harder. Point being, while direct comparison is unfeasible, I find it safe to say that the framework I have produced generates predictions at least as reliable as what previous efforts have accomplished -- if not more. Crucially, I achieve these results in a setting which emulates a real-world scenario. Most previous efforts, on the other hand, have relied on structural data, ignoring the fact that this data would already be dated by the time of release. In a real-world setting this would surely lower the predictive capabilities of frameworks relying on structural features greatly compared to what is presented in published papers.\par

% problam with onsets
It should also be noted that when we analyse conflicts on a highly disaggregated level and treat conflict as a function of past temporal and spatial patterns, the concept of a "hard" onset appears somewhat theoretical blurred. It does not make much sense to say that one single cell experienced an actual conflict onset if the the conflict simply spread from one er more neighboring cell -- possible only a few kilometers away. Remember these cells are nothing but analytically constructs aligning with no structural or geographical features. And even when conflict diffuses across political boundaries such as country boarders  -- e.g. the Duran line between Afghanistan and Pakistan --  the conflict might well be the same and the notion of a new onset still misleading. Novel onsets do happen but we need to think about the phenomenon differently then we used to. Further more, it should be noted that for policy purposes, predicting both termination and continuation of conflicts is arguably just as relevant as predicting conflict onsets.\par  

% Compare to using just the last opserved value

% why I now set a threshold
Given the challenge of comparison and the fact that measures such as AP or AUC are hard to derive substantial interpretations from, I now move on to present the results in a different light. To better convey the actual real world potential of the framework, I set a hard threshold denoting whether or not I assess that a given cell will experience conflict or not. That is I convert the probabilities into a binary measure. A lot of very useful information is discarded this way, but it does serve to present the results in a more intuitively appealing manner. For real world applications, however, the actual probabilities should naturally always be consulted.\par

% The threshold is set at 10-15\%.
Any threshold is bound to be more or less arbitrary. I simply choose to set a threshold, which insures that I predict roughly the same total number of conflicts as was observed in the last year of the training set (2012). Setting the threshold at 10\% fulfills this criteria. This means that every cell which has a probability of conflict above 10\% is classified as "expected to experience conflict", and all other cells as "not expected to experience conflict". Having actual classifications allows us to assess the generated number of true positives, false positives, true negatives, and false negatives. Given the threshold employed I have plotted these rates in the two maps presented in \autoref{confusion_map_2014} and \autoref{confusion_map_2015}.\par
% Should it not be some mean of the last five years. Could run a GP and extrapolate to get an estimate of the number ;) 

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{confusion_map_2014.pdf}
    \caption{\footnotesize{The map is created by binarizing the estimated probabilities of conflict in 2014 and comparing this to the actual binary observations from 2014. Given the threshold of 0.10, all cells with a probability of conflict above 0.10 are classified as conflicts, while all cells with a probability of 0.10 or below are classified as non-conflicts.}}\label{confusion_map_2014}
\end{figure}

% Int the plots - the good
Interpreting these maps, we get a more substantial evaluation of the frameworks performance. The first thing to notice is that most of the classifications are true negatives. Most cells do not experience conflict most of the time, and my framework captures this. Secondly the framework is able to generate a large amount of true positives. Remember these predictions are generated on the basis of respectively two and three years old data and each cell is only approximately $50km\times50km$. Point being, this is a extremely hard classification task -- not least considering that I only incorporate past conflict patterns as predictors. As such, the performance of the framework does inspire optimism.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{confusion_map_2015.pdf}
    \caption{\footnotesize{The map is created by binarizing the estimated probabilities of conflict in 2015 and comparing this to the actual binary observations from 2015. Given the threshold of 0.10, all cells with a probability of conflict above 0.10 are classified as conflicts, while all cells with a probability of 0.10 or below are classified as non-conflicts.}}\label{confusion_map_2015}
\end{figure}

% Int the plots - the bad1 false negatives
However, it should also be clear from \autoref{confusion_map_2014} and \autoref{confusion_map_2015} that there is still a lot of room for improvement. It is especially clear in 2014 where my framework completely misses two major conflicts. A novel conflict in south-east Ukraine and a great surge of conflict in the Central African Republic. While it is unfortunate that my framework misses these conflicts, it is not surprising. The conflict in Ukraine is far removed in both time and space from any other conflict, thus no past patterns were there to alert the framework. The Central African Republic, on the other hand, has a long history of conflict and is surrounded by other conflict prone regions. As such my framework also predicts some sporadic conflicts scattered around the country, but not nearly as widespread a conflict as that actually data indicates. The reason is simply that a peace agreements have been finalized in the last years of my test set, but said deals fail spectacularly in the beginning of the test years \cite{bbc}. As such, the patterns I have extrapolated are those of a declining, not an increase or ongoing, conflict. These two examples clearly show the limits of my framework. Sudden and abrupt changes in the political landscape will always elude a framework solely based on the past spatial and temporal patterns of conflicts.\par

% Int the plots - the bad2 false positives
It is also clear from \autoref{confusion_map_2014} and \autoref{confusion_map_2015} that I do generate some false positives. These, however, are somewhat less problematic than false negatives for a number of reasons. First of all, just because conflict did not rise in a given cell, it does not mean that the risk of conflict in that particular cell was not real. As an example, a large region from Eastern Turkey over northern Syria, northern Iraq and into western Iran is classified as conflicts in 2014, yet no conflict ensued that year. This region corresponds in large to the geographical region of Kurdistan \citep[271-272]{DahlmanKurdistan}, which has historically been the sight of many conflicts \citep{DahlmanKurdistan}.  Indeed, we also see conflict erupt in the region again in 2015 where many of my false positives change to true positives. This does not prove that there was a risk of conflict in 2014, but it surely does make it rather plausibly. The danger of false positives is that resources might be allocated to prevent conflict when no conflict is likely to happen. However, if the false positives tend to indicate high risk zones where conflict simply failed to erupt due more or less to chance, allocating resources here might not constitute any huge waste after all.\par


%+++++++++++++++++++++++++++++++++++++++
%+++++++++++++++++++++++++++++++++++++++
% Så, der mangler lige en afslutning på det her afsnit, og så går det over i en konklusion og en perspektivering/diskussison (jf. måden hr. Hjort vil have tingene på).
% Tusinde tak fo hjælpen, jeg glæder mig til at læse jeres noter i gennem.
%+++++++++++++++++++++++++++++++++++++++
%+++++++++++++++++++++++++++++++++++++++
% What is then the precision and recall - and what does this mean..
Given the specific threshold I here use, I obtain a recall of respectively 0.51 and 0.57 and a precision of respectively 0.56 and 0.52 for the years 2014 and 2015. Thus in substantial terms; my framework is able to correctly classify slightly over half of all conflicts cells, but in the process I will roughly produced one false positive for each true positive. Naturally this ratio is highly dependent on the specific threshold I employ, but these results can still do a lot to convey the potential of my framework. Again, given the imbalanced and the highly disaggregated nature of the data and the sole focus on patterns, this is a descent result -- but does leave a lot of room for improvement. Naturally, such improvement might need to come from the inclusion of more features from other data sources. These paper, after all, only present one piece of the puzzle for creating a complete early warning system, and there likely is limit to the amount of information we can extract from patterns alone.\par

% bridge
That being siad, future research should naturally survey both the potential of including more data and even better handling of past conflict patterns. To inform such efforts the next subsection will briefly touch upon the subject of feature importance. That is, assessing how much prediction power each of my eight features brings to the final predictive framework.\par 

%Knowing the extent to wich the various features contributed with prediciton power will 

\subsection{Feature importance}

% only 2014
Regarding feature importance, I find no difference between 2014 and 2015. As such I will only here present the results for 2014. The results from 2015 are vitually indentical and can be found in the appendix. \autoref{feature_imp2015}. The results from 2014 can be seen in \autoref{feature_imp2014}.\par 

\begin{figure}[!htb]
 	\centering
	\includegraphics[scale=0.47]{feature_imp_2014.pdf}
  \caption{\footnotesize{stuff..}}\label{feature_imp2014}
\end{figure}

% What is then the most imp feature?
From \autoref{feature_imp2014} it is clear that the majority of the prediction power comes from the base feature of conflict magnitude $f_{cm}$. Interestingly this is the most basic feature in the framework simply denoting the expected future conflict magnitude in some cell given said cells history. It is easily understood and I only use a 1D Gaussian process to derive this measure. As such, future efforts aimed both at prediction and estimation might gain a lot from simply including this measure, if measures of the explicate spatial dimensions are deemed to resource demanding. That being said it is still clear from \autoref{feature_imp2014} that all the features do bring some information to the effort. As such I recommend all eight being included in any complete early warning system.\par

% Bridge
This finalizes my evaluation of the predictive framework I created for these thesis. In the next section I will concluded the entire endeavour by summing up all major insights and results which I have presented throughout this thesis. The conclusion is followed by a prospective look in the future where I discuss how we should proceed from here to create a fully functional early warning system for conflict forecasting.\par

\section{The Conclusion}

%What was your starting point
Previous research has shown that past conflict patterns hold a lot of potential when it comes to predicting future conflicts. As such, if we are to create an early warning system for conflict forecasting, such system should include a component focused on extracting prediction power from past temporal and spatial patterns of conflict. However, previous efforts -- estimations and predictions alike -- have to a large extent failed to create features mirroring the theoretical insights we have regarding conflict patterns. To best utilize the predictive potential of past conflict patterns we need a tool that can capture conflict patterns in a manner which complies with the general theoretical expectations of conflict patterns. In this thesis I illustrate that the machine learning technique of Gaussian processes can be such a tool. Using an approach based on Gaussian processes I thus show how we can capture the temporal and geo-spatial patterns of past conflicts and use these patterns to forecast and predict the time and place of future conflicts.\par
%\emph{\textbf{Research Question:} How can we efficiently use the temporal and geo-spatial patterns of past conflicts to forecast and predict the time and place of future conflicts?}\par

% how do you do it
Using Gaussian processes I created eight features each pertaining the spatial and/or temporal patterns of conflicts. These patterns were extrapolated into future years and the extrapolations used to predict the probability of conflict in the geographical grid cells, which I used as unit of analysis.\par

% What did you find?
I used a predictive framework based on xgboost and undersampling along with out-of-sample prediction to evaluate the predictive potential of the extracted and extrapolated conflict patterns. Using my approach to forecast respectivly two and three years into the future I achieved AP scores of 0.51 (2014) and 0.52 (2015) against a baseline roughly 0.05. For both years I achieved an AUC score of 0.91 against a baseline of 0.50. In more substantial terms; if I set a probability threshold at 0.10 I am able to correctly predict half of all conflicts, but doing this will also generate in one false positive for each true positive. Naturally I am able to capture more true positives, at the price of relatively more false positive.\par 

% is that good?
Given the highly disaggregated unit of analyses, the imbalance of the data and the subject at hand these are encouragingly results which definitely shows that past conflict patterns do hold a lot of predictive potential -- not least when they are captured in a theoretical and methodological coherent manner. That being said it is also clear that we still have work to do before an actual reliable early warning system can be compiled.\par 

% compared to efforts?
Unfortunately my results are somewhat hard to compare to previous efforts -- not least due the highly disaggregated unit of analysis. The only effort which is directly comparable is \cite{Maase} which my approach here outperforms despite that fact the \cite{Maase} includes both conflict patterns and structural features. While comparison with other efforts is less forward it is clear that the framework presented here does at least as well, if not better, than the state of the art. Notably this is done using only past patterns, and in a setting which emulates a real world scenario. The later point contrast to many previous efforts where researches ignores the fact that the data their used would be rather dated by the time it is actually made available. As such, while I still have a lot of work in front of my, this thesis present a substantial step forward, towards the creation of a actual early-warning-system for conflict forecasting.\par

% what is next/bridge
As presented, using the patterns of past conflicts as a predictor only constitute one of several components needed to create a complete early warning system. Naturally, there are no final answers concerning how many or which specific components are needed to create a fully operational early warning system. As such, in the next and final section I will present a number of components which I recommend being the focus of future studies.\par

\section{Futher Perspectives}
% For estimaion: if you want arguement regarding baseline model look at \cite{schutte2011diffusion}.
% For prediction see own PHD app.
% Selvkritik - også vedrørende de mål du bruger måkse....

% Weakness of you approach/GP's
Using past efforts as predictors does result in some natural limitations. Most prominently, we will never be able to predict truly novel conflicts far removed in time and space from any previous conflicts using such approach alone. We might be able to achieve even better results with Gaussian processes then what I have presented above. This might be done be distinguishing between long term trends and short term trends or by using hierarchical hyper priors. Furthermore other even more involved methods such as artificial neural networks might be able to capture the patterns of conflict in even more effective ways. But while these opportunities should be explored in future researche, they will never ammend the fundamental limitation of using past patterns to predict future patterns. As such, while patterns should be a central component in any early warning system, they should also only be one of many.\par

% Perhaps somthing about other events: political unrest, riots ect..
%One solutions could be to bring in other event data, such as data on demonstrations, riots, civil unrest ect. but that wich is avialeel is data... MORE

% one solution: reintroduce structural patterns and ammend thier weakneess with GP's
One component which also deserves attention is on composed of structural data and theory on the structural prerequisites of intra-state conflict, such as poverty, resources, regime ect. The advantages of such a component is the large catalog of theory following it \citep{Collier_Hoeffler_1998, Fearon_Laitin_2003, Collier_Hoeffler_2004, Hegre_Sambanis_2006, Kalyvas_2007, Goldstone_2010, Cederman_Gleditsch_Buhaug_2013, perry_2013}. Such insights inform feature engineering, feature selection and model selection \cite[30]{Cederman_Gleditsch_Buhaug_2013}.\par

% disadvantage 1 and solution
As noted, however, one clear disadvantage of this approach is dated data. An other disadvantage is high inertia \citep[10]{chadefaux2017conflict}. Structural features are slow to change while political unrest can evolve into actual intra-state conflict relatively fast. Intriguingly however, given the this inertia we can address the disadvantage of dated data simply by use Gaussian processes to extrapolate the structural patterns into future years. As such, I would exploit the inertia of structural patterns to ameliorate the dated state of the data. To a large extent this effort would mimic the approach presented in this thesis, simply using different data.\par

% disadvantage 2 and solution
Yet, while the inertia inherent in structural data might justify extrapolating these patterns across five or even ten years, the inertia still means that we might identify fragile regions but not necessarily which of these fragile regions will experience conflict \citep[10]{chadefaux2017conflict}. Combining a structural component with one of patterns will reduces this problem especially if we included data on other forms of events such as civil or political unrest.\par 

% Or use test or image recognition..
Following this logic, an other component should be one which uses text or image data obtained from news/social/political sources. Such data would effectively constitute it own kind of event data, but one specifically tailored for the task at hand. Using text data is still a novel approach in social science \citep{grimmer2013text} and image date even more so \citep{williams2019images}. Yet, the use of text data has already shown promise in conflict predictions \citep{chadefaux_2014, mueller_2016}. Using image data to conflict prediction has to my knowledge not been done yet, but it could hold great promise not least since it circumvents the problem of varying norms and languages which challenges text data. \par

%advantage - er du sikker på det er sin egen paregraf..
Text and image data has two advantages on structural data. Firstly, the data has the potential to be very current. In theory, it could be updated in real-time \citep[474]{cederman2017predicting}. Secondly, like more traditional event data, text and image data would be able to sort fragile but peaceful regions from fragile regions on the verge of conflict. Importantly, such data would also holds an advantage over the event data used in this thesis; text and image data could help predict onsets far removed in time and space from any previous conflicts.\par

% Weaknesses
Naturally, using text or images also has its weaknesses. Gathering text or images from the entire globe is no trivial effort. Local sources is hard to come by, and legal barriers might prevent the use of any data obtained. As such, it is not realistic to produce data on a disaggregated level comparable with that of the other components which I have presented. As such, to ameliorate the individual weaknesses of each component they most all be combined into a single unified predictive framework. A unified early warning system for conflict prediction.\par

% bridge out ->
With these paths for future research presented I concluded this thesis on an optimistic note. Reliable conflict prediction might be the conflict research's final frontier, but given the result presented above, it does by no means appear a fruitless nor impossible endeavour.\par


\pagebreak

\section{Bibliography}
\bibliographystyle{apalike} 
\bibliography{conflict.bib}

\pagebreak
\section{Appendix}

\subsection{Priors - Conflict magnitude}\label{cmPrior}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{Hyper-priors(cm).pdf}
    \caption{\footnotesize{Weakly informative hyper-priors for the Guassian processes estimation of conflict magnitude. Simply set to help the computation by discouraging high unrealistic values for $\eta$, $\ell$ and $\sigma$.}}
\end{figure}
\pagebreak

\subsection{Priors - Static conflict exposure}\label{scePrior}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{Hyper-priors(sce).pdf}
    \caption{\footnotesize{Weakly informative hyper-priors for the Guassian processes estimation of static conflict exposure. Simply set to help the computation by discouraging high unrealistic values for $\eta$, $\ell$ and $\sigma$.}}
\end{figure}
\pagebreak

\subsection{Priors - Dynamic conflict exposure}\label{dcePrior}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{Hyper-priors(dce).pdf}
    \caption{\footnotesize{Weakly informative hyper-priors for the Guassian processes estimation of dynamic conflict exposure. Simply set to help the computation by discouraging high unrealistic values for $\eta$, $\ell$ and $\sigma$.}}
\end{figure}
\pagebreak

%\subsection{Visual illustration of Gaussian distribution and Gaussian process}\label{GDGP}
\subsection{Feature importance 2015}\label{feature_imp2015}


\begin{figure}[!htb]
 	\centering
	\includegraphics[scale=0.47]{feature_imp_2015.pdf}
  \caption{\footnotesize{stuff..}}
\end{figure}
\pagebreak


\end{document}
