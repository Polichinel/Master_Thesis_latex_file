%\pagestyle{article}
\documentclass[a4paper]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} % for figures
\usepackage[section]{placeins} %This prevents placing floats before a section.
\usepackage{csquotes}

\usepackage{natbib}% better citation
%\usepackage{hyperref} %autoref
\usepackage[hidelinks]{hyperref} %hidelinks to remove ugly blue format
\usepackage{amsmath} % for \tag and \eqref macros in mathematical eq.


%% Sets linestretch, paragraphstrech, indentation and footnote stuff 
\usepackage{parskip} %space between paragraphs
\parskip=5pt %set space between paragraphs
\setlength\parindent{12pt} %paragraf indentation
\usepackage[onehalfspacing]{setspace} %linespacing; does not affect footnotes
\setlength{\footnotesep}{0.7\baselineskip}% space between footnotes
\usepackage[hang,flushmargin]{footmisc} %% removes identation in footnoteshttps://www.overleaf.com/project/5b98e00a21d3bd15ac5a2e86

\usepackage{makecell} % make cells in tabels for longer text

\usepackage[colorinlistoftodos]{todonotes}

%% For header and footer (1)
% Marco
\usepackage{fancyhdr}
\pagestyle{fancy}
\textwidth = 424pt % test width ish
\oddsidemargin = 18pt % margin width ish

\fancyheadoffset{0 in} % Shifty solutions..

\fancyhf{} %% clear defuelt header and footer

%% For header and footer (2)
%Specifics
\lhead{Simon P. von der Maase}
\rhead{\today}

\lfoot{University of Copenhagen}
\rfoot{\thepage}
\renewcommand{\footrulewidth}{0.8pt}

\title{Where Men Rebel\\A Modern Approach to Conflict Forecasting}

\author{Institute of Political Science, University of Copenhagen\\\emph{By Simon Polichinel von der Maase}\\Under Frederik George Hjort\\\footnotesize{Format: Article}}
\date{July 2019}

\begin{document}

	\begin{titlepage}
		\maketitle
		Character count: 117.685/120.000 (50 normal pages)\\
		\noindent\rule{\linewidth}{0.4pt}
		\begin{figure}[h]
			\centering
			\includegraphics[scale=0.32]{KU_logo.png}
		\end{figure}
		\thispagestyle{empty} % removes page number on front page
	\end{titlepage}
    \tableofcontents
\pagebreak

\begin{abstract}
%\todo[inline]{to come. Max one page: 2400 char.}

%What was your starting point
%Previous research has shown that past conflict patterns hold a lot of potential when it comes to predicting future conflicts. Therefore, if we are to create an early warning system for conflict forecasting, such system should include a component focused on extracting prediction power from past temporal and spatial patterns of conflict. However, previous efforts -- estimations and predictions alike -- have to a large extent failed to create features mirroring the theoretical insights we have regarding conflict patterns. To best utilize the predictive potential of past conflict patterns we need a tool that can capture conflict patterns in a manner which complies with the general theoretical expectations of conflict patterns. In this thesis I illustrate that the machine learning technique of Gaussian processes can be such a tool. Specifically my goal was to assess the extent to which it is possible to use Gaussian processes in tandem with past spatial and temporal conflict patterns to predict the time and place of future conflicts.\par

%\emph{\textbf{Research Question:(NEW)} To what extent is it possible to reliably forecast and predict the time and place of future conflicts, using solely the temporal and geo-spatial patterns of past conflicts in tandem with Gaussian processes.}\par

%what is going on:
This thesis represents a substantial step towards the construction of a reliable computational early-warning system for predicting future intra-state conflicts at a sub-national level. Specifically I examine to what extent it is possible to reliably predict the time and place of future conflicts, using the temporal and geo-spatial patterns of past conflicts in tandem with the machine learning technique of Gaussian processes.\par

% the problem
Previous research has shown that past conflict patterns hold potential when it comes to predicting future conflicts. However, previous efforts have largely failed to create features mirroring the theoretical insights we have regarding conflict patterns. To best take advantage of the predictive potential inherent in past conflict patterns we need a tool that can capture conflict patterns in a manner which complies with theoretical expectations. In this thesis I illustrate that the machine learning technique of Gaussian processes is such a tool.\par

% Test and train
I use highly disaggregated spatial data from the years 1989 through 2012 to train my framework while data pertaining to the years 2013 through 2017 are held back as a test set to emulate the unknown feature which I can test my predictions against. 

% how do you do it
Using Gaussian processes I capture the spatial and temporal patterns of past conflicts and extrapolate these into "future" test years. To asses the extent to which my approach has succeeded in generating reliable forecasts, I use these patterns as features in a predictive framework based on xgboost. The predictions generated by this framework are then evaluated through out-of-sample prediction.\par

% results
Using my approach to forecast respectively two and three years into the "future" I achieved AP scores of 0.51 (2014) and 0.52 (2015) against a baseline of roughly 0.05. For both these years I achieved an AUC score of 0.91 against a baseline of 0.50.\par 

% compared
While direct comparison with previous efforts is difficult, the framework presented here does at least as well, if not better, than the state of the art. Notably this is done using only past patterns, and in a setting which emulates a real world forecasting scenario. 

% one disadvantage 
One disadvantage of the approach is that it is unable to capture truly novel conflict onsets far removed in time and space from any previous conflict. Amending this will require the inclusion of other data sources.\par

% What did you find?
%To asses the extent to which my approach had succeeded in generating reliable forecasts, I used a predictive framework based on xgboost and undersampling along with out-of-sample prediction to evaluate the predictive potential of the extracted and extrapolated conflict patterns. Using my approach to forecast respectively two and three years into the future I achieved AP scores of 0.51 (2014) and 0.52 (2015) against a baseline of roughly 0.05. For both years I achieved an AUC score of 0.91 against a baseline of 0.50. In more substantial terms; if I set a probability threshold at 0.10 I am able to correctly predict half of all conflicts, but doing this will also generate one false positive for each true positive. Naturally I am able to capture more true positives, at the price of relatively more false positive.\par 

% is that good?
%Given the highly disaggregated unit of analyses, the great imbalance of the data and the subject at hand these are encouragingly results which definitely shows that past conflict patterns do hold a lot of predictive potential -- not least when they are captured in a theoretical and methodological coherent manner.\par 

% compared to efforts?
%Unfortunately my results are somewhat hard to compare to previous efforts -- not least due the highly disaggregated unit of analysis. The only effort which is directly comparable is \cite{Maase} which my approach here outperforms despite that fact the \cite{Maase} includes both simple measures of conflict patterns and structural features. While comparison with other efforts is less forward it is clear that the framework presented here does at least as well, if not better, than the state of the art. Notably this is done using only past patterns, and in a setting which emulates a real world scenario. The later point contrast to many previous efforts where researches ignores the fact that the data their used would be rather dated by the time it is actually made available.

% the bad
%That being said it is also clear that I still have work to do before an actual reliable early warning system can be compiled. specifically my approach are unable to identify truly novel conflict onsets far removed from any past conflicts in time and space. That being said this thesis do present a substantial step forward, towards the creation of a actual early-warning-system for conflict forecasting.\par

% what is next/bridge
%As presented, using the patterns of past conflicts as a predictor only constitute one of several components needed to create a complete early warning system. Naturally, there are no final answers concerning how many or which specific components are needed to create a fully operational early warning system. As such, in the next and final section I will present a number of components which might ammend the weaknesses of the approach presented above.\par





\end{abstract}
\pagebreak

\section{Introduction}
%\todo[inline]{The World}

\begin{displayquote}
\emph{[...] the estate of Man can never be without some incommodity or other; and [...] the greatest, that in any form of Government can possibly happen to the people in generall, is scarce sensible, in respect of the miseries, and horrible calamities, that accompany a Civill Warre;} \cite[128]{Hobbes_1991}\par
\end{displayquote}

Civil wars, and internal conflicts in general, have plagued mankind throughout the ages. And still, this affliction has not yet been throttled. Since 1960, over half of all nations have experienced some manner of internal conflict leading to fatalities \citep[3-4]{Blattman_Miguel_2010}. Indeed, since the end of the Second World War, intra-state conflicts have been far more common than inter-state wars and over five times as many people have died in intra-state conflicts compared to inter-state wars \citep[563]{Collier_Hoeffler_2004}. Thus the 367 years old quote above is today as relevant as ever.\par

This thesis represents a substantial step towards the construction of a reliable computational framework for predicting future conflicts at a sub-national level; a so called \emph{early-warning system}. In the short run such a system will provide international actors valuable information and time to act; mitigating the fallout of conflicts \citep{Ward_Greenhill_Bakke_2010, perry_2013}. In the long run such a system will generate theoretical insights into the mechanics of conflicts, potentially enabling actors to address the underlying courses \citep{Schrodt_2014, chadefaux2017conflict}. Given these potentials, efforts to create an early-warning system have been called "conflict researchers’ ultimate frontier" \citep[474]{cederman2017predicting}. As such, the contribution of this thesis is highly topical and can provide practical and ongoing guidance in future conflict prevention, intervention, and peace keeping efforts.\par

A complete early-warning-system would be constituted by a legion of sophisticated components. In this thesis I will focus on one of these components: A component capable of using patterns of past conflict to predict the patterns of future conflict. The reason why I choose this focus is, as I will demonstrate throughout the thesis, that this approach has a number of very appealing properties: it has a clear theoretical foundation, it holds high prediction power, and it takes advantage of very current data. As such, using past patterns to predict future patterns has the potential of being one of the most important and central components of any complete early-warning system.\par

% what do you find
Indeed, in this paper I show that using the machine learning technique of Gaussian process to capture and extrapolate past conflict patterns into future years carries great predictive potential. Specifically, while direct comparison is difficult, I am able to generate predictions which are at least as good, if not better, than any previous efforts of conflict prediction. Importantly I do this using solely the patterns of past conflict, a highly disaggregated unit of analysis and a setting which rigorously emulates a real world forecasting scenario. The later point is crucial since many researchers have previously ignored different aspects of real world forecasting -- such as the release date of the data they use relative to the actual years they aim to forecast into.\par

% conclusion
I conclude that the the construction of an early warning system is possible and that the inclusion of past conflict patterns -- correctly handled -- should play a key part of such a system. However, I also conclude that we must incorporate data for other sources to create a system reliable enough to use in real world applications.\par 

%bridge
%The proceeding subsections presents relevant insights and challenges from the broader field of conflict studies and conflict prediction. This introduction will serve as a primer, putting my specific approach into the context of previous efforts.\par

The proceeding subsections will serve as a more thorough introduction to the context, subject and objective of my thesis.\par

\subsection{Conflict prediction so far}
% condensat af lit review
%\todo[inline]{The science}

% what
Three specific subjects from the broader field of conflict studies are of prime relevance for this paper: The difference between estimation and prediction, the use of sub-country disaggregated data as opposed the country level data, and the use of event data instead of structural data as the basis of conflict prediction. Each of these subjects will be briefly introduced in turn below.\par

% Prediction
Firstly, the study of internal conflicts has a long history. The sub-field of computational conflict prediction\footnote{from here just denoted conflict prediction}, however, is a rather novel offspring. Researchers of conflict prediction use modern computational tools in efforts to predict the time and place of future conflicts \citep{cederman2017predicting, chadefaux2017conflict}. Some of the earliest examples in academia of such a focus being \cite{Goldstone_2010}, \cite{Hegre2013} and \cite{perry_2013}.\par

% why not before
There are two main reasons why the field of conflict prediction -- despite its obvious usefulness -- has not received more attention. First of all; the required technology is relatively new. Indeed, some of the more impressive results are the products of very recent developments in quantitative methods, computation power and data availability \citep{ol2010afghanistan, perry_2013}. Secondly, traditional conflict research has focused on causes, correlates and prerequisites of conflict rather than generating actual predictions \citep[8]{chadefaux2017conflict}. As such, modern predictive efforts are still regarded with high skepticism and papers devoted to prediction have been accused of lacking adequate theoretical grounding \citep[8-9]{chadefaux2017conflict}. 

% why it should be now.
In reality, however, both prediction and explanation are important components of scientific inquiry, and both are needed to generate and test theories \citep{Schrodt_2014, chadefaux2017conflict}. Indeed, in the natural sciences, accurate predictions are central for the validation of theory \citep[289]{Schrodt_2014}. As such, the restraint against predictions in the field of conflict research has been increasingly criticized \citep{King_Zeng_2001, Ward_Greenhill_Bakke_2010, Goldstone_2010, Schrodt_2014, chadefaux2017conflict}. Furthermore, creating models with actual prediction-power will also provide heuristic tools and powerful policy-guides for real-world application \citep[372]{Ward_Greenhill_Bakke_2010}. As such, a focus on prediction have been increasingly encourages \citep{Ward_Greenhill_Bakke_2010, Schrodt_2014}.\par

% another recent development: disaggregation.
Secondly, countries have traditionally been the main focus, but since the phenomenon of interest is a sub-country phenomenon, the unit of analysis should also be disaggregated at sub-national level \citep[490]{Cederman_Gleditsch_2009}. Employing a disaggregated unit of analysis allows me to create a more detailed analysis of conflict patterns. It also allows me to better analyze incidents where administrative boarders provide little to no ward against conflict diffusion \citep[445-446]{ol2010afghanistan}. In turn, the derived insights allow me to generate forecastings pertaining to specific sub-national areas rather than entire countries.\par

% Event data
Thirdly, the last subject constitutes most directly the starting point and contribution of this thesis: the use of event data over structural data to predict future conflicts. Traditional efforts have tended to use structural features as foundation. This has been true for both estimations and predictions \cite[10]{chadefaux2017conflict}. However, in a recent contribution of my own I show that patterns of conflict events in themselves appear to hold much more prediction power than the traditional structural variables \citep{Maase}. These findings align perfectly well with a growing strain of the literature concerning conflict diffusion; little doubt remains that conflicts cluster in time and space \citep[15]{crost2015conflict} and recent efforts have shown that the clustering and diffusion of conflict is often a direct product of contagion \citep{buhaug2008contagion,schutte2011diffusion,crost2015conflict,bara_2017}. As such, when it comes to sheer prediction power, event data appears to have the advantage over structural data.\par

% why evetn data is better 2
Importantly, event data is also, at present, much more current and more often maintained than data pertaining to the structural features. In practice this means that the data I use for actual forecasting is much closer in time to the forecastings I wish to generate, thus creating more reliable predictions and mitigating uncertainty.\par

% bridge
Given these insights and conditions -- and the scope of the thesis at hand -- I will only utilize data relating directly to past conflict events in my prediction effort. That is, estimating the probability of future conflicts given past patterns of conflict. The next section will introduce the research question I answer, the approach I utilize and the framework I construct in this thesis.\par

\subsection{This framework}
% \todo[inline]{this paper}

% what you gonna do there champ?
The prerequisite for using past patterns of conflicts to predict future patterns of conflict is the ability to identify and extract salient patterns and further extrapolate these patterns into future years. In this thesis, I show how this can be done using the machine learning technique of \emph{Gaussian processes}. I will also demonstrate how the technical properties of Gaussian processes align remarkable well with the theoretical foundation of conflict diffusion in general.  The presentation, qualification, and exemplification of how Gaussian processes can turn past conflict patterns into future conflict predictions is the prime objective of this thesis. The research question motivating this thesis can be summed up accordingly:\par

% \begin{displayquote}

% \emph{\textbf{Research Question:} How can we most efficiently use the temporal and geo-spatial patterns of past conflicts to forecast and predict the time and place of future conflicts?}\par

% \end{displayquote}


% [Alt1]

\begin{displayquote}

\emph{\textbf{Research Question:} To what extent is it possible to reliably forecast and predict the time and place of future conflicts, using the temporal and geo-spatial patterns of past conflicts in tandem with Gaussian processes.}\par

\end{displayquote}

% Steps - over all (new)
To answer this question, I use event data pertaining to sub-country geographic grid cells. The data I use covers the years form 1989 through 2017. I split the data into a \emph{training set} (1989-2012) and a \emph{test set} (2013-2017). The test set is meant to emulate the unknown future, and as such is kept isolated until the final evaluation effort. I then construct a framework composed of two layers of estimation. First, Using the training data I estimate the spatial and temporal conflict patterns via Gaussian processes. Also using Gaussian processes, I extrapolate these patterns into future years corresponding to those of the test data. The product is eight features pertaining to the patterns of conflict. Secondly, from these eight features I use the values corresponding to the training years to train a predictive framework based on \emph{Extreme Gradient Boosting}. Having trained this framework I introduce the extrapolated values corresponding to the test years. Using these extrapolations I estimate the probability of intra-state conflict in a specific geographic grid cell given a specific (future) year from the testset. To asses how well the extracted patterns are able to actually predict the time and space of future conflict these predictions are evaluated through \emph{out-of-sample predictions} against the actual observations contained in the testset.\par

% Data and unit of analysis
To be more specific; the data I use is obtained from the Uppsala Conflict Data Program \citep{UCDP_2017}. This data denotes, among other things, conflict fatalities at specific coordinates and dates \citep{UCDP_2017}. I use the logarithm of this measure to create a measure of \emph{conflict magnitude} (cm). The temporal dimension spans from 1989 to 2017 and I aggregate it at a yearly level. The spatial dimension, I aggregate using a global grid constituted by $0.5 \times 0.5$ decimal degree cells; that is squares roughly measuring $50km\times50km$ at the equator \citep[367]{Tollefsen_2012}. Thus, the unit of analysis is one specific grid cell at one specific year.\par

% Time lines as functions
I will refer to the combined years of a given cell as the \emph{time-line} of that cell. Each time-line tells the story of conflict in the corresponding cell throughout the included years. Each time-line can also be seen as a continuous function $y = f(x) + \epsilon$ where $\epsilon$ is a noise term, $y$ is conflict magnitude and $x$ is years. If we can estimate this function, we can also extrapolate it into the future by introducing new years; $x_{new}$. This is exactly what we can use Gaussian processes for.\par

% introducing space
Now, this will give an estimate of the future magnitude of conflict in each individual cell. This is in itself a prediction. But I can do better. Using only the magnitude of the individual cell, we would fail to account for the spatial diffusion of conflicts between cells. We need a measure accounting for \emph{spatial exposure} as well. Encouragingly, I can use Gaussian processes for this purpose as well.\par

% how you solve space
For each individual year in my sample, I estimate a 2D function of the spatial pattern of conflict over all included grid cells. This gives me an estimate of the level of \emph{static conflict exposure} (sce) each cell experiences in any given year. To bind this information together across all years, and allow for extrapolation into the future, I once more view the individual time lines as functions $y = f(x) + \epsilon$. $x$ is still years, but now $y$ is conflict exposure. This captures the spatial patterns of \emph{dynamic conflicts exposure} (dce) across time\footnote{Effectively this constitutes a pseudo 3D space. It could also have been estimated directly in 3D if I had access to vastly more computational power.}.\par

% the six other featues
%Where conflict magnitude denotes the level of conflict in a specific cell, conflict exposure denotes the aggregated level of adjacent conflicts. 
I thus have two base functions. One of conflict magnitude and one of conflict exposure. Intriguingly, since I am effectively working with continuous functions, I can readily extract other relevant information. Specifically how much the conflict magnitude or exposure is increasing or decreasing (slope), whether the conflict magnitude or exposure of a given cell is accelerating or decelerating (acceleration), and the total mass of conflicts in the time-line of each cell (mass). Using these options on both conflict magnitude and conflict exposure, I construct six additional features. All in all, I produce eight features representing the spatial and temporal patterns of conflict. All eight feature are extrapolated into future years.\par

% how do you combined these features
The extrapolation of these measures constitute forecastings in themselves. However, to harvest the full potential of these measures, I will use them as features in a combined predictive framework. A framework capable of predicting probability of conflict in a given cell at some future point in time. For this I will use the forecasting-framework presented in \cite{Maase}. This framework is based on an Extreme Gradient Boosting algorithm \citep{Chen_2016}. The framework is further primed for rare events by employing a combination of case-cohort under-sampling \citep[142]{King_Zeng_2001} and informed under-sampling \cite[1267]{He_2008}. I specifically designed this framework with internal conflicts in mind, thus making it an obvious choice for the evaluation effort.\par 

% test and train
To evaluate how good these predictions are I employ out-of-sample prediction. If I were to forecast into actual future years, I would not be able to conclude how reliable my approach is -- at least not before a number of years have passed. To avoid this impractical latency I divide my data into a \emph{train set} and a \emph{test set}. My train set will encompass all years from 1998 to 2012 while the test set will encompass all years from 2013 to 2017. Importantly, neither my features nor my model will be based on data from the test set, which will be kept isolated until the evaluation effort. As such, the test set effectively represents "the future" \cite[199-200]{Goldstone_2010}. Using this evaluation-scheme insures that I obtain an accurate assessment regarding my approach potential for actual forecasting.\par 

%my results shows that....
Using my approach I am able to achieve rather reliable conflict prediction. Given the highly disaggregated unit of analysis I employ, direct comparison with previous efforts is less forward, but it is safe to say that my framework produces prediction which are at least as good if not even better then the state of the art in academia.\par % here only in

%future potentials
As such, I find there is a great potential for using Guassian processes to capture and extrapolate conflict patterns for conflict forecasting. That being said the approach does have its limits. Using only this component I will never be able to predict truly novel conflicts far removed in time and space from any previous conflict. Amending this issue will require the introduction of other components based on other data sources e.g. text or images. As such, I recommend that these subjects should be the focus of future research efforts.\par 

%bridge
Having outlined the structure, approach and conclusions of my thesis, the next section will serve to elaborate on how my thesis fits into the large context of conflict studies. This will serve to further qualify why I have chosen the specific approach I present in this thesis.\par

\section{Recent and Relevant Developments}\label{challenges}

%\todo[inline]{Political Science Literature Review}
%Introducer alle de begreber du bruger. 

% what is gonna happen below
The field of conflict studies has flourished during the last two decades. Yet, during this period it has also been challenged and critiqued from numerous angles. This thesis is naturally a product of these past debates and developments. Since my starting point is the latest research in the field, I here present the two most recent and relevant developments. In the first subsection I elaborate on the development from estimation towards forecasting. In the second subsection I elaborate on the development from cross-country studies towards more disaggregated geographical units. A basic understanding of these two developments is necessary to appreciate my main challenge presented hereafter: Using past patterns as future predictors.\par

\subsection{From estimation to forecasting}\label{est_to_pred} % ---------------------------------------------------------------------

%What use to be
Traditionally, conflict studies have focused on explaining conflict and understanding which features facilitate conflicts. The features under investigation have mostly been structural such as poverty, natural resources or a specific political regime. Researchers used statistical tools such as linear and logistic regressions to estimate the effects of such features on the probability of conflict \citep[8]{chadefaux2017conflict}, and further whether this estimated effect could be considered \emph{statistically significant} \citep[363-364]{Ward_Greenhill_Bakke_2010}. If a given feature was found significantly related to conflict -- and the study could be considered valid and unbiased -- researchers would use theory to argue why the correlation could be considered causal. This is \emph{causal inference} \citep[8]{chadefaux2017conflict}. Knowing which features "causes" conflict could then be used for policy recommendation.\par

% But why that way?
The focus on causal inference was (and still is) prevalent, and few conflict experts have ever attempted to undertake actual conflict prediction and forecasting \citep[474]{cederman2017predicting}. This reluctance to focus on prediction is primarily due to two assertions. Firstly, efforts devoted to prediction have been accused of lacking strong theory and as a consequence been rejected by traditional political science journals \citep[8-9]{chadefaux2017conflict}. Secondly, predictions have been considered fruitless due to "the perceived impossibility of forecasting political events" \citep[8]{chadefaux2017conflict}.

% The problem with these assertions.
Such assertions, however, are both misleading and unproductive. First of all, prediction is not "unscientific". On the contrary, both prediction and explanation are key components of scientific inquiry, and both are needed to generate and test theories \citep[8]{chadefaux2017conflict}. In the natural sciences, accurate predictions are seen as the "epitome of validation of a theory" \citep[289]{Schrodt_2014}. Secondly, while we do not know the full potential of conflict prediction \citep{cederman2017predicting, chadefaux2017conflict}, we know it is not impossible. The reason is that we already have a few tentative, but encouraging, results available \citep{Goldstone_2010, perry_2013, mueller_2016, Maase}. Indeed, developments in statistical methods, computational power and data availability make such endeavours increasingly feasible \citep{ol2010afghanistan, perry_2013}.\par

% But is there i problem with the old approach
Given these insights and developments, the sentiment is shifting and criticism is increasingly aimed at the explanatory approach. This approach has often been justified by assuming that high explanatory power equals high predictive power \citep[8]{chadefaux2017conflict}, however, This is not the case. Using statistical significance as the basis of policy recommendation is now considered highly imprudent, since many prominent studies using this approach have shown very poor predictive capabilities \citep{Ward_Greenhill_Bakke_2010, Schrodt_2014, chadefaux2017conflict}. Indeed, the approach of significance testing in conflict studies has been consistently criticized for almost two decades \citep{king_zeng_2001b, Ward_Greenhill_Bakke_2010, Goldstone_2010, Schrodt_2014, chadefaux2017conflict}. Given this critique and my predictive goal, the focus in this thesis will be solely on prediction-power.\par

%Notably, even when explanation is the sole purpose of a study, significance testing has been deemed a misleading way to evaluate the included features of interest. Instead, prediction-power is a seen as a better benchmark for the salience of the included features, even when forecasting is not the end-goal \citep{Ward_Greenhill_Bakke_2010, Schrodt_2014}. The point is that creating models with actual prediction-power is both a better way to evaluate feature importance and it will provide heuristic tools and powerful policy-guides for real world applications \citep[372]{Ward_Greenhill_Bakke_2010}. Given this critique and the fact that the focus of this thesis is actual forecasting, high prediction-power is the sole goal.\par

% so what do we do?
When employing a predictive approach I do not rely on significance levels for evaluation. Even more, since the goal is purely heuristic, concerns about bias and endogeneity are shelved. Instead, the primary concern is increasing prediction-power by mitigating both \emph{underfitting} and \emph{overfitting}. Underfitting, meaning creating a model which has failed to learn any salient patterns in the data pertaining to the phenomenon under investigation. Overfitting, meaning the accidental identification of patterns present in the data, yet not present in the real world \citep[165-168]{Mcelreath_2018}. One failure of traditional estimation efforts is the tendency for the models to either over- or underfit \citep[364]{Ward_Greenhill_Bakke_2010}. Thus, avoiding such ills, is of prime concern in this thesis.\par 

% and what do we gain from this?
Testing whether a given model can generate reliable predictions can help identify overfitting, underfitting and other ills. There are many tools available for testing the prediction power of a model. One such tool recommended for conflict studies is out-of-sample prediction \citep{king_zeng_2001b, Ward_Greenhill_Bakke_2010, perry_2013, Schrodt_2014}. This approach is simple and entails the construction of the predictive model(s) on one set of data, leaving another set of data for testing; a training set and a test set. In simplified terms, if the model fits the test set as well as the training set, overfitting has been avoided. If the predictions are also accurate and reliable, underfitting has been avoided. While out-of-sample predictions might not cure the ills, it generates honest evaluations and reveal overfitting and other compromising malaise. As such, out-of-sample prediction is the evaluation approach I use in this thesis.\par

% What happens now?
Adopting similar evaluation frameworks, some scholars have started using prediction to evaluate the salience of given features along with traditional parameter estimation \citep{Goldstone_2010}. Other scholars have abandoned parameter estimation and now combines modern machine learning techniques with the traditional roster of structural features to create predictive tools for policy recommendation \citep{perry_2013}. Lastly, some scholars abandoned both parameter estimation and the traditional roster of features all together, such as \cite{mueller_2016} who rely solely on text data from news outlets to predict future conflicts.\par

% What do you do
In this thesis I will use modern machine learning tools in cohort with past conflict patterns to predict future conflicts. A "causal" discussion regarding whether conflict can be considered truly contagious is both interesting and worthwhile, but it is not the focus of this thesis. My goal is solely to examine the potential of using past conflict patterns for reliable forecasting. As such, high prediction power is my prime concern going forward into this project. This does not mean that theory does not matter. What it does mean is that the theory I employ serves to improve prediction power by informing how I construct my framework ex ante -- and not to argue about causality ex post.\par 

% Bridge:
This concludes my section on the development from estimation to prediction. Another central development is the shift from cross-country studies to more disaggregated studies. That is, from studies taking countries as their unit of analysis to studies using much smaller geographic entities as unit of analysis.\par

%This development will be presented in the following section.\par

\subsection{From cross-country to disaggregated} % ---------------------------------------------------------------------

% What you gonna do there mate?
%In this thesis, rather than countries, the unit of analysis is $0.5\times0.5$ decimal degree grid-cells. This subsection presents the theoretical background and motivation for this disaggregated approach.\par

%  In other words, the aim was to find the probability that some given country would experience internal conflict in some given year.

% Traditional
Through out the quantitative literature on internal conflict and civil war, the unit of analysis has traditionally been \emph{country-years}. That is; a specific country in a specific year. This has been true both when the goal was prediction \citep{Goldstone_2010, mueller_2016} and explanation \citep{Collier_Hoeffler_1998, Fearon_Laitin_2003, Collier_Hoeffler_2004, Hegre_Sambanis_2006}. In this thesis, rather than countries, the unit of analysis is $0.5\times0.5$ decimal degree grid-cells. This subsection presents the theoretical background and motivation for this disaggregated approach.\par

% the problems with this approach
In reality, civil war rarely encompasses entire countries, but are often confined to specific regions of a country \cite[487]{Cederman_Gleditsch_2009}. As such, we miss important nuances and patterns when treating internal conflict as a phenomenon which is necessarily country-wide. Some regional conflicts will be presented as country-wide civil wars, while other regional conflicts will be treated as non-conflicts. Furthermore, some theoretically relevant features cannot readily be modelled when using observations aggregated at country-level. As an example, \cite{Cederman_Gleditsch_2009} argues that the many non-findings regarding the role of ethnic fractionalization in the quantitative literature\footnote{Among the most seminal of these studies are \cite{Fearon_Laitin_2003}, \cite{Collier_Hoeffler_2004}, and \cite{Hegre_Sambanis_2006}} can be attributed to over-aggregation \citep[493]{Cederman_Gleditsch_2009}. A point which is rather convincingly elaborated in \cite{Cederman_Gleditsch_Buhaug_2013} and supported by the results in \cite{Goldstone_2010}. 

% Why did we not do it before?
Indeed the denomination "internal conflict" itself should compel us to explore the phenomenon at a sub-country level. As formulated by \cite{Cederman_Gleditsch_2009}: "If our theories are disaggregated, then our empirical analyses and research designs should reflect this" \citep[490]{Cederman_Gleditsch_2009}. Now, using sub-country units requires more computational power, better models, and not least the right data. Such obstacles have previously impeded sub-national analysis on a wider scale. Encouragingly, recent developments in statistics, technology, and data availability address these issues and make disaggregated studies evermore manageable \citep[446]{ol2010afghanistan}.\par

% What dies this mean for your paper?
By using a disaggregated approach I am able to analyze the local temporal and spatial dynamics of conflicts at a level which both yields more practical insights and is more appropriate given the theoretical foundation \citep[446]{ol2010afghanistan}. If I were to model the spatial patterns of conflict using countries as the unit of analysis, I would be hard pressed to produce insights beyond those most trivial, such as "If country A is experiencing conflict, a neighbouring country B might be at a greater risk of also experiencing conflict". This would tell us nothing about where the conflict is located in country A; whether it is getting closer to country B; whether it engulfs the boarder between A and B; or where in country B it develops. A more disaggregated approach allows me to produce deeper and more fine-grained insights regarding the diffusion of conflict -- a potential powerful policy tool indeed.\par 

%Bridge: what you gonna do next?
This concludes my presentation of two recent and highly relevant developments in the fields of conflict studies and conflict predictions. In the next section I will focus on the challenge at hand; using conflict patterns as conflict predictors.\par 

%Firstly, I present empirical motivation for using past patterns as opposed to e.g. structural features as the basis of my forecasting framework. Secondly, I will also present some of the insights recently produced by the literature on conflict diffusion and contagion. Lastly, I show how past efforts have tried to incorporate the patterns of conflict in predictions and explanations alike. The point is to juxtapose the theory of conflict patterns with past implementations illustrating \emph{what not to do} while also formulating criteria for \emph{what we should do}. Together, these insights will qualify why I have chosen to use Gaussian processes for the challenge of mapping conflict patterns.\par

\section{The Present Challenge}

% Whats gonna happen here mate?
Whether the goals have been explanation or prediction, past efforts have usually focused on structural features such as poverty, deprivation, resources, political regimes etc. \citep[10]{chadefaux2017conflict}. That being said, temporal and spatial patterns of conflict have not gone unnoticed. In the proceeding sections I will first present empirical motivation for using past patterns as opposed to structural features as the basis of my forecasting framework. Secondly, I will present some of the insights recently produced by the literature on conflict diffusion and contagion. Lastly, I show how past efforts have tried to incorporate the patterns of conflict in predictions and explanations alike. 

% What is the point
The point is to juxtapose the theory of conflict patterns with past implementations illustrating \emph{what not to do} while also formulating \emph{what we should do}, thus creating clear theoretical criteria for how conflict patterns should be modelled. These criteria will then serve to qualify the tools I use in the project; particularly Gaussian processes.\par 


%Whether the goals have been explanation or prediction, past efforts have usually focused on structural features such as poverty, deprivation, resources, political regimes etc. \citep[10]{chadefaux2017conflict}. That being said, temporal and spatial patterns of conflict have not gone unnoticed. The proceeding sections will motivate why these patterns are my primary focus, present what we know about conflict patterns, discuss how previous efforts have tried to incorporate conflict patterns, and lastly argue why these efforts leaves plenty room for improvement. The point is to present clear theoretical criteria for how conflict patterns should be modelled. These criteria will then serve to qualify the tools I use in the project; particularly Gaussian processes.\par 

\subsection{Why Conflict patterns}

% How come you choose this approach?
When reliable prediction is the primary goal, we need features with substantial predictive potential. In \cite{Maase} the predictive potential of various features was evaluated in order to map fertile paths for future research regarding the construction of an early-warning-system. The paper showed that, while structural features such as poverty, deprivation, population size, country size etc. did contribute with prediction power, the most important features -- by far -- where those pertaining directly to the spatial and temporal patterns of conflict. Specifically three features: Distance from the geographic unit to the nearest conflict, all past fatalities in the geographic unit, and number of past conflict years in the geographic unit \citep[17-18]{Maase}. As such, the conclusion was that further predictive efforts should focus on extracting even more information from the temporal and spatial dimensions by developing more theoretically and methodically appropriate features pertaining to these dimensions \citep[21-23]{Maase}.\par

A second very important advantage when the goal is actual forecasting is that the data pertaining to the patterns of conflict is more readily available, more up-to-date and more current compared to structural data. To capture the spatial and temporal patterns of conflict I only need event data. That is, data pertaining to past conflicts themselves. Structural data such as wealth measures often take a lot of time to gather and process. The consequence being that the last observations of such data is often quite dated by the time the data is made public. Event data such as that used in this thesis is released much more frequently with the last entry being much more current. As an example, if I used structural data for the project at hand, it would be hard to get complete data more current than 2015. The event data used for this effort, however, has its last entry at 2017, with 2018 already available\footnote{While the data for 2018 has been available from UCDP since 03-06-2019, it was not included in this project since all the most demanding computations where completed before this release. Since I do not actually here forecast into true future years such as 2020 or 2021 the inclusion of the 2018 data would have delayed the completion of this project, without adding much value to the effort.}. As such, the topicality of event data is another important advantage over structural data when forecasting is the goal.\par

\subsection{What we know about conflict patterns}

%What do we know:
% Thay culster in time and space
% They can be a product of cognetation
% They move seemlessly over boarders
% near boarders - men det tager du ikke højde for så ud med det
% Previous research on conflict diffusion has established that internal conflicts often unfolds near boarders \cite[29-30]{Blattman_Miguel_2010} 
% They expand outwards in space from one place to the surrounding places -> seems like cogniation

% what we know:
It is well known that conflicts exhibit discernible patterns. I here present four specific insights from the literature on conflict patterns. Firstly, it has been firmly established that conflicts cluster in time and space, with \cite{crost2015conflict} listing no less then 20 published academic papers supporting this assertion \citep[15]{crost2015conflict}. Secondly, the emerging consensus is that the clustering and diffusion of conflict is often a direct product of contagion rather then merely a bi-product generated through clusters of structural features such as poverty or political regimes \citep{buhaug2008contagion,schutte2011diffusion,crost2015conflict,bara_2017}. Thirdly, it has been found that conflicts often diffuse seamlessly across any administrative boundaries they might encounter \cite[442-443]{ol2010afghanistan}. Lastly \cite{schutte2011diffusion} show how patterns of internal conflict are characterized by distinctive patterns comparable across cases. Indeed, when conflict engulfs one location it is likely to expand outwards from the location over time \citep[151]{schutte2011diffusion}. This pattern of conflict can, at its most fundamental level, be seen as exhibiting bell-curve (or Gaussian) like properties. The closer you are to an active conflict in time and/or space, the more likely it is to spread to your location, largely unimpeded by national boarders. A simple but powerful guideline which will prove very useful going forward.\par

% - The problems are ...
The challenge is to construct a framework which incorporates such insights into the actual modeling of conflict patterns. Unfortunately, past efforts which have aimed at taking conflict patterns into account often fall short of creating theoretically and methodologically coherent operationalizations. Indeed it would not be unfounded to call many past solutions underdeveloped. Naturally this contention requires elaboration and justification which is best done through the power of examples. This leads me to the next subsection.\par

\subsection{How (not) to use patterns as predictors}

% What's gonna happen now?
%Given the widespread consensus that conflicts cluster in time and space, it is no surprise that a number past efforts have aimed to incorporate measures pertaining to temporal and spatial patterns. Unfortunately, modeling these patterns has rarely been the prime objective. The consequence is that the operationalization of these patterns has been ad hoc and underdeveloped. This is true for spatial and temporal patterns alike. In this section I will, in turn, present and criticize some of the past efforts made to capture the temporal and spatial patterns of conflict. In tandem with the insights on conflict patterns just presented, I will use this section to formulate clear theoretical criteria which any framework meant for the identification and extraction of conflict patterns should fulfill. These criteria will in turn qualify the tools presented in the proceeding section.\par

% ex perry's temporal
I will start by presenting how the temporal dimension of conflict patterns have previously been modelled. A deterioration index recently proposed by \cite{perry_2013} can serve as an example of the general state of affairs. Perry's idea is related to the phenomenon of a conflict trap and the notion of some inertia in conflict which might deteriorate over time. This time deteriorating index would be created by including the number of fatalities in some geographic unit for each of the last ten years as features. The deterioration rate is then incorporated through down-weighting these fatalities by dividing with the number of years passed since the corresponding events. Thus, a feature pertaining to fatalities two years ago will have, as its values, half of the fatalities observed that year \cite[14]{perry_2013}. In short, the proposed index tries to fit the insight that the closer in time a geographic region is to past conflicts, the more likely the region is to experience conflict again.\par

% The problem with perry:
As such the heart is at the right place and the sentiment presented in \cite{perry_2013} is also rather symptomatically for the literature at large. The problem is that it is an ad hoc and underdeveloped solution. There is no reason to cap the effort at ten years and there is no theoretical or practical reason to choose the suggested deterioration rate. Instead of dividing with years past it might be more appropriate to divide by half that; or the deterioration rate might have an altogether different functional form, such as an exponential or linear decay function. The point is that if we do not know the relevant functions, efforts should been made to estimate them rather than guess them.\par 

% Better solutions - but we still have a problem
Some scholars have used slightly more involved solutions. \cite{Collier_Hoeffler_2004} use a linear decay function counting years since last conflict and \cite{Hegre_Sambanis_2006} use a linear decay function counting years since last peace. Yet, while such frameworks come closer to actual estimation, the specification of these functions still require ad hoc and arbitrary decisions \cite[501]{Gelman_2013}. Others such as \cite{Cederman_Gleditsch_Buhaug_2013} and \cite{Maase} simply count the number of previous conflicts in the geographical unit of analysis. Surely, we can do better if we employ methods capable of estimating actual functions directly derived from the relevant data.\par

% The spatial problem
Turning to the spatial patterns of conflicts the challenges are, to a large extent, the same. However, the enduring focus on countries inflates the problem even further. To exemplify, a simple dummy is often used to indicate whether some predefined number of neighbouring countries are experiencing conflict or not \citep{Hegre_Sambanis_2006, Goldstone_2010}. The thresholds here often appear ad hoc as \cite{Hegre_Sambanis_2006} has a dummy denoting 1 or more "bad neighbours" \citep[521-522]{Hegre_Sambanis_2006} while \cite{Goldstone_2010} has a threshold of 4 or more bad neighbours \citep[197]{Goldstone_2010}. Surely the mechanisms determining whether conflicts spread from A to B are more complex then this and surely we can do a better job of emulating them.\par 

% Better solutions 1 - but we still ahve a problem
Encouragingly, a few scholars have started to explore more complex patterns, taking into account the size of shared boarders, the country size of bad neighbours, the presence of trans-boarder ethnic kinship, and the explicit number of bad neighbours \citep{buhaug2008contagion, Cederman_Gleditsch_Buhaug_2013, bara_2017}. This is definitely a progressive development, yet the enduring focus on countries still hampers the development of micro-level insights concerning where precisely a conflict unfolds in a given country and where it will expand and diffuse to its surroundings.\par

% Better solutions 2 - but we still have a problem
Two studies which do take a disaggregated approach are \cite{ol2010afghanistan} and \cite{weidmann_ward_2010predicting}. \cite{ol2010afghanistan} do a commendable job of showing the diffusion of conflict from Afghanistan to Pakistan over the Duran Line from a disaggregated perspective, while \cite{weidmann_ward_2010predicting} illustrate how spatial and temporal patterns influenced the civil strife in Bosnia between 1992 and 1995. The challenge is that, using a disaggregated approach, we still have to decide how to include the effects of bad neighbours -- the neighbours now simply being some sub-country unit. Indeed the uncertainty of how many bad neighbours to include only amplifies as we move from country to the sub-country level. Here 2$^{nd}$, 3$^{th}$, 4$^{th}$ and potential n$^{th}$ order neighbours will have to be considered, preferably with some demising influence as a function of distance, given the insight from \cite{schutte2011diffusion}. Furthermore, it seems logical that the magnitude of adjacent conflicts also have an important part to play.\par

%  what we should do
Unfortunately, both \cite{ol2010afghanistan} and \cite{weidmann_ward_2010predicting} choose only to include a dummy for conflict in 1$^{st}$ order neighbours. The operationalization presented in \cite{Maase} is hardly any better; here distance to nearest conflict is used without taking into account the magnitude of this conflict, or the number of other adjacent conflicts zones. And even if the study had included the 2$^{nd}$ nearest conflict, the 3$^{th}$ nearest conflict etc., and scaled the distance by some factor related to the magnitude of conflict, we would still not know if these conflicts surrounded and engulfed the observation of interest or instead clustered neatly and distinctly beside it. The pattern of conflict might matter; the magnitude of conflict might matter; the magnitude of adjacent conflicts in 1$^{st}$, 2$^{nd}$ and n$^{th}$ order might matter. Again the point is clear: modeling features to capture these phenomena must be an estimation effort in and of itself.\par

% Summing up the temporal criteria
To reiterate, what we need with regards to the temporal dimension is a tool that allows incorporation of information drawn from all past (included) years. The magnitude and volatility of past conflicts should influence the probability of future conflicts with some decreasing influence as a function of time. Furthermore this deterioration rate should be estimated through the data itself, rather than being guessed by the researcher.\par

% Summing up the spatial criteria
In regard to the spatial dimension, the criteria are rather similar. We need a tool capable of including information from all relevant events, taking into account both the magnitude and distance of all relevant conflicts. Notably, I do not want to decide how close a conflict has to be in order to be included. Nor do I want to decided the deterioration rate of influence. These elements should be estimated from the available data. Furthermore, the tool should be able to distinguish between different patterns of conflicts. E.g. I want encirclement to exhibit greater influence than tangency.\par

In the next section I present a tool capable of fulfilling all these criteria: The machine learning technique of Gaussian processes. The goal is to demonstrate the nuts and bolts of the tool before I move on to the actual implementation. The section below will also briefly introduce a number of other computational tools used to bind the whole effort together.\par

% why slope, acc and mass?

\section{The Appropriate Tools}\label{tools}

% what going down here mate?
%The aim of this subsection is to introduce the tools used and qualify why these tools are particularly suited for the challenges at hand. 

The main focus in this subsection will be Gaussian processes. In addition I will briefly introduce the final predictive framework and the evaluation metrics used in the final evaluations effort. First however, a small subsection will introduce the concept of \emph{feature engineering}.\par

\subsection{Feature engineering -- capturing theory with data} % ---------------------------------------------------------------------

% what?
Creating features from raw data is called feature engineering. In conventional machine learning this means modifying the data to maximize its predictive power. In political science this often means modeling the data to more accurately capture the theoretical mechanism connecting $x$ to $y$. This could involve changing a wealth measure from absolute to relative, if one believes relative deprivation to be more important than greed or state capacity. When I talk about extracting patterns from event data, I am talking about feature engineering.\par

% Why?
Theoretically appropriate features are naturally needed if we wish to estimate a proposed theoretical relationship between two phenomena \citep{Blimes_2006, Cederman_Gleditsch_Buhaug_2013}. However, this thesis focuses on prediction and I do not estimate any relationships per se. That being said, theoretically viable features will allow us to create models which strives to emulate the true data generating process, thus increasing the predictive power of the model \citep[209-211]{Mcelreath_2018}. As the criteria formulated above illustrates, theory can go a long way in guiding our feature engineering effort -- also when prediction is the prime objective.\par

% So what do you do?
The feature engineering I present in this thesis, will be an estimation effort in itself: Not estimating a limited number of parameters as in traditional linear regressions, but estimating complete functions pertaining to the diffusion of conflict through time and space. To this end I will employ the machine learning technique of Gaussian processes.\par 

\subsection{Gaussian Processes -- capturing theory with method}\label{GPS}  % 

% the things that will happen here:
The point of this subsection is to familiarize the reader with the basics of Gaussian processes and concurrently illustrate how Gaussian processes conform beautifully to the criteria formulated for modelling conflict patterns. I will not get overly technical, but some intuition is needed in order to appreciate the link between theory and method.\par

\subsubsection{From lines to functions}

% A point of reference
To get an appreciation for how Gaussian Processes works, it is helpful to start with a simple linear relationship. In the example presented in equation \ref{eq:lin}, a linear relationship between a target $y$ and the feature $x$ is described by a slope parameter $\beta$ and an error term $\epsilon$. The parameter $\beta$ is drawn from a Gaussian distribution ($\mathcal{N}$) with mean $\mu$ and standard deviation $\sigma$:

\[
\Tilde{y_i} = \beta x_i + \epsilon  \tag{1} \label{eq:lin}
\]
\[
\beta \sim \mathcal{N}(\mu,\sigma)  \tag{2} \label{eq:beta}
\]

% But we can do better
Now, the linear form presented above only allows the relationship between $y$ and $x$ to be described by a straight line with the slope given by $\beta$. We rarely see a linear development in temporal trends, -- at least not in the long -- and regarding spatial patterns it is hard to imagine any natural or social phenomenon taking this shape. As such, we want a way to model more complex functional forms. As a solution we might include n$^{th}$ order terms, which effectively would allow us to depict a function of arbitrarily large complexity:\par

\[
\Tilde{y_i} = \beta_1 x_{i1} + \beta_2 x_{i2}^2 + \dots + \beta_n x_{in}^n + \epsilon  \tag{3} \label{eq:orders}
\]

% Not enough though
However, unless we have very clear theoretical presumptions, we would not know how many orders to include. This would lead to arbitrary decisions. Furthermore, the approach of using higher order transformations is a well known source of overfitting \citep[2]{williams2006gaussian}. We need a framework which can accommodate complex forms and simultaneously combat overfitting.\par

% The solution
Instead of including $n^{th}$ order terms let us imagine some relationship where the function $f$ is given by a Gaussian Process $\mathcal{GP}$. The Gaussian process is closely related to the Gaussian distribution, but instead of being a distribution of numbers, it is a distribution of functions \citep[13-15]{williams2006gaussian}. As such, equation \ref{eq:f} does not denote any specific functional form for $f$. Instead, it denotes that the function $f$ is drawn from a Gaussian process -- just as we draw numbers from a Gaussian distributing. Rather than being defined by the parameters $\mu$ and $\sigma$ a Gaussian process is given by a \emph{mean function} $m$ and a \emph{covariance function} $k$.\par

\[
\Tilde{y} = f(x) + \epsilon  \tag{4} \label{eq:y}
\]
\[
f(x) \sim \mathcal{GP}(m(x),k(x,x'))  \tag{5} \label{eq:f}
\]

% what is the mean function?
The mean function $m$ is our assumption in the absence of knowledge. Where data presents itself, the mean function adapts to the data \citep[3-4]{williams2006gaussian}. In Bayesian terms this mean function can be understood as a weakly informative prior and in frequentist terms as a weak regularization \citep[35]{Mcelreath_2018}. Notably, only very little data is needed to overshadow the mean function. Indeed the surrounding observations and the covariance function $k$ is much more important.\par

% what is you mean function 1?
Usually the mean function is set to the constant zero, but it need not be the case -- it could be any other constant such as the mean of $y$, a slope or any other function which might be appropriate given the specific theoretical underpinnings \citep[28-29]{williams2006gaussian}. In our case, the median and the mode of our target is 0 and the mean is rather close; most places do not experience conflict most of the time -- and since the target is logged, even large outliers, such as the genocide in Rwanda 1994, do not overly influence the mean. As such, a constant of zero also appears as an appropriate mean function here.\par

% what is you mean function 2?
Furthermore, the only situation in this project where I do not have data dictating the mean function is when I am forecasting. Proximate forecastings will be determined by the data pertaining the preceding years and the covariance function $k$. Forecasting to more distant years will increasingly be influenced by the predetermined mean function. That is, the further we move away from the last observed year, the less the data can tell us about future conflicts and the more influence the mean function will claim. Notably, the mean function will only dominate, when I extrapolate into a future too distant for data to reliably describe -- at which point the projections should not be consulted anyhow. Thus, as presented in equation \ref{eq:m} a mean functions of zero will be used going forward.\par 

\[
m(x) = 0 \tag{6} \label{eq:m}
\]

% what is a covariance function?
The covariance function $k$ is the crux of the machinery, often referred to as the kernel. It describes the similarity between each of the observations $x$ and $x'$. It effectuates the assumption that two observations with similar values on $x$ should also have similar values on $y$ \cite[79]{williams2006gaussian}. In the case of time and space this is a quite reasonable assumption.\par 

%Given conflict magnitude pertaining to a geographic location $A$ at year 1990, 2012 and 2013 I would expect the conflict magnitude to be most similar between the adjacent years 2012 and 2013. Likewise, given a specific year I expect the conflict-intensity to be more similar the closer two geographic locations are located to each other. These are of cause simplified assumptions but they align with the insights produced by both \cite{weidmann_ward_2010predicting} and \cite{schutte2011diffusion}. All in all, such assumptions do not appear unreasonable given the general theoretical insights already presented.\par 

% what is your covariance function 1?
The covariance function can be understood as a similarity measure. Many similarity measures are valid covariance functions -- each appropriate for specific tasks given specific theory and assumptions \citep[79]{williams2006gaussian}. In this thesis I use the \emph{squared exponential covariance function}. This covariance function is widely applied and is often a safe choice since the only assumption attached is that we are estimating smooth functions \citep[84]{williams2006gaussian}. As such, it is often used to model trends \cite[119]{williams2006gaussian}.\par 


% what is your covariance function 2?
Naturally, if we find it unsafe to assume smoothness or safe to make more detailed assumptions, other covariance functions might be appropriate \citep[502-503]{Gelman_2013}. It is beyond the scope of this thesis to explore different covariance functions, but future endeavours should test whether more appropriate kernels exist. Here, the squared exponential covariance function will serve as the covariance function of choice going forward. It is given in equation \ref{eq:k}.\par

\[
k(x,x') = \eta^2 exp\left(-\frac{|x-x'|^2}{2\ell^2}\right) \tag{7} \label{eq:k}
\]

% What are hyperparemeters?
From equation \ref{eq:k} it is clear that this is simply a similarity measure. What stands out are the \emph{hyperparameters} $\ell$ and $\eta$. Hyperparameters in this context meaning scale parameters, which can be estimated and determine the volatility of the functions drawn from the Gaussian process.\par

% Ell?
The $\ell$ is denoted the \emph{lengthscale} \cite[501-502]{Gelman_2013} and can be interpreted as the distance we have to move across our $x$-axis before the functional value can change drastically \citep[14-15]{williams2006gaussian}. As such, in the present endeavour $\ell$ also serves as an appropriate rule-of-thumb-limit regarding how far into the future we should consult the extrapolated forecasting. Beyond the last observed year + $\ell$ our data provides little to no information, uncertainty proliferates, and the predefined mean function will start to dominate.\par

% Eta?
The $\eta$ is denoted \emph{amplitude} or \emph{output variance}, and roughly determines the average distance the functions vary from their means \cite[502]{Gelman_2013}. While $\eta$ serves a central part in the covariance function, the substantial interpretation is only of secondary interest given the focus of my project. Thus, I will only devote little attention to this hyperparemater going forth.\par

\subsubsection{Exemplifying Gaussian Processes}

% Example
In \autoref{GP_varying_hp} I have drawn 15 samples from three different Gaussian processes given three different, pre-defined, sets of hyperparameters. The functions are randomly drawn from the \emph{prior}; that is the function space before any data have been introduced to the Gaussian processes at hand.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{GP_varying_hp.pdf}
    \caption{\footnotesize{15 functions drawn from three different GPs (priors) with different hyperparameters $\ell$ and $\eta$. All three GPs uses a squared exponential kernel function and a mean function = 0}}\label{GP_varying_hp}
\end{figure}

% Explaining the 1. example
The thick line is denoted $\mu$ and is the mean value of all 15 functions. It is routinely used as the \emph{most-likelihood} estimate of the functional form, and without any data it defaults to the mean function \cite[3]{williams2006gaussian}. The volatility of $\mu$ seen in \autoref{GP_varying_hp} is only due to the small number of samples drawn. The shaded area denotes $\mu \pm 2\sigma$ where $\sigma$ is the standard deviations. Without any data introduced all functions given by the mean and covariance function are valid estimates. However, introducing data makes some functions more likely than others, effectively limiting the forms of the functions. This is illustrated in \autoref{GP_toy_posterior} where the sampled functions now accommodate the data where it is available.\par  

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{GP_toy_posterior.pdf}
    \caption{\footnotesize{15 samples from a Gaussian process after the introduction of data. The points represent the data. The thick line is $\mu$ and the shaded area represents $\mu \pm 2\sigma$.}}\label{GP_toy_posterior}
\end{figure}

% Explaining the 2. example
%Again, $\mu$ is the thick line and the shaded background represents $\mu \pm 2\sigma$. 
We now see that uncertainty shrinks in regions illuminated by data, and grows the further we move away from data. Note that this Gaussian process is defined without any error term $\epsilon$, thus forcing all drawn functions to cut directly through the data points.\par

% concluding on examples
It should be clear from \autoref{GP_varying_hp} and \autoref{GP_toy_posterior} that if I were to determine the hyperparameter myself and omit an error term $\epsilon$, I could fit most smooth patterns with total precision. This would lead to overfitting and furthermore, I would not have handled the issue of researchers guessing at functions rather than estimating them.\par

% Solution
Encouragingly, this can be amended elegantly. We included an error term $\epsilon$ to the Gaussian processes, which along with $\ell$ and $\eta$, will be estimated through a framework which actively discourages overfitting \cite[114-115]{williams2006gaussian}. Using the estimated error term and hyperparameters in tandem with our data will generate Gaussian processes which will capture the general patterns of the data, but not overfit to noise.\par

% How this solution is don?
These estimates are obtained by maximizing the \emph{marginal likelihood} of the given model \cite[114-115]{williams2006gaussian}. This is a technical and non-trivial mathematical operation which I shall not explore further here\footnote{Curious readers should consult \cite{williams2006gaussian} section 5.4.1 for a complete overview and implementation of the operation.}.\par

% Exemple 3
A toy-example, emulating the subject of conflict magnitude, can be seen in \autoref{GP_toy_eks}. This could be the development in three different conflict-ridden geographic units from 1989 to 2018. Here $\ell$, $\eta$ and $\epsilon$ are estimated from the data. I have only included $\mu$, as the solid lines and the shaded areas represents $\mu \pm 2\sigma$ given the underlying samples. Since we have observations for each year until 2018 there is very little uncertainty regarding $\mu$ during the observed years. Note that the inclusion of $\epsilon$ allows $\mu$ some freedom to vary from the observations, thereby discouraging overfitting to noise.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{GP_toy_eks.pdf}
    \caption{\footnotesize{Three (generated) time-lines of conflict-ridden geographical locations. $\ell$ = 3.64, $\eta$ = 2.54, $\epsilon$ = 0.51}\label{GP_toy_eks}}
\end{figure}% you could make an ex with more noise.

In \autoref{GP_toy_eks} I have extrapolated 10 years ahead to illustrate how the hyperparameters determine the functional form of the functions in the absence of data and how the mean function takes over as we venture into the unknown future. Crucially, I do not estimate a separate sets of hyperparameters for each of the three time-lines, but use the information from all three time-lines to estimate shared hyperparameters for all observations -- so-called \emph{multi-task learning} \cite[115]{williams2006gaussian}.\par

%
% Patterns and non-zeroes
While I do use the same hyperparameter for all time lines in my implementation, I will not use all of the time lines when I estimate the hyperparameters. The reason is that most time lines do not experience conflicts and as such do not tell us anything about conflict patterns. Including such "flat-lines" would yield a misleading estimate of $\ell$. This is because $\ell$ tells us how far we have to move on $x$ to see changes in $y$ and time lines with no conflicts have a consistent conflict magnitude $y$ of $0$ no matter which year $x$ we look at. The result would be an estimated $\ell$ which would reflect that conflict magnitude is largely constant across time \footnote{Indeed, preliminary tests showed that the models would often not converge at all, if I did not add a minimum of noise to the "flat lines".}. Naturally, this is only the case for time lines experiencing no conflicts and not time lines actually experiencing conflicts. To accommodate this issue the hyperparameters are only estimated using time lines with at least two years of conflicts. While two might seem an arbitrary number, it stands to reason that you need at least two none-zero observations to constitute a pattern.\par

% Your assumtions
As such, I assume that the broader patterns of conflict across time (and later space) are comparable across the observations\footnote{Using separated hyperparameters for all observations would be going too far and would mean that we do not think conflict patterns share any similarity across cases. Yet, less demanding assumptions could be made if we used a hierarchical structure which allowed the hyperparameters to be similar without being identical. Notably, that would entail a substantial increase in the computational resources needed.}. While the results from \cite{schutte2011diffusion} do support the use of the same covariance functions across all cases, it would be too bold to claim that the results conclusively support the use of the same hyperparameters across cases. The validity of this assumptions should be scrutinized in future endeavours. For now, however, this will do.\par

% Priors for hyper parameters
%It should be briefly noted that just as I have priors for my Gaussian processes, I also set priors for these hyperparameters and the error term. More specifically, in the examples shown in \autoref{GP_toy_eks} I instruct my program to search for these parameters within a pre-specified distribution as presented in equation \ref{eq:dist_ell}, \ref{eq:dist_eta} and \ref{eq:dist_epsilon}.

%\[
%\ell \sim \text{Gamma}(5,2)  \tag{8}  \label{eq:dist_ell}
%\]

%\[
%\eta \sim \text{HalfCauchy}(2)  \tag{9}  \label{eq:dist_eta}
%\]

%\[
%\epsilon \sim \text{HalfCauchy}(5)  \tag{10}  \label{eq:dist_epsilon}
%\]

%Both the Gamma distribution and the Half-Cauchy distribution are simply probability distribution just as the Normal distribution. The difference is that they have different forms which makes them more suited for the tasks I assign them \citep[280-285]{Mcelreath_2018}. Understanding the nature and properties of these distributions is not necessary in order to appreciate the role they play: they serve as weakly regularizing priors, which merely discourage highly unrealistic values. These priors are easily overwhelmed by the patterns in the data, should the two not align. As such these priors only serve to increase computational efficiency and insure convergence \citep[35-36]{Mcelreath_2018}.\par 

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[scale=0.47]{GP_toy_eks.pdf}
%     \caption{\footnotesize{Three (generated) time-lines of conflict ridden geographical locations. $\ell$ = 3.64, $\eta$ = 2.54, $\epsilon$ = 0.51}\label{GP_toy_eks}}
% \end{figure}

% Concluding on the example:
In the toy example $\ell$ is estimated to be 3.64 with 95\% probability of being between 2.46 and 4.56. A so called 95\% \emph{credibility interval}, which is similar to a traditional \emph{confidence interval} but based on the actual samples rather then estimated \citep[54]{Mcelreath_2018}. Thus, in this example it would be imprudent to extrapolate beyond year 2022 as indicated by the red line and shade in \autoref{GP_toy_eks}. Importantly, this hard limit is only a rule-of-thumb, here given by the mean estimate of $\ell$. The specific uncertainty should \textbf{always} be consulted in practice.\par 

%In this example the uncertainty becomes extremely high after 2020. The mean of the three Gaussian processes are still valid estimates, but the prudent analyst should recognize that a "best guess" does not necessarily equal a "good guess". With this call for prudence in mind, \autoref{GP_toy_eks} does illustrate the potential of using Gaussian processes to model functions pertaining to the temporal pattern of conflict and how this framework allows easy extrapolation into future years.\par

% Changing to a spatial focus
To model the spatial pattern, I simply use latitude and longitude instead of years as features. Here, the point is not to forecast into some unknown geographical space, but rather to let each observed cell incorporate information from all other cells in the data to estimate how exposed the given cell is to conflict. Naturally, the spatial and temporal patterns can also be combined into 3D space including two spatial and one temporal dimension, thus allowing for extrapolation of conflict exposure into future years.\par

% X_new
Having both estimated temporal patterns of conflict magnitude and conflict exposure, forecasting is simply a matter of introducing new future years $x_{new}$ to the time lines and generate Gaussian processes over these elongated time lines.\par 

%The data of each original time line together with the covariance function and the estimated hyperparameters will guide how the function flows into the newly included years. The longer we stray from any observed value the more uncertainty will accumulate and the more influence the mean function will claim.\par 

% integration and differentiation:
Having functions extending into future years also allow for easy extractions of measure pertaining to \emph{slopes}, \emph{acceleration} and \emph{mass}. In practice, the estimate I produce is not an actual formula for the function $f$ but merely the values generated by the function $f$. As such equation \ref{eq:slope}, \ref{eq:acc} and \ref{eq:mass} denotes what I derive and extract, but not the actual mathematical or computational operation used. The values from $f'$, $f''$ and $F$ are simply measures derived from the function $mu$ and can also be used as individual features in a greater predictive framework.\par 

%$f'$, $f''$ and $F$ are simply measures derived from the function $mu$ -- which was simply is maximum likelihood estimate obtained over the Gaussian processes. As such, the values of these functions can also be used as individual features in a greater predictive framework.\par 
% should this be included in the criteria? 
%You should mention why it is theoriticly interesting nad potnetially usfulll

\[
\text{slope} = f'(x)   \tag{11}  \label{eq:slope}
\]

\[
\text{acceleration} = f''(x) \tag{12}  \label{eq:acc}
\]

\[
\text{mass} = F(x) \tag{13}  \label{eq:mass}
\]

%Another interesting potential of this approach is that we can also model a function as a combination of more functions; E.g. a short term trend and a long term trend \citep[505-510]{Gelman_2013}. In such a scenario the $\ell$ of a long term trend would be greater than the combined $\ell$ of both the short and the long term trend. It follows that the identifications of a long term trend would allow me to extrapolate further into the future with less uncertainty. Naturally, this is an opportunity which I shall take advantage of further on.\par

% Back to the criteria
Now, revisiting the criteria I presented earlier, we see that Gaussian processes fulfill them all. In regards to the temporal pattern, they allow incorporation of information drawn from all past (included) years with decreasing influence \citep[410-419]{Mcelreath_2018}. Furthermore, the rate with which past years influence the forecastings is estimated through the data itself. These properties are the reason why Gaussian processes are often used to model functions over time \citep[13]{williams2006gaussian}. Furthermore, no arbitrary "splines" or "knots" needs defining, which is one reason it has been recommend as a substitute to linear decay functions \cite[501]{Gelman_2013}. In regards to the spatial dimension, utilizing Gaussian Processes on a disaggregated geographical grid allows us to analyze and model spatial patterns at arbitrarily high complexity levels only hampered by the resolution of the data and computational power available. We need not define the number of neighbours, since all observations are considered\footnote{That said, we could choose some appropriate subset to improve computation massively \citep{gelfand2016spatial} -- but, this is a project for an other time.}. Furthermore, we do not have to guess the deterioration rate of influence since this is estimated. Lastly, using Gaussian processes to model spatial diffusion, a given geographical cell will be influenced directly by the pattern and magnitudes of conflict around it, in a manner similar to the conflict patterns identified by \cite{schutte2011diffusion}. High magnitude will translate to higher influence, as will encirclement compared to tangency. Indeed, these properties are part of what compelled \cite{gelfand2016spatial} to declare the union of spatial data and Gaussian processes a "beautiful marriage" \citep[86]{gelfand2016spatial}.

%In regards to the spatial pattern this is ..... \cite{schutte2011diffusion} MEN! husk noget med friedman as-if... Du laver ikke noget kausal studio og kikker ikke på nogen mekanisme, men du mener stadig man skal gå efter at emulerer den data generende process i det omfang man har insigt, teori og empiri der muliggøre det. 

% But there are some problems... Below zero and space as degrees is more important then count...
Notably however, it should also be clear from \autoref{GP_toy_posterior} that the framework presented here is somewhat misspecified. Since my base measure for conflict is conflict fatalities (logged), one could argue that I should treat the data as count data. Since I will not be using the extrapolations directly as estimations of death tolls, getting fractions of deaths is not the problem. Instead the issue is that I will incidentally estimate negative conflict magnitude and exposure. This will happen proceeding steep dives in temporal or spatial patterns.\par

% How cloud this be solved - and why it is not a problem
The issue could be handled by formulating the regression presented in equation \ref{eq:y} as a \emph{Poisson regression}. This is conceptually trivial, but unfortunately computationally expensive. Somewhat encouragingly however, I ran initial tests which showed little to no difference when using a Poisson framework. The estimated $\mu$'s rarely dips below zero, and when they do, it is only marginally. As such, I allow this misspecification to persist for the purpose of simplicity and efficiency\footnote{A choice which is not unheard of  \cite[123]{williams2006gaussian}. A similar example can be found in \cite{Gelman_2013} chapter 21. Effectively, it is the same choice made every time a linear regression is used on count data such as death tolls, births, employment and indeed most data revolving around items or people.}.\par %your model is misspecified \cite[123]{williams2006gaussian}

% [Credibility inteval And baysian jazz?]\par++++++++++++++++++++++++

% Next section
The next section will briefly present the theoretical underpinnings of the predictive framework which will transform the patterns estimated into predictions.\par 

%small $\ell$ less noice. Large $\ell$ more noice \cite[115]{williams2006gaussian}
%computational burdensome \citep[503]{Gelman_2013}

\subsection{The predictive framework}
% not the central endeavour!
% Her til er du kommet.

%[GP kunne altså godt bruges some pred i sin egen ret, men...]

% Whats going down here mate?
Gaussian processes can be used as predictive models in themselves; after all we forecast expected values into future years. However, to combine these forecasted values of conflict magnitude, conflict exposure and the derived measures of slops, accelerations and mass into unified predictions of conflict probability, we need another tool. Indeed, Gaussian processes are often utilized as subcomponents in larger models \citep[505]{Gelman_2013}. A suitable predictive framework has been presented in \cite{Maase}. Since the nature of this framework is not a prime concern in this thesis, I will keep this presentation very brief and concise. A more in-depth presentation can be found in the original paper \citep[9-12]{Maase}.\par %While I here implement a number of improvements which I proposed in the conclusion of \cite{Maase} the setup is largely the same.

% The specific elements
The framework consists of a number of individual elements best introduced in turn. First of all we need some algorithm capable of using the patterns extracted to estimate the probability of an event. We know that conflicts are complicated phenomenas ridden with \emph{interactions} \citep[474]{cederman2017predicting}. Thus, the predictive algorithm needs to be able to identify and generate such interactions. Furthermore, we know that conflicts are rare events. As such, the algorithm also needs to be suitable for handling rare events. For the sake of both policy recommendations and theoretical discussion it is also important that the algorithm is not a \emph{black box}; we must be able to asses which "decisions" facilitate the results \cite[476]{cederman2017predicting}. Secondly, even an algorithm tuned for rare events can have difficulty handling the rarity of conflicts. As such I need tools which can mitigate some of the ills of imbalanced data. Finally, we need appropriate metrics for evaluating the potential of the endeavour as a whole. Metrics which again take into account the rarity of the event give us an honest evaluation of the predictive potential of the approach. In the following subsections I show how the extreme gradient boosting algorithm, undersampling and the precision-recall curve can fulfill these roles.\par

%Bayesian Prior Correction ?

\subsubsection{Extreme Gradient Boosting}\label{xgboost}

% what is this shit?
The algorithm I use to estimate both the probability of conflict is called extreme gradient boosting or simply \emph{xgboost} \citep{Chen_2016}. It can be constructed as a regressor to predict a number, similar to a linear regression, or as a classifier to predict probabilities, similar to a logistic regression. In this thesis, I will use it as a classifier. Particularly three characteristics of the xgboost classifier deserve attention; it is a \emph{boosting} algorithm; it consists of \emph{regression trees}; and it is \emph{self-regularizing}.\par
% What will you say about it?
%This is where the similarity between traditional regression analysis and xgboost cease. 
% The xgboost algorithm is a rather new addition to the machine learning toolbox. Thus it is a more complex construct than most political scientist have traditionally been exposed to. Luckily, one does not need a deep technical understanding of the algorithm to appreciate its properties. As such, I shall refrain from getting into the technicalities of the algorithm. That being said, some base-intuition will serve to qualify why this algorithm works remarkable well in the present context. Particularly three characteristics deserve attention; it is a \emph{boosting} algorithm; it consists of \emph{regression trees}; and it is \emph{self-regularizing}.\par

% boosting:
Boosting is used in a variety of machine learning algorithms and entails aggregating a lot of weak classifiers to create a single strong classifier \citep[337]{Friedman_2001}. To this end, we evaluate the results from the weak classifiers and on basis of these results we distribute different weights across our observations. We now run a new batch of classifiers but this time, the observations which were correctly predicted in the first round will carry less weight while observations which were incorrectly predicted will carry more weight. This procedure is iterated until some predefined criteria is met. Lastly, all classifiers are weighted according to their performance and used as a predictive ensemble to estimate the probability of some event \citep[338-339]{Friedman_2001}. This procedure ensures a continuing focus on "hard to classify"-observations, and as such it is a particularly useful approach when working with rare events.\par

% regression tress - interactions er pointen! så er spørgsmålet om du bruger for meget jazz på class/reg...
Naturally, we need to decide which weak classifiers to use for our boosting. Xgboost utilizes regression trees -- which strictly speaking are regressors and not a classifiers but in the xgboost algorithm they are used as classifiers in non-the-less\footnote{The reason the xgboost algorithm uses regression trees rather then decision trees, even for classification, is that each tree produces a continues score as oppose to a binary classification at the end of each branch. These score holds more information then a hard classifications and they can be added together across all trees before being normalized to probabilities and used for classification} \citep[786]{Chen_2016}. We use these regression tress to partition our data according to the split-points which best sort our data according to a predefined target \citep[786]{Chen_2016} In this project it means using my eight features to split grid cells experiencing conflict from cells not experiencing conflict. The features and specific split-points to be used are automatically found by identifying the splits that minimizes a specific \emph{objective function}\footnote{I  will not go into the mathematics of this function, but the curious reader can find it in \cite{Chen_2016} page 786.}\citep[786]{Chen_2016}. We keep splitting partitions until we fail to minimize the objective function further \citep[786]{Chen_2016}. What is crucial about this procedure, is that each split (apart from the very first) effectively constitutes an interaction. Thus the xgboost algorithm is able to automatically identify and generate the most salient interactions.\par
% Regression trees are related to the more traditional decision trees. Yet, unlike decision trees, regression a tree produces a continuous score, which can be converted into probabilities rather then the binary classifications of decision trees \citep[786]{Chen_2016}. 

% self-regularizing
An another important feature of the specific objective function is that is is self-regularizing thus mitigating overfitting. Specifically the objective function penalizes complex tree structures. When the algorithm decides whether to create a new split, it compares the potential improvement in prediction power to the added complexity. If the added complexity is to great compared to the improvement in prediction power the split is not effectuated \cite[787-791]{Chen_2016}. Thus, the regression trees used in the boosting effort searches for relevant patterns in the data, but automatically stops before overfitting commence.\par

% but also a bit more
%There are a large number of other regularization strategies and mechanism which also plays a part in the actual implementation of xgboost \citep[787]{Chen_2016}. However, to review them all is far beyond the scope of this project. Thus I move on to the final characteristics of the algorithm which needs introduction here. Its transparency.\par

% Feature imp.
Since the xgboost algorithm is based on tree structures, we can readily asses which splits generated most prediction power, and thus which features are most \emph{important} in regards to the combined prediction effort. Importance here meaning how much prediction power the specific feature contribute with, compared the the other features \citep[787-788]{Chen_2016}. As such, feature importance should be understood as a relative measure comparing how much information a specific features bring the the effort compared to the other features \cite[367-368]{Friedman_2001}. While this tells us nothing about causation, it is still highly relevant for guiding future prediction frameworks, informing theoretical debates pertaining to explanations and for formulation of concrete policy recommendations.\par

% Bridge - good for undersampling but no good enough
Naturally, this is a very superficial introduction to the xgboost algorithm; nevertheless it serves to illustrate why this algorithm is especially suited for the endeavour at hand. The boosting element makes the algorithm suitable for rare events and the fact that is is based on regressions trees both allows for automatic generation of interactions and for assessment of feature importance. Importantly, the specific trees used in this algorithm are self-regularizing thus discouraging overfitting. However, I can still do more to handle the imbalance of the data. The next section will introduce a number of \emph{undersampling} techniques which I implement to further tackle the rarity of conflict events.\par 

\subsubsection{Undersampling}
% Her til er du nået +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
%\todo[inline]{IN PROGRESS}

% what is Imbalance?
%"Specifically, this form of imbalance is referred to as a between-class imbalance; not uncommon are between class imbalances on the order of 100:1, 1,000:1, and 10,000:1, where in each case, one class severely outrepresents another [4], [5], [6]. [...]Imbalances of this form are commonly referred to as intrinsic , i.e., the imbalance is a direct result of the nature of the dataspace" \citep[1264]{He_2008}

% what is undersampling?
When our data is highly imbalanced, the predictive algorithm will favor the classification of the majority class. In my case this would mean that the framework would be focused on predicting the absence of conflict and not the presence of conflict. A simple solution is to undersample the majority class. As such in our train set we drop a portion of non-events to even the ratio between events and non-events. This is called undersampling \citep[1266-1267]{He_2008}.\par

% Using a boosting algorithm does a good job of mitigating this problem, but I can do more.

% What do you do? - 
Specifically I combine two procedures; \emph{case-cohort sampling} and \emph{informed undersampling}. Case-cohort sampling implies, that I train my model using all available events in the training set together with a randomly drawn and equally sized set of non-events also from the training set \citep[142]{King_Zeng_2001}. This procedure is usually justified by arguing that more information is stored in the events than in non-events \cite[139]{King_Zeng_2001}. While this may be true, I still discard a lot of potentially relevant information this way. To amend this, I also use variant of informed undersampling. Instead of just using one model with one random subset of non-events I use a large \emph{ensemble} of models each using a new random subset of non-events \cite[1267]{He_2008}. Specifically I run the xgboost algorithm 1000 times; each time with a new randomly drawn subset of non-events. As such I am effectively estimating a distribution of conflict probabilities for each cell thus taking advantage of all the information in events and non-events alike. I can then use the mean of these distributions as a maximun likelihood point estimate for the actual probability. Furthermore, given that I can also asses the variance of these distributions, I am also able to infer how certain I am of this point estimate by assessing the credibility interval.\par 

% Introducing the Baysian correction
One issue with this undersampling approach is that the specific probabilities produced will be somewhat inflated. All models are trained to believe that conflict is more common than it is. This can easily be amended using a \emph{Bayesian prior correction} akin to what is presented in \cite{King_Zeng_2001, king_zeng_2001b} and implemented in \cite{Goldstone_2010}. I use the overall probability of conflict in the last observed year in my training set: 2012. This is simply the ratio between events and non-events. I denote the share of events $Pr(E_{2012})$ and the share of non-events $Pr(NE_{2012})$. Then, denoting the estimated probabilities of an event in a specific cell at a specific year $Pr(E_{estimated})$; the corresponding estimated probabilities of a non-event $Pr(NE_{estimated})$; and the corrected probabilities of events as $Pr(E_{corrected})$ the correction can be expressed as follows:

\[
Pr(E_{corrected}) = \frac{Pr(E_{estimated}) \times Pr(E_{2012})}{Pr(E_{estimated}) \times Pr(E_{2012})+Pr(NE_{estimated} \times Pr(NE_{2012})} \tag{14} \label{eq:bayesC}
\]

% concluding on it:
%This correction ensures that the probabilities estimated match the "empirical" probability of conflict given the data at hand. Notably however, this does not make my framework more or less precise. The reason is that, if we want to turn our estimated probabilities into actually classifications we still need to set some probability threshold splitting our estimates dichotomous into predicted events and predicted non-events. This threshold is normally set at 0.5 (50\%), but this threshold is arbitrary as any other number would be \citep[890-891]{weidmann_ward_2010predicting}. Indeed, any such threshold should always be chosen with the specific subject and purpose in mind \citep[194]{Goldstone_2010}. As such, since the correction does not change the relative difference between the estimated probabilities, I could get the same binary classification both with and without the Bayesian correction if I just used two different thresholds. One high threshold for the uncorrected estimates, and one lower threshold for the corrected estimates. However, the probabilities obtained after the correction are still preferable since they incorporate information regarding actually conflict propensity present in the data. As such they correctly conform to how we usually understand probabilities. This is crucial, since I do not recommend using binary classification for decision-making purposes. The actual probabilities hold much more information and should always be consulted.\par

%bridge
Together, the xgboost algorithm and the undersampling approach do a good job of priming the framework for rare events. However, both efforts do so through the model training; the test data that we feed our model will still be imbalanced. We cannot undersample this data since its role is to emulate an unknown future. Undersampling it would imply that we already know which cells that will experience conflict. Unfortunately conventional evaluation matrices tends to judge models used on such imbalanced data too favorable \citep[1264]{He_2008}. The next section introduces the evaluation metrics which I use for this project, and qualify why these are appropriate for evaluating unbalanced data.\par


\subsection{Evaluating the Predictions}
%\todo[inline]{TODO: Precision-recall curve}
%Samme som sidst, men må ikke fremstå som plagiat... Og denne gang skal du også have AUC med for at kunne sammenligne med andre efforts.

% The two different estimation efforts.
%For the construction of my framework I use two layers of estimation. First, I use Gaussian processes to estimate the pattern of conflict magnitude and conflict exposure. Secondly, having extrapolated these patterns into future years and derived the corresponding slope, acceleration and mass, I use these patterns as features in my final predictive framework which is based on the xgboost algorithm and various undersampling methods. I will then use this final predictive framework to estimate the probability of future conflicts. Naturally to assess whether I truly captured any salient conflict patterns with the Gaussian processes I must evaluate how well the final predictive framework performs; how good my predictions actually are.\par

% Out-of-sample prediction
Given the predictive scope of my project, I employ out-of-sample prediction to evaluate the performance of my approach. Out-of-sample prediction is implemented by using a subset of my data to train my predictive framework and another subset to test the framework. Given that my goal is practical forecasting I use the last five years (2013-2017) of my data as test set. As such, I use a ratio of roughly 20\% for the test set, which is rather conventional \citep{Friedman_2001, Ward_Greenhill_Bakke_2010}. To train the predictive framework I use the target $y_{cmBinary}$ from the training set which is a binary measure simply denoting whether any conflict was present in the specific cell some specific year. The features I use are those constructed via Gaussian processes $X_{patterns}$ also pertaining to the training set. After the training is complete the extrapolated values $X_{patternsEX}$ covering the test years are introduced into my predictive framework to produce out-of-sample predictions $\tilde{y}_{prob}$. These prediction can then be evaluated against the empirical observations $y_{cmBinary}$ contained in the test set.\par

% What are yo gonna do?
%Now, having my predictions $\tilde{y}_{prob}$ (test set), and the empirical observations $y_{cmBinary}$ (test set) 
Now I need some metric which can capture how well  $\tilde{y}_{prob}$ fits $y_{cmBinary}$. There are a plethora of such metrics available. The metric I will primarily use is the \emph{precision-recall} (PR) curve and the three related metrics \emph{recall}, \emph{precision} and the \emph{average precision} (AP) score. However, to put these metrics into perspective I will also introduce the metrics \emph{accuracy} and the \emph{Receiver Operating Characteristic} (ROC) curve along with the corresponding metric the \emph{Area Under the Curve} (AUC) score. The reason I include more then one metric well become apparent as I introduce each measure.\par

% Criteria for a good measure/why no hard threshold.
The metrics used must fit the challenge; not least the fact that I am dealing with imbalanced data. Furthermore, many metrics require that I set some hard threshold partitioning my predictions into predicted events and predicted non-events. The framework I use, however, does not produce binary results but probabilities. As such $y_{cmBinary}$ might by binary, either $0$ or $1$, but $\tilde{y}_{prob}$ can take any value between $0$ and $1$. These probabilities are in themselves far more informative than a simple binary classification. As such, the metrics I use should not depend on the formulation of some arbitrary threshold.\par 

% Introducing Acc and error/ the problem the Acc and error
The most commonly used metric for classification is accuracy. Accuracy simply denotes the proportion of correctly predicted observations. As such accuracy is easy to interpret and is intuitively appealing. However, there are two problems. Firstly, the measure requires that we choose a hard threshold. Secondly, when the data is imbalanced we can achieve a rather high accuracy just by predicting in favor of the majority class every time. If conflict only happens 5\% of the time we can get an accuracy of 95\% by predicting that conflict never happens. Thus accuracy is not suited for imbalanced data \citep[1264]{He_2008}. As such, even though it is the most commonly known measure, I will not be using this metric going forward.\par

% Introducing AUC (and TO/TN/FN/FP)
The metric most commonly chosen to avoid the problems afflicting accuracy is the ROC-curve and the summarizing measure the AUC scores \citep[1277-1278]{He_2008}. The ROC curve circumvents the issue of a hard threshold by evaluating each possible threshold. Specifically the ROC curve denotes the trade-off between the \emph{true positive rate} ($TP_{rate}$) and the \emph{false positive rate} ($FP_{rate}$) by plotting the $TP_{rate}$ over the $FP_{rate}$. This curve can then be interpreted visually or summarized by the area under it; the AUC score \citep[1277-1278]{He_2008}. Denoting the actual number of negatives $N_C$ and the actual number of positives $P_C$, the rates can be expressed by equation \ref{eq:TPFP}.\par

\[
TP_{rate} = \frac{TP}{P_C};\quad FP_{rate}=\frac{FP}{N_C} \tag{15} \label{eq:TPFP}
\]

% concluding on AUC
As such the ROC curve does not require me to specify a hard threshold and it illustrates clearly the trade-off between true positives and false positives at all possible thresholds. Given these attributes it has been widely used in conflict studies \citep[14]{chadefaux2017conflict}, and even been coined as the "gold-standard" in this field \citep[366]{perry_2013}. 

% The problem with AUC in imbalanced problems - and why it is still here
However, while better suited for imbalanced data than accuracy, the ROC curve and AUC score tends to judge model-performance on highly imbalanced data too favorable \citep[1278]{He_2008}. Looking at equation \ref{eq:TPFP} it is clear that if we can increase $N_C$ without increasing the $FP$ rate we will get a better score. As such, including Antarctica would probably improve my results substantially. Antarctica would constitute a large number of non-events ($N_C$) and given my focus on past conflict patterns my framework would never produce a false positive ($FP$) here, leading to a lower false positive rate ($FP_{rate}$).\par

% Why is it still here
Despite this weakness I will still report the AUC score. The simple reason is that the metric is widely used and rather commonly known. The ROC curve and AUC score are points of reference for most political scientist working with advanced quantitative methods and including the measure will make it easier to compare my project with past efforts. That being said, we should move on to more appropriate metrics better suited for highly imbalanced data. Therefore, my main focus will be on the PR curve.\par

% Intorducing Precision, Recall, PR-curve and average precision.
The PR curve shares many similarities with the ROC curve. It also denotes the trade off between two measures, specifically recall and precision. Notably recall is just another name for the true positive rate $TP$, while precision denotes the rate of true positive out of all positives. As such, recall and
precision can be expressed as in equation \ref{eq:recall/precision}.\par% and \autoref{eq:precision}.\par 

\[
precision = \frac{TP}{TP+FP}; \quad recall = \frac{TP}{TP+FN} \tag{16} \label{eq:recall/precision}
\]

% \[
% recall = \frac{TP}{TP+FN} \tag{17} \label{eq:precision}
% \]

% int the equations:
It is clear that since $TP+FN = P_C$ recall is indeed simply the true positive rate. In substantial terms precision denotes the share of classified conflicts which were actual conflicts, while recall denotes the share of all actual conflict I manage to capture. These two measures are in themselves valid metrics and are both relevant when dealing with imbalanced data, but since these metrics rely on components such as $TP$'s, $FP$'s, $TN$'s and $FN$'s, both metrics require a hard threshold. Encouragingly, Combining them into a curve for all possible thresholds eliminates the need for any hard threshold and concurrently summarizes both metrics neatly \citep[1287]{He_2008}.\par

% Average precision
The PR curve can be interpreted visually and also be summarized in a single measure called average precision $AP$. This summarizing metric denotes a weighted mean of precision at each possible threshold. The weighting is the increase in recall from the previous threshold. Denoting recall $R$, precision $P$, and the different thresholds as $n$ the AP score can be expressed as seen in equation \ref{eq:ap}.\par

\[
AP = \sum_n (R_n-R_{n-1})P_n \tag{17} \label{eq:ap}
\]

% compared to AUC?
The AP score has a number of similarities with AUC and can be thought of as the area under the PR curve  \citep[349-350]{su2015relationship}. The key difference is that AP places more emphasis on identifying high probability events than identifying low probability events \citep[350]{su2015relationship}. The interpretation also differs from AUC. An AUC score of 0.5 denotes a classifier which is no better than random. This is not the case with AP where 0.5 can be a decent score depending on the context \citep[350-351]{su2015relationship}. Specifically, an approximation of the "random" baseline of AP is given the share of events \citep[132]{bestgen2015AP}. If the data is precisely balanced the baseline for the AP score is 0.5 just like the AUC score. If the data is imbalanced, say 5\% events versus 95\% non-events, the baseline for the AP score will be 0.05. As such, AP is a good summarizing measure for judging and comparing the predictive performance of models on imbalanced data without setting a hard threshold.\par

%I will use both measures to compare my results with the results presented in \cite{Maase} and to show how the predictive power of my framework changes as I move further into the future.\par

% The downside and the solution
The downside of AP is that it is not particularly interpretable on a substantive level. As such, to best present the potential of my framework in substantial terms I will use the AP score in tandem with recall and precision. In the same manner I will also use the components $TP$, $FP$, $FN$ and $TN$ for visualizations. This will naturally demand that I set some hard threshold. I use a threshold which generates a number of predicted events which roughly matches the number of actual events in the last observed year: 2012. Together these measures will ensure both honest evaluation and interpretability of my framework.\par % you could also map with different thresholds....

% Bridge
Having presented the methods which I will use to construct my predictive framework, I will now move on to present the specific data which I use. As such the next section serves as the last primer before I present the implementation and the results.\par

\section{The Chosen Data}\label{data}% you have the essence in the introduction...

% Whats go happen here mate?
In this paper I use two data sources. A spatial grid which divides the world into cells is obtained from the PRIO grid database \citep{Tollefsen_2012} while the Upssala Conflict Data Program (UCDP) \citep{Sundberg_2013, Croicu_Sundberg_2017} provides all substantial data used. I will present each source in turn below.\par

\subsection{The PRIO grid}

%What PRIO DATAbase?
%The PRIO grid database holds a large variety of features denoting wealth, mountains, ethnic discrimination and much more, partitioned at sub-national level. In this paper, I do not use any of these features. I only use the geographical base-grid which the database provides. Using a preconstructed base-grid not only save me the hassle of constructing my own grid, it also allows for PRIO grid features or data prime for the PRIO grid to be easily incorporated in future endeavours.\par

% What the PRIO gird
The PRIO grid is a global grid dividing the world -- excluding Greenland and Antarctica -- into grid cells of $0.5 \times 0.5$ decimal degrees, which corresponds to roughly $50km\times50km$ at the equator \citep[367]{Tollefsen_2012}. It is constructed as geo-spatial data and primed for collaboration with the data from UCDP. As such merging and handling these two data sources is a trivial task. However, due to computational limitations I have chosen only to use a subset of the full globe. This subset is presented in \autoref{map_2017}.\par

% er tallen serif?
\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.5]{log_best_2012_samples.pdf}
    \caption{\footnotesize{Conflict fatalities (logged) from 2017 according to UCDP aggregated at the level of PRIO grid cells. Encompasses the geografical area given by the following coordinates; north: $50^{\circ}$ , south: $-10^{\circ}$ , east: $100^{\circ}$ , west $-20^{\circ}$}}\label{map_2017}
\end{figure}

%interpreate the map
In \autoref{map_2017} I have plotted all conflict fatalities (logged) classified by UCDP in 2017 aggregated at PRIO grid cell level in the chosen subset. While the exact boarders of the subset are rather arbitrary, I have aimed to capture as many conflicts as possible across the surveyed timespan in one continuous geographic area.\par

%As such, the subset encompasses more or less conflict-prone regions such as Balkan, Caucasus, Syrian, Iraq, Yemen, Palestine, Rwanda, Kashmir, Afghanistan, Nepal, Aceh, Sri Lanka, Rwanda, Mali, Nigeria and many more. With more computational power available, the rest of the globe could easily be incorporated into my framework.\par

% selecting on the dependable
Naturally, this is selection on the dependable variable, and will lead to bias in any estimation effort \citep[129-130]{king1994designing}. However, I have no traditional parameters to estimate and no claim of effect or causality to make. Thus, since accurate prediction is the goal, selection on the dependable variable is less of a problem. Furthermore, any ills could easily be handled through yet another Bayesian correction \citep[627-628]{King_Zeng_2001}. That being said, it would still be imprudent to extrapolate any insights I produce -- such as the estimated hyperparameters -- beyond the geographical scope of this project. Correspondingly, the probabilities I produce should be seen as conditional on the geographical subset under scrutiny.\par

% This precaution, however, is not enough. On one hand selecting a geographic area with relatively many conflicts is a way to battle the imbalance of the data. Indeed " the real information in the data lies much more with the ones than the zeros" \citep[139]{king_zeng_2001b}. One the other hand, however, our model will "believe" that conflict is much more common then it is. This is already a problem given the effort to battle to imbalance of the data as presented in \autoref{imbalanced} and thus the remedy the same already introduced; a baysian correction similar to that presented in \cite{King_Zeng_2001} and implemented in \cite{Goldstone_2010}.\par 
% Er det den ritige henvising?

% Having present, the context, the challenge, the tools and the data which I use, the next section while present the implementation.\par
% Bridge
With this call for prudence I now introduce the substantial data which I will use to capture the patterns of conflict magnitude and exposure.\par

\subsection{The UCDP data}

%\todo[inline]{Her du skal sige hvilket år der er test og hvilke der er train}
% Two layers; many different y and x's -> how to keep up?


% What is the UCDP?
My framework consists of two layers of estimations. First, I estimate the patterns of conflict magnitude and conflict exposure. Then I use these estimated patterns to estimate the probability of conflict in a cell at some future year. The only data I need for these two endeavours is data pertaining directly to the history of conflict patterns. For this I use data from the UCDP. Specifically I utilize the UCDP Georeferenced Event Dataset (GED) Global version 18.1 \citep{UCDP_2017}. The data contains records of conflict fatalities and the corresponding coordinates and dates. I aggregate this data to yearly fatalities in grid cell and utilize data from 1989 through 2017.\par 

% How is conflict fatalities defined
I define conflict fatalities using the minimal definition from UCDP. They include in their data all fatalities where "[...] armed force was used by an organized actor against another organized actor, or against civilians, resulting in at least 1 direct death at a specific location and a specific date” \cite[9]{Croicu_Sundberg_2017}.\footnote{See definitions regarding "armed force" and "organized actor" page 10 and forth of \cite{Croicu_Sundberg_2017}.}\par 

% onlys intra
Since I limit my project to intra-state conflict, I only include estimates from incidents which do not include two different nations as the organized actors. What is left are all conflict fatalities induced by internal conflicts, civil strife and terror.\par

% what do you uses?
There are a number of interesting features included in the UCDP data. I only use the feature \emph{best}. This feature is defined as: "The best (most likely) estimate of total fatalities resulting from an event" \cite[7]{Croicu_Sundberg_2017}. To get my raw measure of conflict magnitude, used as a target in my pattern estimation efforts, I take the log of this measure.\par

\[
\text{conflict magnitude} = log(\text{conflict fatalities}) \tag{18} \label{eq:cm}
\]

% Why log?
The log-transformation is warranted since the data is highly skewed; across all years the majority of the cells experience no conflict fatalities, while a few cells experiences a lot of conflict fatalities. Furthermore a logged transformation mitigates the challenges of extreme outlets such as Rwanda 1994.\par

% Different y's and x'x
This measurement, conflict magnitude, aggregated at a yearly level and distributed across the PRIO grid is the basis of my whole framework. In the first estimation layer it will be the target $y_{cm}$ as I estimate the patterns of conflict magnitude and years will constitute the single feature $x_{year}$. As I estimate the static conflict exposure for each year it will also be the target $y_{cm}$, while longitude and latitude will be the features $X_{ll}$. In the second layer, a binary transformation of conflict magnitude will constitute the target $y_{binary}$ when I estimate the probability of conflict, while the features will be the eight features derived from the first estimation layer will constitute the features $X_{patterns}$.\par

%bridge 
Having presented the context of my project, the tools I employ and the data used, I now move on to the actual creation of my framework.\par

\section{Compiling the framework}% Better name?

% What is gonna happen here?
The following section is divided into two subsections corresponding to the two layers of estimation I employ. Firstly, I estimate the temporal and spatial patterns of conflict using my test set and Gaussian processes. These patterns will then be extrapolated into future years corresponding to those of the test set. From these elongated time lines I will derive the slope and acceleration pertaining to each year, along with the total conflict mass inhabiting each time line. This yields eight features. Secondly, using xgboost and undersampling, these eight features will be combined in my final predictive framework to estimate the probabilities of conflict in each individual grid cell given the test years from 2013 through 2017. An overview of the two layers of estimations is presented in \autoref{overview}.\par

% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{1cm} m{1.8cm} m{6cm} m{0.2cm} m{4cm}}
	%\hline
	\textbf{Estimations}
	\\Overveiw\\
	\hline
    & Target $(y)$                            &  Features $(x/X)$                    && Estimate $(\tilde{y})$  \\
	\hline
	\\
	\thead{\\}                  &$y_{cm}$                                & $x_{year}$                           && $\tilde{y}_{cm} = f_{cm}(x_{year}) + \epsilon_{cm}$        \\
    \thead{First\\layer}        &$y_{cm}$                                & $X_{ll} =$ $x_{long}$, $x_{lat}$       && $\tilde{y}_{sce} = f_{sce}(X_{ll}) + \epsilon_{sce}$           \\
    \thead{\\}                  &$f_{sce}(X_{ll})$                       & $x_{year}$                           && $\tilde{y}_{dce} = f_{dce}(x_{year}) + \epsilon_{dce}$        \\
    \\
    \hline
    \\
    \thead{Second\\layer}       &$y_{cmBinary}$                           & $X_{patterns} =$  $f_{cm}(x_{year})$, $f'_{cm}(x_{year})$, $f''_{cm}(x_{year})$, $F_{cm}(x_{year})$, $f_{dce}(x_{year})$, $f'_{dce}(x_{year})$, $f''_{dce}(x_{year})$, $F_{dce}(x_{year})$     &&$\tilde{y}_{prob}$ \\
    \\
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{Targets, features and estimates pertaining to the various estimation efforts in the two next sections. For brevity I omit the extrapolations in the table}}\label{overview}
\end{table} 

\subsection{First layer: Patterns as features}

% in wht order
To construct these eight features, I start by estimating and extrapolating the functions pertaining to conflict magnitude $f_{cm}$. I then move on to estimate and extrapolate the function pertaining to conflict exposure $f_{dce}$. Finally I derive the slope, acceleration and mass corresponding to each of these two base functions.\par

% Esitmateing cm
To estimate the function pertaining to conflict magnitude via Gaussian processes I use conflict magnitude as my target $y_{cm}$ and the years in my training set as the sole feature $x_{year}$. The mean function $m_{cm}$ is simply a constant $0$ and the covariance function $k_{cm}$ is the squared exponential function. Mathematically this is expressed in the equations \ref{eq:form_cm}, \ref{eq:func_cm}, \ref{eq:m_cm} and \ref{eq:k_cm}.\par

%All corresponding priors can be found in the appendix, \autoref{cmPrior}.\par

\[
\tilde{y}_{cm} = f_{cm}(x_{year}) + \epsilon_{cm} \tag{19} \label{eq:form_cm}
\]

\[
f_{cm}(x_{year}) \sim \mathcal{GP}_{cm}(m_{cm}(x_{year}),k_{cm}(x_{year},x_{year}')) \tag{20} \label{eq:func_cm}
\]

\[
m_{cm}(x_{year}) = 0 \tag{21} \label{eq:m_cm}
\]

\[
k_{cm}(x_{year},x_{year}') = \eta_{cm}^2 exp\left(-\frac{|x_{year}-x_{year}'|^2}{2\ell_{cm}^2}\right) \tag{22} \label{eq:k_cm}
\]

% hyper parameters and sample
I first estimate the hyperparameters $\eta_{cm}$ and $\ell_{cm}$ along with the error term $\epsilon_{cm}$ using time lines with two or more years of conflict. I then introduce $x_{yearNew}$ which is a vector of all years; training and test alike. Using the estimated hyper parameters and the data contained in the training set I now generate Guassian processes for each time line across all years included in $x_{yearNew}$. The estimated hyperparameters can be found in \autoref{cm_hp} and an illustrative sample of 15 estimated functions and corresponding time lines can be seen in \autoref{cm_sampel_eks}.

% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{3cm} m{3cm} m{3cm} m{3cm}}
	%\hline
	\textbf{Hyperparameters}\\
	\text{Conflict magnitude}\\
	\hline
                            &  \thead{Point estimate\\(mean)}   & \thead{Standard\\deviation}   & \thead{95\% Credibility\\interval} \\
	\hline
	$\ell_{cm}$             & \thead{3.56}        & \thead{0.24} 	& \thead{3.08 - 3.99}                             \\
    $\eta_{cm}$             & \thead{1.36}        & \thead{0.04} 	& \thead{1.26 - 1.39}                             \\
    $\epsilon_{cm}$         & \thead{0.95}        & \thead{0.02} 	& \thead{0.91 - 0.98}                             \\
  
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{The tabel contains the estimated hyperparemeters pertaining to $\tilde{y}_{cm}$. }}\label{cm_hp}
\end{table}

% Int. the estimated hps
The most informative entry in \autoref{cm_hp} is the lenghtscale $\ell_{cm}$. Given the data and my model specifications there is a 95\% probability that $\ell_{cm}$ lies between 3 and 4 with my point estimate being 3.6. As such, the patterns I extract should be somewhat reliable until three years past my last observation. Thus, given that my training set ends at 2012, I expect my prediction power to drop substantially beyond 2015. \par

% eta and epsilon. Not that big difference. = maybe short and long term?
The error term $\epsilon$ and the amplitude $\eta$ are most informative when assessed in tandem. Given the ratio between $\eta$ and $\epsilon$ it appears that my estimated functions are able to explain well over half of the variations in the data. This is an early indication that conflict patterns can indeed be captured. On the other hand it also shows that there is still a lot of variation not captured by my estimated functions.\par %and? Men du vil jo heller ikke fange alt? Det ville være overfitting

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{cm_15_samples.pdf}
    \caption{\footnotesize{The estimated temporal patterns of conflict magnitude from fifteen randomly drawn time lines. For visualization purposes all fifteen samples has minimum one event over the course of the train years. The solid line is the maximum likelihood point estimate of $\mu_{cm}$ and the corrosponding shading denotes $\mu_{cm} \pm 2\sigma_{cm}$. At such, given the model and the data there is roughly a 95\% that $\mu_{cm}$ is within this zone. The scatter points are the actual observed $y_{cm}$ values from the test set. The estimated hyperparameters are $\ell_{cm}$ = 3.6, $\eta_{cm}$ = 1.1, $\epsilon_{cm}$ = 0.9}\label{cm_sampel_eks}}
\end{figure}

% Int. the samples  -> critaria for good temporal patterns.-> whats the point?
Turning from the hyperparameters to the estimated functions; \autoref{cm_sampel_eks} shows a sample of 15 randomly drawn time lines and their corresponding functions $f_{cm}$. These functions have been extrapolated to cover all years; $x_{yearNew}$. As such, the estimated functions continue beyond the training years 1989-2012 into the test years 2013-2017. Thus, what I illustrate with the small sample in \autoref{cm_sampel_eks} is how conflict has waxed and waned in the geographical grid cells over the course of the training years, and how this pattern can be expected to continue into the test years given the data and model specification employed.\par 

%What about the critarias?\par
The samples in \autoref{cm_sampel_eks} illustrates in practice how the criteria for theoretical coherent (temporal) conflict patterns are fulfilled by using Gaussian processes. Information is drawn from all past included years; the volatility of past conflict impact the magnitude of estimated future conflicts; the influence of past observations decline over time; and the deterioration rate of influence is estimated, as opposed to guessed at.\par

% What it does not capture: two steps ot ammend
The functions $f_{cm}$ only capture the temporal patterns. To capture the spatial patterns more explicitly I need $f_{dce}$. But to get this function I must first estimate a 2D Gaussian process for each separate year in the training set using longitude and latitude as features ($x_{lat}$, $x_{long}$: $X_{ll}$)\footnote{While $X_{ll}$ actual represents a $2\times n$ matrix and not vector, I will still keep all mathematical notations as vector notations for simplicity.} and conflict magnitude ($y_{cm}$) as target. This is the measure static conflict exposure ($sce$). It is "static" since I have yet to take time into account -- the measure simply tells us how exposed a given cell is to conflict in a given year, without taking into account any temporal patterns. Secondly, I simply estimate a 1d Gaussian process similar to that already implemented to estimate $\tilde{y}_{cm}$. Once more I use $x_{year}$ as the sole feature, but instead of conflict magnitude ($y_{cm}$) as target, I use the values obtained through $f_{sce}$ as my target $y_{dce}$. The estimate I derive is one of dynamic conflict exposure $\tilde{y}_{dce}$. Instead of only taking into account the past patterns of the individual cell, this measure takes into account the past patterns of all cells in the relevant proximity.\par 

% SCE
Starting with the first step I estimate the shared hyperparameters and error term $\ell_{sce}$, $\eta_{sce}$ and $\epsilon_{sce}$ for a 2D Gaussian process pertaining to the spatial conflict patterns pertaining to each specific year in the training set. Conflict magnitude is my target $y_{cm}$ and I use longitude $x_{long}$ and latitude $x_{lat}$ as the features $X_{ll}$. This gives me an estimate of static conflict exposure $\tilde{y}_{sce}$. The mathematical notation can be found in equations \ref{eq:form_sce}, \ref{eq:func_sce}, \ref{eq:m_sce} and \ref{eq:k_sce}.\par

%The priors for $\epsilon_{sce}$, $\eta_{sce}$, $\ell_{sce}$ can all be found in the appendix, \autoref{scePrior}.\par

\[
\tilde{y}_{sce} = f_{sce}(X_{ll}) + \epsilon_{sce} \tag{23} \label{eq:form_sce}
\]

\[
f_{sce}(X) \sim \mathcal{GP}_{sce}(m_{sce}(X_{ll}),k_{sce}(X_{ll},X_{ll}')) \tag{24} \label{eq:func_sce}
\]

\[
m_{sce}(X_{ll}) = 0 \tag{25} \label{eq:m_sce}
\]

\[
k_{sce}(X_{ll},X_{ll}') = \eta_{sce}^2 exp\left(-\frac{|X_{ll}-X_{ll}'|^2}{2\ell_{sce}^2}\right) \tag{26} \label{eq:k_sce}
\]

% hyper parameters and sample
As before, I first estimate the hyperparameters and error term $\eta_{sce}$, $\ell_{sce}$, $\epsilon_{sce}$. Since I have only estimated the function over spatial dimensions I cannot extrapolate into future years $x_{yearsNew}$ (yet) and I have no intention of extrapolating the patterns into unknown geografical regions so I do not introduce any $X_{llNew}$. The estimated hyperparameters and error term can be found in \autoref{sce_hp}. To visualize the output, the static conflict patterns pertaining to 2012 are plotted in \autoref{sce_sampel_eks}.\par


% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{3cm} m{3cm} m{3cm} m{3cm}}
	%\hline
	\textbf{Hyperparameters}\\
	\text{Static conflict exposure}\\
	\hline
                            &  \thead{Point estimate\\(mean)}   & \thead{Standard\\deviation}   & \thead{95\% Credibility\\interval} \\
	\hline
	$\ell_{sce}$             & \thead{1.33}        & \thead{0.02} 	    & \thead{1.26 - 1.39}                             \\
    $\eta_{sce}$             & \thead{0.20}        & \thead{$<$0.01} 	& \thead{0.19 - 0.20}                             \\
    $\epsilon_{sce}$         & \thead{0.48}        & \thead{$<$0.01} 	& \thead{0.47 - 0.48}                             \\
  
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{The tabel contains the estimated hyperparemeters pertaining to $\tilde{y}_{sce}$. }}\label{sce_hp}
\end{table}

% Int. the estimated hps
Looking at the hyperparameters, the most informative is once again the lenghtscale $\ell_{sce}$. There is a 95\% probability that $\ell_{sce}$ is between 1.2 and 1.4 with my point estimate being 1.3. In substantial terms this tells us that conflict magnitude is relatively stable within a radius of roughly 130 kilometers. To illustrate the actual spatial patterns estimated I have plotted the obtained $\tilde{y}_{sce}$ values pertaining to 2012 in \autoref{sce_sampel_eks}. Similar, but unconnected, output is estimated for all years in the training set.\par

% Something about eta and epsilon - eta is smaller then epsilon.. That is somthing to comment on. A lot of things cell specific stuf is not captured here.  But we also wants general patterns
The ratio between $\eta$ and $\epsilon$ tells us that there is a lot of variation not explained by our 2D function. Indeed, with $\epsilon$ being twice as large as $\eta$ it appears my function only captures $1/3$ of the total variation in conflict exposure. There are two simple reasons why this is not overly surprising. First of all there are many unknown/unincluded factors separating the different cells from each other. One cell might include a major city, another a great lake. One might be inhabited by a wealthy elite and another by a marginalized and/or poor minority. Secondly, just because a cell did not experience conflict, it does not mean that there was no risk of conflict. What the four features pertaining to the spatial patterns of conflict are meant to capture is not whether or not a given cell experience conflict, but simply whether or not it is exposed to conflict. Thus this ratio between $\eta$ and $\epsilon$ poses no apparent problem.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{sce_2012_samples.pdf}
    \caption{\footnotesize{The estimated 2D function $f(X_{ll})_{sce}$ pertaining to the year 2012.}}\label{sce_sampel_eks}
\end{figure}

%Int the plot. -> critaria for good spatial patterns.-> whats the point?
What I illustrate in \autoref{sce_sampel_eks} is simply an estimated 2D function over the conflict magnitude of all cells in 2012. We see that the spatial patterns estimated conforms neatly to the theoretical expectation regarding spatial conflict patterns. Information is drawn from all relevant events in the specific year, taking into account both the magnitude and the distance of said events, the deterioration rate of influence is estimated from the available data; conflict diffusion appears fundamentally bell-shaped and radiates out from specific centers. Further more, looking at examples such as Nigeria, Somalia and especially Afghanistan we also see how patterns such as circulation produces different results compared to tangency.\par  

% Moving on to dce.
To connected this measure across time and facilitate extrapolation into future years the next step is to estimate $\tilde{y}_{dce}$. To this end, I simply repeat the steps taken to estimate $\tilde{y}_{cm}$. Now, instead of using $y_{cm}$ as target I use the estimated values obtained from $f_{sce}(X_{ll})$ as my target. I denote this estimate $\tilde{y}_{dce}$. Beyond that small change, the procedure is identical. The mathematical specifications are presented in equation \ref{eq:form_dce}, \ref{eq:func_dce}, \ref{eq:m_dce} and \ref{eq:k_dce}.\par

%The priors for $\epsilon_{dce}$, $\eta_{dce}$, $\ell_{dce}$ can be found in the appendix, \autoref{dcePrior}.\par

\[
\tilde{y}_{dce} = f_{dce}(x_{year}) + \epsilon_{dce} \tag{27} \label{eq:form_dce}
\]

\[
f_{dce}(x_{year}) \sim \mathcal{GP}_{dce}(m_{dce}(x_{year}),k_{dce}(x_{year},x_{year}')) \tag{28} \label{eq:func_dce}
\]

\[
m_{dce}(x_{year}) = 0 \tag{21} \label{eq:m_dce}
\]

\[
k_{dce}(x_{year},x_{year}') = \eta_{dce}^2 exp\left(-\frac{|x_{year}-x_{year}'|^2}{2\ell_{dce}^2}\right) \tag{29} \label{eq:k_dce}
\]

% hyper parameters and sample
I estimate the relevant hyperparameters $\eta_{dce}$ and $\ell_{dce}$ and the error term $\epsilon_{dce}$. The patterns are then extrapolated into the test years using $x_{yearNew}$. I present the estimated hyperparemeters in \autoref{dce_hp}. To illustrate the estimated patterns I draw 15 adjacent time lines which are plotted in \autoref{dce_sampel_eks}.\par 

% HP table
\begin{table}[!htb]
\begin{center}
\centering
% 	\begin{tabular}{l*{4}{c}}
	\begin{tabular}{m{3cm} m{3cm} m{3cm} m{3cm}}
	%\hline
	\textbf{Hyperparameters}\\
	\text{Dynamic conflict exposure}\\
	\hline
                            &  \thead{Point estimate\\(mean)}   & \thead{Standard\\deviation}   & \thead{95\% Credibility\\interval} \\
	\hline
	$\ell_{dce}$             & \thead{3.23}        & \thead{0.13} 	& \thead{2.99 - 3.50}                             \\
    $\eta_{dce}$             & \thead{0.59}        & \thead{0.01} 	& \thead{0.55 - 0.62}                             \\
    $\epsilon_{dce}$         & \thead{0.23}        & \thead{0.01} 	& \thead{0.22 - 0.23}                             \\
  
    \hline
	\end{tabular}
\end{center}
\caption{\footnotesize{The tabel contains the estimated hyperparemeters pertaining to $\tilde{y}_{dce}$. }}\label{dce_hp}
\end{table}


% Int the hyperparameters
We see that $\ell_{dce}$ has a 95\% probability of being between 3 and 3.5 with a point estimate of 3.2. As such, this result is very similar to that of $\ell_{cm}$. Again, I only expect my results to be reliable three years into the future. A sample of the estimated patterns is presented in \autoref{dce_sampel_eks}.\par

% eta and epsilon...
% The two oher estimates for $\epsilon$ and $\eta$ are less simple to interpreate here since, a lot of noise have allready been removed estimating $\tilde{y}_{sce}$.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{dce_15_samples.pdf}
    \caption{\footnotesize{The estimated temporal patterns of conflict exposure from fifteen randomly drawn adjacent time lines. The solid line is the maximum likelihood point estimate of $\mu_{dce}$ and the corrosponding shading denotes $\mu_{dce} \pm 2\sigma_{dce}$. At such, given the model there is roughly a 95\% that $\mu_{cde}$ is within this zone. The colors of the lines denotes how close the time lines are in space. More similar colours equals more proximate cells. The scatter points are the target values obtained through $f_{sce}$. The hyperparameters are $\ell_{dce}$ = 3.2, $\eta_{dce}$ = 0.59, $\epsilon_{dce}$ = 0.2}}\label{dce_sampel_eks}
\end{figure}

% Int the figure  -> critaria for good spatial patterns. -> whats the point?
By drawing adjacent samples, the spatial dimension of conflict exposure becomes easily discernible. As such, even though I have not explicitly plotted the spatial dimension in \autoref{dce_sampel_eks}, it is still clearly visible. Each time line is influenced by all proximate time lines with declining impact as distance grows. Again, the product aligns gracefully with our theoretical criteria regarding conflict patterns.\par

% Two base measures. bridge
I now have my two base measures $f_{cm}$ and $f_{dce}$. Both these measures are estimated using my training set and have then been extrapolated into the "future" test years. As such, it is now a trivial task to further extract the corresponding slopes ($f'_{cm}$ and $f'_{dce}$), accelerations ($f''_{cm}$ and $f''_{dce}$) and masses ($F_{cm}$ and $F_{dce}$). With this done I have created all eight features which I will use to capture the patterns of conflict.\par

% The new split 
The last step here is to split the features according to the training and test set. Therefore, all feature values pertaining to the training years from 1998 through 2012 ($X_{patterns}$) are appended to the training set, while the extrapolated feature values from 2013 through 2017 ($X_{patternsEX}$) are appended to the test set. Importantly, the target values in the test set have still not been used for any estimations, computations or model training. As such, the process still emulates a real world forecasting scenario where we are able to extrapolate patterns based on past observations, but not use any information pertaining to future results. With all features constructed and the data-split completed, I now move on to test the combined predictive power of these features using the final predictive framework.\par

\subsection{Second layer: Predicting conflicts}
% \todo[inline]{todo}

% Whats going to happen here mate?
% In this short subsection I will briefly describe how I use the eight constructed features in the final predictive framework to create out-of-sample predictions. I then evaluate these predictions in the proceeding section.\par

% what goes ind nad what does not go ind.
To train the models, I employ the features $X_{patterns}$ and a binary conflict indicator $y_{binary}$ as the target -- naturally only the set pertaining to the training years. As such, $X_{patterns}$ contains the values of all eight features from 1989 through 2012 and $y_{binary}$ is a binary indicator denoting whether or not a given cell experienced any conflict in some given year between 1989 and 2012. This constitutes the training data. The test data, which holds the extrapolated $X_{patternsEX}$ and the out-of-sample prediction target $y_{binary}$ values from 2013 through 2017 are kept isolated from the model construction effort and not used before the evaluation effort.\par

% what happens with what goes ind
I train 1000 xgboost models using the training data. Every model uses the complete set of events from the training set along with an equally sized set of randomly drawn non-events, also from the training set. Every time a single model is finished training I use the model to generate out-of-sample predictions $\tilde{y}_{pred}$ by introducing the $X_{patternsEX}$ from the test set.\par

%As such, combining all 1000 predictions pertaining to one cell in one given year, I obtain a probability distribution of predictions. \par

%A most likely estimate of the predicted probability can be obtain from this distribution along with the an estimate of the variance of the distributions.\par
%[can be programmed better]


% What comes out
The genereated predictions are expressed as probabilities. Specifically, probabilities that some given grid cell will experience conflict the specific (test) year. As such the full outputs are probability distributions of probabilities. The individual probabilities are adjusted via Bayesian correction to account for the undersampling technique, and a maximum likelihood estimate is obtained from each individual distribution of probabilities. Given that the distributions appears approximately Gaussian, the maximum likelihood estimate is simply the mean and represents my best guess of what the probability of conflict is in a given cell, in a specific year.\par 

% Bridge
To evaluate to what extent my framework, and as such the features I have created, have successfully captured the patterns of conflict, I will now compare these probabilities to the actual observations contained in the test set $y_{binary}$. The results will be presented in the next section.\par

\section{The Results}
% [Analysis]
% I virkeligheden mest bare resultaterne; start bare hård med et resultat.

% Whats gonna happen here.
In the preceding sections I have shown how we can estimate and extrapolate the temporal and geo-spatial patterns of past conflicts using modern machine learning techniques. However, I have yet to demonstrate whether these estimated patterns hold any predictive power -- whether they can actually by used to forecast the time and place of future conflicts. In the following section I will evaluate the predictive performance of my approach in order to assess the extent to which I have succeeded at reliably predicting the time and place of future conflicts, using the temporal and geo-spatial patterns of past conflicts in tandem with Gaussian processes.\par

%to which the constructed features hold prediction power pertaining to time and place of future conflicts.\par 

%RQny: To what extent is it possible to reliably forecast and predict the time and place of future conflicts, using solely the temporal and geo-spatial patterns of past conflicts in tandem with Gaussian processes.}\par

%RQ: How can we use effectivly the temporal and geo-spatial patterns of past conflicts to forecast and predict the time and place of future conflicts?

\subsection{The predictive potential}

% How
To best convey the potential of my framework, I will evaluate it from a number of angles starting with the PR-curve, the AP score, and the ROC-AUC score. Then, I will set a threshold which will be used to convert my predicted probabilities to binary predictions. From these binary predictions I derive the rates of true positives, false positives, true negatives and false negatives as well as the related measures precision and recall. Following this, I will evaluate the relative importance of the eight features used in the framework.\par

% AP over time
The AP score is the prime evaluation metric of interest. Since I have a distribution of predictions, I naturally also have distributions of results. In \autoref{ap_scores} I show the distributions of estimated out-of-sample AP scores for each of the test years used with point estimates simply being the mean. As expected the performance of my framework changes as I move into the future. Specifically -- and as foretold by the lenghtscales $\ell_{cm}$ and $\ell_{dce}$ -- the performance drops substantially beyond 3 years. This is easily seen in \autoref{ap_trend} and \autoref{ap_scores} as the AP scores fall subtantially after 2015.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{ap_trend_alt.pdf}
    \caption{\footnotesize{The trend in average precision as it changes over the test years. The orange line denotes the maximum likelihood estimate (mean). The blue shade denotes the actual 1000 estimates per year. The red line denotes that last year $2012+3=2015$}}\label{ap_trend}
\end{figure}

\autoref{ap_trend} shows how the AP score change over the test years from 0.55 in 2013 down to 0.42 in 2017. The orange line is the maximun likelihood estimate of the AP given all the models and blue shade is the individual estimates. This is further illustrated in \autoref{ap_scores}.\par


\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{ap_scores.pdf}
    \caption{\footnotesize{Average precision distributions across all test years. Each distribution is base on the results from 1000 models}}\label{ap_scores}
\end{figure}

% the trend
As such it is clear that there is a substantial difference between my prediction power before 2015 and after. Indeed, \autoref{ap_scores} show practically no overlap between 2013, 2014 and 2015 on one side and 2016 and 2017 on the other. Looking at the actual numbers, out of all the models run, no model from 2013, 2014 and 2015 did as bad or worse then any model from 2016 or 2017. This leaves us a probability of $<0.001\%$ that our framework will perform as well after 3 years as before. For comparison there is a 2.4\% probability that $AP_{2015} \geq AP_{2013}$ and a 89.3\% probability that $AP_{2015} \geq AP_{2014}$. The point is that the lenghtscale indeed does provide powerful guidance regarding how far we can look into the future, and it should be taken quite seriously doing any real world application.\par

% Regarding why 2015 is better then 2014!
Naturally, it might seem a bit odd that my model seems to do better in 2015 than in 2014. Intuitively the predictive power of the framework should always decrease somewhat when going into the future. As I will comment on below this is neither a flaw nor a mystery. It is simply due to the fact that the patterns of 2015 coincidentally aligns more with the patterns of 2012 -- the last train year -- than 2014 does. As such, this is not a pattern I would expect to generalize beyond these particular years.\par 

%selected years
Now, given these results, and to keep the evaluation effort concise, I will not spend more time evaluating the two years 2016 and 2017. To mirror the challenges of real world applications I also ignore the first test year 2013. After all, the data used to train the models would not have been available before spring/summer 2013, and thus predictions regarding conflicts in 2013 would have been of limited use. Further more, any relevant actor needs some reaction time to take any forecasting into account. As such I focus on the years 2014 and 2015, respectively 6 and 18 months into the future from when the data would first have been available for analysis.\par

% PR-curve and ap score ( ROC and AUC..) for 
The PR-curve and the AP score are presented in \autoref{pr_curves} while the ROC-curves and AUC scores are presented in \autoref{roc_curves}.\par 

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{pr_curves_14_15.pdf}%insert baseline
    \caption{\footnotesize{The precision-recall curve for the years 2014 and 2015. The orange line is the maximun likelihood point estimate while the blue lines represents the individual samples}}\label{pr_curves}
\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{roc_curves_14_15.pdf}
    \caption{\footnotesize{The receiver operating characteristic curve for the years 2014 and 2015. The orange line is the maximun likelihood point estimate while the blue lines represents the individual samples}}\label{roc_curves}
\end{figure}

% Int the PR-curve and ROC curve
The PR-curve in \autoref{pr_curves} illustrates the trade-off between recall and precision at various thresholds, while the ROC-curve in \autoref{roc_curves} denotes the relationship between the false positive rate and the true positive rate at various thresholds. The share of events in both 2014 and 2015 is respectively 0.050 and 0.053. As such an AP score around 0.05 and AUC score at 0.5 is equivalent to random guesses. Thus, with an AP scores of 0.51 and 0.52, and AUC scores of 0.91 and 0.91 (point estimates) it is clear that the features I produced exhibit considerable predictive power. The question now is how these results hold up compared to other efforts using different approaches.\par

% compare with last assignment 
Intriguingly, the results presented here are better than those produced in \cite{Maase}. Specifically \cite{Maase} achieved an AP score of 0.47 \cite[14]{Maase}. This is interesting for a number of reasons. First of all, since the results which I have produced for this thesis rely solely on conflict patterns, they reaffirm the conclusion from \cite{Maase} stating that patterns are more informative than structural features when it comes to predicting future conflicts. Secondly, the framework presented in \cite{Maase} also included features pertaining to the temporal and spatial patterns of conflicts. These features, however, were vastly less theoretically and methodologically developed compared to the eight features I use in this thesis. Point being, using only the past patterns of conflict, in a theoretically and methodologically coherent manner, here generates better predictions, than using a broad roster of more traditional structural variables in cohort with poorly operationalized patterns.\par

%Only future research will show if the predictions I present here can be further improved be reintroducing structural patterns.\par

%compared to general stat of the art.
Beyond the results presented in \cite{Maase}, direct comparison is less forward. My framework produces and AUC of 0.91 for both 2014 and 2015. The state of the art prediction efforts in academia achieve an AUC at approximately 0.80 \citep[14]{chadefaux2017conflict}. Importantly however, most of these past studies deal with country-level conflicts and only include novel onsets \citep[14]{chadefaux2017conflict}. This naturally makes any direct comparisons with my framework somewhat misleading. On one hand it could be argued that predicting onsets is the most challenging part of conflict prediction. On the other hand, I am both predicting conflict onsets, continuation of conflict and conflict termination; and indeed at a much more disaggregated level than any efforts before this, which should make prediction harder. Point being, while direct comparison is unfeasible, I find it safe to say that the framework I have produced generates predictions at least as good -- if not better -- than what previous efforts have accomplished. Crucially, I achieve these results in a setting which emulates a real-world scenario. Conversely, most previous efforts have relied on structural data, ignoring the fact that this data would already be dated by the time of release. In a real-world setting this would surely lower the predictive capabilities of frameworks relying on structural features greatly compared to what is presented in published papers.\par

% problam with onsets
It should also be noted that when we analyse conflicts on a highly disaggregated level and treat conflict as a function of past temporal and spatial patterns, the concept of a "hard" onset appears somewhat theoretical blurred. It does not make much sense to say that one single cell experienced an actual conflict onset if the conflict simply spread from one or more neighbouring cells -- possible only a few kilometers away. Remember these cells are nothing but analytically constructs aligning with no structural or geographical features. And even when conflict diffuses across political boundaries such as country boarders  -- e.g. the Duran line between Afghanistan and Pakistan --  the conflict might well be the same and the notion of a new onset still misleading. Novel onsets do happen but we need to think about the phenomenon differently then we used to when employing highly disaggregated data. Further more, it should be noted that for policy purposes, predicting both termination and continuation of conflicts is arguably just as relevant as predicting conflict onsets.\par  

% why I now set a threshold
Given the challenge of comparison and the fact that measures such as AP or AUC are hard to derive substantial interpretations from, I now move on to present the results in a different light. To better convey the actual real world potential of the framework, I set a hard threshold denoting whether or not I predict that a given cell will experience conflict or not. That is I convert the probabilities into a binary measure. A lot of very useful information is discarded this way, but it does serve to present the results in a more intuitively appealing manner. For real world applications, however, the actual probabilities should naturally always be consulted.\par

% The threshold is set at 10-15\%.
I choose to set a threshold, which insures that I predict roughly the same total number of conflicts as was observed in the last year of the training set (2012). Setting the threshold at 0.10 fulfills this criteria. This means that every cell which has a probability of conflict above 10\% is classified as "expected to experience conflict", and all other cells as "not expected to experience conflict". Having actual classifications allows us to assess the generated number of true positives, false positives, true negatives, and false negatives. Given the threshold employed I have plotted these metrics in the two maps presented in \autoref{confusion_map_2014} and \autoref{confusion_map_2015}.\par
% Should it not be some mean of the last five years. Could run a GP and extrapolate to get an estimate of the number ;) 

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{confusion_map_2014.pdf}
    \caption{\footnotesize{The map is created by binarizing the estimated probabilities of conflict in 2014 and comparing this to the actual binary observations from 2014. Given the threshold of 0.10, all cells with a probability of conflict above 10\% are classified as conflicts, while all cells with a probability of 10\% or below are classified as non-conflicts.}}\label{confusion_map_2014}
\end{figure}

% Int the plots - the good
Interpreting these maps, we get a more substantial evaluation of the performance of the framework. The first thing to notice is that most of the classifications are true negatives. Most cells do not experience conflict most of the time, and my framework captures this. Secondly the framework is able to generate a large amount of true positives. Remember these predictions are generated on the basis of respectively two and three years old data and each cell is only approximately $50km\times50km$. Point being, this is an extremely hard classification task -- not least considering that I only incorporate past conflict patterns as predictors. As such, the performance of the framework does inspire optimism.\par

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.47]{confusion_map_2015.pdf}
    \caption{\footnotesize{The map is created by binarizing the estimated probabilities of conflict in 2015 and comparing this to the actual binary observations from 2015. Given the threshold of 0.10, all cells with a probability of conflict above 10\% are classified as conflicts, while all cells with a probability of 10\% or below are classified as non-conflicts.}}\label{confusion_map_2015}
\end{figure}

% Int the plots - the bad1 false negatives
However, it should also be clear from \autoref{confusion_map_2014} and \autoref{confusion_map_2015} that there is still a lot of room for improvement. It is especially clear in 2014 where my framework completely misses two major conflicts. A novel conflict in south-east Ukraine and a great surge of conflict in the Central African Republic. While it is unfortunate that my framework misses these conflicts, it is not surprising. The conflict in Ukraine is far removed in both time and space from any other conflict, thus no past patterns were there to alert the framework. The Central African Republic, on the other hand, has a long history of conflict and is surrounded by other conflict prone regions. As such, my framework also predicts some sporadic conflicts scattered around the country, but not nearly as widespread a conflict as was actually the case. The reason is simply that a peace agreement had been finalized in the last years of my test set, but said agreement fail spectacularly in the beginning of the test years \citep{bbc}. As such, the patterns I have extrapolated are those of a declining, not an increase or ongoing, conflict. These two examples clearly show the limits of my framework. Sudden and abrupt changes in the political landscape will always elude a framework solely based on the past spatial and temporal patterns of conflicts.\par

% Int the plots - the bad2 false positives
It is also clear from \autoref{confusion_map_2014} and \autoref{confusion_map_2015} that I do generate some false positives. These, however, are somewhat less problematic than false negatives for a number of reasons. First of all, just because conflict did not manifest in a given cell, it does not mean that the risk of conflict in that particular cell was not real. As an example, a large region from Eastern Turkey over northern Syria, northern Iraq and into western Iran is classified as conflicts in 2014, yet no conflict ensued that year. This region corresponds in large to the geographical region of Kurdistan \citep[271-272]{DahlmanKurdistan}, which has historically been the sight of many conflicts \citep{DahlmanKurdistan}.  Indeed, we also see conflict erupt in the region again in 2015 where many of my false positives change to true positives. This does not prove that there was a risk of conflict in 2014, but it surely does make it rather plausible. The danger of false positives is that resources might be allocated to prevent conflict when no conflict is likely to happen. However, if the false positives tend to indicate high risk zones where conflict simply failed to erupt due more or less to chance, allocating resources here might not constitute any huge waste after all.\par

% What is then the precision and recall - and what does this mean..
Given the specific threshold I here use, I obtain a recall of respectively 0.51 and 0.57 and a precision of respectively 0.56 and 0.52 for the years 2014 and 2015. Thus, in substantial terms; my framework is able to correctly classify slightly over half of all conflicts cells, but in the process I will roughly produce one false positive for each true positive. Naturally this ratio is highly dependent on the specific threshold I employ, but these results can still do a lot to convey the potential of my framework. Again, given the imbalanced and the highly disaggregated nature of the data and the sole focus on patterns, this is a decent result -- but it also does leave a lot of room for improvement. Naturally, such improvement might need to come from the inclusion of more features from other data sources. This paper, after all, only present one piece of the puzzle for creating a complete early warning system.\par

% bridge
As such, future research should survey both the potential of including more data and even better handling of past conflict patterns. To inform such efforts the next subsection will briefly touch upon the subject of feature importance. That is, assessing how much prediction power each of my eight features brings to the final predictive framework.\par 

%Knowing the extent to wich the various features contributed with prediciton power will 

\subsection{Feature importance}

% only 2014
Regarding feature importance, I find no difference between 2014 and 2015. As such I will only here present the results for 2014. The results from 2015 are vitually indentical and can be found in the appendix. \autoref{feature_imp2015}. The results from 2014 can be seen in \autoref{feature_imp2014}.\par 

\begin{figure}[!htb]
 	\centering
	\includegraphics[scale=0.47]{feature_imp_2014.pdf}
  \caption{\footnotesize{The relative importance of each feature in the prediciton effort}}\label{feature_imp2014}
\end{figure}

% What is then the most imp feature?
From \autoref{feature_imp2014} it is clear that the majority of the prediction power comes from the base feature of conflict magnitude $f_{cm}$. Interestingly this is the most basic feature in the framework simply denoting the expected future conflict magnitude in some cell given said cells history. It is easily understood and I only use a 1D Gaussian process to derive this measure. As such, future efforts aimed both at prediction and estimation might gain a lot from simply including this measure, if measures of the spatial dimensions are deemed to resource demanding. That being said it is still clear from \autoref{feature_imp2014} that all the features do bring some information to the effort. As such I recommend all eight being included in any complete early warning system.\par

% Bridge
This finalizes my evaluation of the predictive framework I created for these thesis. In the next section I will concluded the entire endeavour by summing up all major insights and results which I have presented throughout this thesis. The conclusion is followed by a prospective look in the future where I discuss how we should proceed from here to create a fully functional early warning system for conflict forecasting.\par

\section{The Conclusion}

%What was your starting point
Previous research has shown that past conflict patterns hold a lot of potential when it comes to predicting future conflicts. Therefore, if we are to create an early warning system for conflict forecasting, such system should include a component focused on extracting prediction power from past temporal and spatial patterns of conflict. However, previous efforts -- estimations and predictions alike -- have to a large extent failed to create features mirroring the theoretical insights we have regarding conflict patterns. To best utilize the predictive potential of past conflict patterns we need a tool that can capture conflict patterns in a manner which complies with the general theoretical expectations of conflict patterns. In this thesis I illustrate that the machine learning technique of Gaussian processes can be such a tool. Specifically my goal was to assess the extent to which it is possible to use Gaussian processes in tandem with past spatial and temporal conflict patterns to predict the time and place of future conflicts.\par

%Using an approach based on Gaussian processes I thus show how we can capture the temporal and geo-spatial patterns of past conflicts and use these patterns to forecast and predict the time and place of future conflicts.\par

%\emph{\textbf{Research Question:(NEW)} To what extent is it possible to reliably forecast and predict the time and place of future conflicts, using solely the temporal and geo-spatial patterns of past conflicts in tandem with Gaussian processes.}\par


% how do you do it
To this end I used Gaussian processes to create eight features each pertaining the spatial and temporal patterns of conflicts. Also using Gaussian processes I extrapolated these features into future years and then used these extrapolations to predict the probability of future conflicts in the geographical grid cells used as unit of analysis.\par

% What did you find?
To asses the extent to which my approach had succeeded in generating reliable forecasts, I used a predictive framework based on xgboost and undersampling along with out-of-sample prediction to evaluate the predictive potential of the extracted and extrapolated conflict patterns. Using my approach to forecast respectively two and three years into the future I achieved AP scores of 0.51 (2014) and 0.52 (2015) against a baseline of roughly 0.05. For both years I achieved an AUC score of 0.91 against a baseline of 0.50. In more substantial terms; if I set a probability threshold at 0.10 I am able to correctly predict half of all conflicts, but doing this will also generate one false positive for each true positive. Naturally I am able to capture more true positives, at the price of relatively more false positive.\par 

% is that good?
Given the highly disaggregated unit of analyses, the great imbalance of the data and the subject at hand these are encouragingly results which definitely shows that past conflict patterns do hold a lot of predictive potential -- not least when they are captured in a theoretical and methodological coherent manner.\par 

% compared to efforts?
Unfortunately my results are somewhat hard to compare to previous efforts -- not least due the highly disaggregated unit of analysis. The only effort which is directly comparable is \cite{Maase} which my approach here outperforms despite that fact the \cite{Maase} includes both simple measures of conflict patterns and structural features. While comparison with other efforts is less forward it is clear that the framework presented here does at least as well, if not better, than the state of the art. Notably this is done using only past patterns, and in a setting which emulates a real world scenario. The later point contrast to many previous efforts where researches ignores the fact that the data their used would be rather dated by the time it is actually made available.

% the bad
That being said it is also clear that I still have work to do before an actual reliable early warning system can be compiled. specifically my approach are unable to identify truly novel conflict onsets far removed from any past conflicts in time and space. That being said this thesis do present a substantial step forward, towards the creation of a actual early-warning-system for conflict forecasting.\par

% what is next/bridge
As presented, using the patterns of past conflicts as a predictor only constitute one of several components needed to create a complete early warning system. Naturally, there are no final answers concerning how many or which specific components are needed to create a fully operational early warning system. As such, in the next and final section I will present a number of components which might ammend the weaknesses of the approach presented above.\par

\section{Futher Perspectives}
% For estimaion: if you want arguement regarding baseline model look at \cite{schutte2011diffusion}.
% For prediction see own PHD app.
% Selvkritik - også vedrørende de mål du bruger måkse....

% Weakness of you approach/GP's
Using past conflict patterns as predictors does result in some natural limitations. Most prominently, we will never be able to predict truly novel conflicts far removed in time and space from any previous conflicts using such approach alone. We might be able to achieve even better results with Gaussian processes than what I have presented above. This might be done by distinguishing between long term trends and short term trends or by using hierarchical hyper priors. Furthermore other even more involved methods such as artificial neural networks might be able to capture the patterns of conflict in even more effective ways. But while these opportunities should be explored in future research, they will never amend the fundamental limitation of using past patterns to predict future patterns. As such, while patterns should be a central component in any early warning system, they should also only be one of many.\par

% Perhaps somthing about other events: political unrest, riots ect..
%One solutions could be to bring in other event data, such as data on demonstrations, riots, civil unrest ect. but that wich is avialeel is data... MORE

% one solution: reintroduce structural patterns and ammend thier weakneess with GP's
One component which also deserves attention is composed of structural data and theory on the structural prerequisites of intra-state conflict, such as poverty, resources, regime ect. The advantages of such a component is the large catalog of theory following it \citep{Collier_Hoeffler_1998, Fearon_Laitin_2003, Collier_Hoeffler_2004, Hegre_Sambanis_2006, Kalyvas_2007, Goldstone_2010, Cederman_Gleditsch_Buhaug_2013, perry_2013}. Such insights inform feature engineering, feature selection and model selection \cite[30]{Cederman_Gleditsch_Buhaug_2013}.\par

% disadvantage 1 and solution
As noted, however, one clear disadvantage of this approach is dated data. An other disadvantage is high inertia \citep[10]{chadefaux2017conflict}. Structural features are slow to change while political unrest can evolve into actual intra-state conflict relatively fast. Intriguingly however, given the this inertia we can address the disadvantage of dated data simply by use Gaussian processes to extrapolate the structural patterns into future years. As such, I would exploit the inertia of structural patterns to ameliorate the dated state of the data. To a large extent this effort would mimic the approach presented in this thesis, simply using different data.\par

% disadvantage 2 and solution
Yet, while the inertia inherent in structural data might justify extrapolating these patterns across five or even ten years, the inertia still means that we might identify fragile regions but not necessarily which of these fragile regions will experience conflict \citep[10]{chadefaux2017conflict}. Combining a structural component with one of these patterns will reduce this problem especially if we include data on other forms of events such as civil or political unrest.\par 

% Or use test or image recognition..
Following this logic, another component should be one which uses text or image data obtained from news/social/political sources. Such data would effectively constitute its own kind of event data, but one specifically tailored for the task at hand. Using text data is still a novel approach in social science \citep{grimmer2013text} and image data even more so \citep{williams2019images}. Yet, the use of text data has already shown promise in conflict predictions \citep{chadefaux_2014, mueller_2016}. Using image data for conflict prediction has to my knowledge not been done yet, but it could hold great promise not least since it circumvents the problem of varying norms and languages which challenges the use of text data. \par

%advantage - er du sikker på det er sin egen paregraf..
Text and image data has two advantages on structural data. Firstly, the data has the potential to be very current. In theory, it could be updated in real-time \citep[474]{cederman2017predicting}. Secondly, like more traditional event data, text and image data would be able to sort fragile but peaceful regions from fragile regions on the verge of conflict. Importantly, such data would also holds an advantage over the event data used in this thesis; text and image data could help predict onsets far removed in time and space from any previous conflicts.\par

% Weaknesses
Naturally, using text or images also has its weaknesses. Gathering text or images from the entire globe is no trivial effort. Local sources is hard to come by, and legal barriers might prevent the use of any data obtained. As such, it is not realistic to produce data on a disaggregated level comparable with that of the other components which I have presented. Thus, to ameliorate the individual weaknesses of each component they must all be combined into a single unified predictive framework. A unified early warning system for conflict prediction.\par

% bridge out ->
With these paths for future research presented I conclude this thesis on an optimistic note. Reliable conflict prediction might be the conflict researcher's final frontier, but given the results presented above, it does by no means appear a fruitless nor impossible endeavour.\par


\pagebreak

\section{Bibliography}
\bibliographystyle{apalike} 
\bibliography{conflict.bib}

\pagebreak
\section{Appendix}

\subsection{Python scripts}\label{scripts}

The following is a list of all scripts used for this thesis. They are all written for python 3 in jupyter notebooks (.ipynb). the list is ordered by order of execution. All the notebooks can also be accessed via my github: \hyperlink{https://github.com/Polichinel/Master_Thesis}{https://github.com/Polichinel/Master\_Thesis}. For simplicity they are all contained in the .zip file thesis\_apps\_simon\_vonderMaase.zip

Note that it will take days if not weeks to execute all notebooks even on a high-end PS.\par

Order of execution:
\begin{enumerate}
\item GP\_presentation.ipynb
\item Pickle\_full\_data.ipynb
\item Pickle\_restricted\_data.ipynb
\item Pickle\_test\_train.ipynb
\item Pickle\_hp\_sce\_all\_years.ipynb
\item Pickle\_hp\_dce\_mu\_and\_var.ipynb
\item Pickle\_dce\_mu\_predictions.ipynb
\item Pickle\_hp\_cm\_mu.ipynb
\item Pickle\_cm\_mu\_predictions.ipynb
\item Pickle\_slope\_acc\_mass.ipynb
\item Plot\_hp\_n\_samples.ipynb
\item Pickle\_predictions\_n\_metrics.ipynb
\item Plot\_results.ipynb
\end{enumerate}

The Prio grid shape file can be found at \hyperlink{https://www.prio.org/Data/PRIO-GRID/}{https://www.prio.org/Data/PRIO-GRID/} or directly from \hyperlink{file.prio.no/ReplicationData/PRIO-GRID/priogrid_shapefiles.zip}{file.prio.no/ReplicationData/PRIO-GRID/priogrid\_shapefiles.zip}\par

The UCDP shape file can be found at \hyperlink{https://www.ucdp.uu.se/downloads/\#d1}{https://www.ucdp.uu.se/downloads/\#d1} or directly from \hyperlink{http://ucdp.uu.se/downloads/ged/ged181-shp.zip}{http://ucdp.uu.se/downloads/ged/ged181-shp.zip}\par

The paper \cite{Maase} can also be found at my github page:\par

\hyperlink{https://github.com/Polichinel/Conflict_Prediction}{https://github.com/Polichinel/Conflict\_Prediction}

\pagebreak

% \subsection{Priors - Conflict magnitude}\label{cmPrior}

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[scale=0.47]{Hyper-priors(cm).pdf}
%     \caption{\footnotesize{Weakly informative hyper-priors for the Guassian processes estimation of conflict magnitude. Simply set to help the computation by discouraging high unrealistic values for $\eta$, $\ell$ and $\sigma$.}}
% \end{figure}
% \pagebreak

% \subsection{Priors - Static conflict exposure}\label{scePrior}

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[scale=0.47]{Hyper-priors(sce).pdf}
%     \caption{\footnotesize{Weakly informative hyper-priors for the Guassian processes estimation of static conflict exposure. Simply set to help the computation by discouraging high unrealistic values for $\eta$, $\ell$ and $\sigma$.}}
% \end{figure}
% \pagebreak

% \subsection{Priors - Dynamic conflict exposure}\label{dcePrior}

% \begin{figure}[!htb]
% 	\centering
% 	\includegraphics[scale=0.47]{Hyper-priors(dce).pdf}
%     \caption{\footnotesize{Weakly informative hyper-priors for the Guassian processes estimation of dynamic conflict exposure. Simply set to help the computation by discouraging high unrealistic values for $\eta$, $\ell$ and $\sigma$.}}
% \end{figure}
% \pagebreak

%\subsection{Visual illustration of Gaussian distribution and Gaussian process}\label{GDGP}
\subsection{Feature importance 2015}\label{feature_imp2015}


\begin{figure}[!htb]
 	\centering
	\includegraphics[scale=0.47]{feature_imp_2015.pdf}
  \caption{\footnotesize{The relative importance of each feature in the prediciton effort}}
\end{figure}
\pagebreak


\end{document}
